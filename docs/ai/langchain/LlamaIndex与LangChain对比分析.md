---
title: LlamaIndexä¸LangChainå¯¹æ¯”åˆ†æ
date: 2025-01-14
permalink: /ai/langchain/llamaindex-vs-langchain.html
tags:
  - LangChain
  - LlamaIndex
  - æ¡†æ¶å¯¹æ¯”
  - RAG
categories:
  - AI
  - LangChain
---

# LlamaIndexä¸LangChainå¯¹æ¯”åˆ†æ

## æ¦‚è¿°

LlamaIndex å’Œ LangChain æ˜¯ç›®å‰æœ€æµè¡Œçš„ä¸¤ä¸ª LLM åº”ç”¨å¼€å‘æ¡†æ¶ã€‚æœ¬æ–‡å°†æ·±å…¥å¯¹æ¯”è¿™ä¸¤ä¸ªæ¡†æ¶çš„è®¾è®¡ç†å¿µã€åŠŸèƒ½ç‰¹ç‚¹ã€é€‚ç”¨åœºæ™¯ï¼Œå¸®åŠ©ä½ åšå‡ºæ­£ç¡®çš„æŠ€æœ¯é€‰æ‹©ã€‚

---

## ä¸€ã€æ ¸å¿ƒå®šä½å¯¹æ¯”

### ğŸ¯ è®¾è®¡å“²å­¦

```mermaid
graph LR
    A[LLMåº”ç”¨å¼€å‘] --> B[LlamaIndex]
    A --> C[LangChain]

    B --> B1[æ•°æ®ç´¢å¼•]
    B --> B2[çŸ¥è¯†æ£€ç´¢]
    B --> B3[RAGç³»ç»Ÿ]

    C --> C1[é€šç”¨å¼€å‘]
    C --> C2[Agentç³»ç»Ÿ]
    C --> C3[å·¥å…·é›†æˆ]
    C --> C4[å¤æ‚å·¥ä½œæµ]

    style B fill:#e1f5ff
    style C fill:#fff4e1
```

### LlamaIndexï¼ˆåŸå GPT Indexï¼‰

**æ ¸å¿ƒç†å¿µ**ï¼šä¸º RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰è€Œç”Ÿ

- ğŸ“š **ä¸“æ³¨é¢†åŸŸ**ï¼šæ•°æ®ç´¢å¼•å’Œæ£€ç´¢
- ğŸ¯ **è®¾è®¡ç›®æ ‡**ï¼šè®©æ•°æ®æ¥å…¥ LLM å˜å¾—ç®€å•
- ğŸ’¡ **å…³é”®ä¼˜åŠ¿**ï¼šç®€æ´ã€é«˜æ•ˆã€ä¸“æ³¨
- ğŸš€ **æœ€ä½³åœºæ™¯**ï¼šé—®ç­”ç³»ç»Ÿã€çŸ¥è¯†åº“ã€æ–‡æ¡£æ£€ç´¢

### LangChain

**æ ¸å¿ƒç†å¿µ**ï¼šé€šç”¨ LLM åº”ç”¨å¼€å‘æ¡†æ¶

- ğŸ”§ **ä¸“æ³¨é¢†åŸŸ**ï¼šå…¨é¢çš„ LLM åº”ç”¨å·¥å…·é“¾
- ğŸ¯ **è®¾è®¡ç›®æ ‡**ï¼šæä¾›å®Œæ•´çš„åº”ç”¨å¼€å‘ç”Ÿæ€
- ğŸ’¡ **å…³é”®ä¼˜åŠ¿**ï¼šçµæ´»ã€å¯ç»„åˆã€åŠŸèƒ½ä¸°å¯Œ
- ğŸš€ **æœ€ä½³åœºæ™¯**ï¼šAgentsã€å¤æ‚å·¥ä½œæµã€å¤šå·¥å…·é›†æˆ

---

## äºŒã€å¿«é€Ÿå¯¹æ¯”è¡¨

| ç»´åº¦ | LlamaIndex | LangChain | è¯´æ˜ |
|------|-----------|-----------|------|
| **æ ¸å¿ƒå®šä½** | æ•°æ®ç´¢å¼•å’Œæ£€ç´¢ | é€šç”¨åº”ç”¨å¼€å‘ | LlamaIndexæ›´ä¸“æ³¨ï¼ŒLangChainæ›´å…¨é¢ |
| **å­¦ä¹ æ›²çº¿** | â­â­â­ | â­â­â­â­â­ | LlamaIndexæ›´å®¹æ˜“ä¸Šæ‰‹ |
| **ä»£ç å¤æ‚åº¦** | ç®€æ´ç›´è§‚ | çµæ´»ä½†å¤æ‚ | LlamaIndexå‡ è¡Œä»£ç æå®šRAG |
| **RAGèƒ½åŠ›** | â­â­â­â­â­ | â­â­â­â­ | LlamaIndexåœ¨RAGæ–¹é¢æ›´å¼º |
| **Agentèƒ½åŠ›** | â­â­â­ | â­â­â­â­â­ | LangChainçš„Agentæ›´å¼ºå¤§ |
| **å·¥å…·é›†æˆ** | â­â­â­ | â­â­â­â­â­ | LangChainæœ‰500+é›†æˆ |
| **æŸ¥è¯¢æ€§èƒ½** | â­â­â­â­â­ | â­â­â­â­ | LlamaIndexé’ˆå¯¹æ£€ç´¢ä¼˜åŒ– |
| **ç¤¾åŒºè§„æ¨¡** | å¤§ï¼ˆ30k+ starsï¼‰ | æ›´å¤§ï¼ˆ80k+ starsï¼‰ | LangChainç¤¾åŒºæ›´æ´»è·ƒ |
| **æ–‡æ¡£è´¨é‡** | ä¼˜ç§€ | ä¼˜ç§€ | ä¸¤è€…æ–‡æ¡£éƒ½å¾ˆå®Œå–„ |
| **æ›´æ–°é¢‘ç‡** | é¢‘ç¹ | éå¸¸é¢‘ç¹ | LangChainæ›´æ–°æ›´å¿« |
| **ç”Ÿäº§å°±ç»ª** | âœ… | âœ… | éƒ½å¯ç”¨äºç”Ÿäº§ç¯å¢ƒ |
| **ä¼ä¸šæ”¯æŒ** | æœ‰ | æœ‰ | éƒ½æœ‰å•†ä¸šæ”¯æŒç‰ˆæœ¬ |

---

## ä¸‰ã€åŠŸèƒ½è¯¦ç»†å¯¹æ¯”

### 3.1 æ•°æ®åŠ è½½å’Œç´¢å¼•

#### LlamaIndexï¼šâ­â­â­â­â­

**ç‰¹ç‚¹**ï¼šå¼€ç®±å³ç”¨ï¼Œæç®€ API

```python
from llama_index import VectorStoreIndex, SimpleDirectoryReader

# 1. åŠ è½½æ–‡æ¡£ï¼ˆä¸€è¡Œä»£ç ï¼‰
documents = SimpleDirectoryReader('data').load_data()

# 2. åˆ›å»ºç´¢å¼•ï¼ˆä¸€è¡Œä»£ç ï¼‰
index = VectorStoreIndex.from_documents(documents)

# 3. æŸ¥è¯¢ï¼ˆä¸€è¡Œä»£ç ï¼‰
query_engine = index.as_query_engine()
response = query_engine.query("å…¬å¸çš„ä¼‘å‡æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ")
print(response)
```

**ä¼˜åŠ¿**ï¼š
- âœ… 3è¡Œæ ¸å¿ƒä»£ç å®Œæˆå®Œæ•´RAGæµç¨‹
- âœ… è‡ªåŠ¨å¤„ç†æ–‡æœ¬åˆ†å‰²ã€åµŒå…¥ã€å­˜å‚¨
- âœ… å¼€ç®±å³ç”¨çš„åˆç†é»˜è®¤é…ç½®

---

#### LangChainï¼šâ­â­â­â­

**ç‰¹ç‚¹**ï¼šçµæ´»å¯æ§ï¼Œéœ€è¦æ›´å¤šé…ç½®

```python
from langchain.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

# 1. åŠ è½½æ–‡æ¡£
loader = DirectoryLoader('data')
documents = loader.load()

# 2. åˆ†å‰²æ–‡æ¡£
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)
splits = text_splitter.split_documents(documents)

# 3. åˆ›å»ºå‘é‡å­˜å‚¨
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(splits, embeddings)

# 4. åˆ›å»ºæ£€ç´¢é“¾
llm = ChatOpenAI()
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever()
)

# 5. æŸ¥è¯¢
response = qa_chain.run("å…¬å¸çš„ä¼‘å‡æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ")
print(response)
```

**ä¼˜åŠ¿**ï¼š
- âœ… æ¯ä¸€æ­¥éƒ½å¯ä»¥ç²¾ç»†æ§åˆ¶
- âœ… å¯ä»¥è‡ªç”±é€‰æ‹©å’Œç»„åˆç»„ä»¶
- âœ… é€‚åˆå¤æ‚åœºæ™¯çš„å®šåˆ¶åŒ–éœ€æ±‚

**å¯¹æ¯”ç»“è®º**ï¼š
- ğŸ¯ **ç®€å•åœºæ™¯**ï¼šLlamaIndex èƒœå‡ºï¼ˆä»£ç é‡å°‘70%ï¼‰
- ğŸ¯ **å¤æ‚å®šåˆ¶**ï¼šLangChain èƒœå‡ºï¼ˆæ›´çµæ´»ï¼‰

---

### 3.2 ç´¢å¼•ç±»å‹

#### LlamaIndexï¼šä¸°å¯Œçš„ç´¢å¼•ç±»å‹

LlamaIndex æä¾›å¤šç§å¼€ç®±å³ç”¨çš„ç´¢å¼•ï¼Œé’ˆå¯¹ä¸åŒåœºæ™¯ä¼˜åŒ–ï¼š

```python
# 1. Vector Store Indexï¼ˆæœ€å¸¸ç”¨ï¼‰- åŸºäºå‘é‡ç›¸ä¼¼åº¦
from llama_index import VectorStoreIndex
vector_index = VectorStoreIndex.from_documents(documents)
# é€‚ç”¨åœºæ™¯ï¼šè¯­ä¹‰æœç´¢ã€ç›¸ä¼¼å†…å®¹æ£€ç´¢

# 2. List Index - é¡ºåºéå†æ‰€æœ‰æ–‡æ¡£
from llama_index import ListIndex
list_index = ListIndex.from_documents(documents)
# é€‚ç”¨åœºæ™¯ï¼šéœ€è¦è€ƒè™‘æ‰€æœ‰æ–‡æ¡£çš„åœºæ™¯ã€æ‘˜è¦ç”Ÿæˆ

# 3. Tree Index - å±‚æ¬¡åŒ–æ ‘å½¢ç»“æ„
from llama_index import TreeIndex
tree_index = TreeIndex.from_documents(documents)
# é€‚ç”¨åœºæ™¯ï¼šå¤§è§„æ¨¡æ–‡æ¡£ã€åˆ†å±‚æ‘˜è¦

# 4. Keyword Table Index - åŸºäºå…³é”®è¯åŒ¹é…
from llama_index import KeywordTableIndex
keyword_index = KeywordTableIndex.from_documents(documents)
# é€‚ç”¨åœºæ™¯ï¼šç²¾ç¡®å…³é”®è¯æœç´¢ã€è¡¥å……å‘é‡æ£€ç´¢

# 5. Knowledge Graph Index - çŸ¥è¯†å›¾è°±ç´¢å¼•
from llama_index import KnowledgeGraphIndex
kg_index = KnowledgeGraphIndex.from_documents(documents)
# é€‚ç”¨åœºæ™¯ï¼šå®ä½“å…³ç³»æŸ¥è¯¢ã€ç»“æ„åŒ–çŸ¥è¯†

# 6. SQL Index - ç»“æ„åŒ–æ•°æ®ç´¢å¼•
from llama_index import SQLStructStoreIndex
sql_index = SQLStructStoreIndex.from_documents(documents)
# é€‚ç”¨åœºæ™¯ï¼šæ•°æ®åº“æŸ¥è¯¢ã€ç»“æ„åŒ–æ•°æ®åˆ†æ
```

**ç´¢å¼•é€‰æ‹©å†³ç­–æ ‘**ï¼š

```mermaid
graph TD
    A[é€‰æ‹©ç´¢å¼•ç±»å‹] --> B{æ•°æ®ç±»å‹?}

    B -->|éç»“æ„åŒ–æ–‡æœ¬| C{æŸ¥è¯¢æ¨¡å¼?}
    B -->|ç»“æ„åŒ–æ•°æ®| D[SQL Index]
    B -->|å®ä½“å…³ç³»| E[Knowledge Graph Index]

    C -->|è¯­ä¹‰æœç´¢| F[Vector Store Index]
    C -->|å…³é”®è¯åŒ¹é…| G[Keyword Table Index]
    C -->|éœ€è¦æ‘˜è¦| H{æ–‡æ¡£è§„æ¨¡?}

    H -->|å°è§„æ¨¡| I[List Index]
    H -->|å¤§è§„æ¨¡| J[Tree Index]

    style F fill:#90EE90
    style D fill:#FFD700
    style E fill:#87CEEB
```

---

#### LangChainï¼šçµæ´»çš„å‘é‡å­˜å‚¨

LangChain ä¸»è¦ä¾èµ–å‘é‡å­˜å‚¨ï¼Œä½†æ”¯æŒæ›´å¤šå‘é‡æ•°æ®åº“ï¼š

```python
# æ”¯æŒçš„å‘é‡æ•°æ®åº“
from langchain.vectorstores import (
    Chroma,           # å¼€æºã€æ˜“ç”¨
    FAISS,            # Facebook AIã€é«˜æ€§èƒ½
    Pinecone,         # äº‘ç«¯ã€æ‰˜ç®¡æœåŠ¡
    Weaviate,         # å¼€æºã€å‘é‡æ•°æ®åº“
    Milvus,           # å¼€æºã€ä¼ä¸šçº§
    Qdrant,           # å¼€æºã€Rustå®ç°
    # ... è¿˜æœ‰30+ç§
)

# ä½¿ç”¨ç¤ºä¾‹
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(
    documents=splits,
    embedding=embeddings,
    persist_directory="./chroma_db"
)
```

**å¯¹æ¯”ç»“è®º**ï¼š
- ğŸ¯ **ç´¢å¼•å¤šæ ·æ€§**ï¼šLlamaIndex èƒœå‡ºï¼ˆ6ç§ç´¢å¼•ç±»å‹ï¼‰
- ğŸ¯ **å‘é‡æ•°æ®åº“æ”¯æŒ**ï¼šLangChain èƒœå‡ºï¼ˆ30+ç§ï¼‰

---

### 3.3 æŸ¥è¯¢æ¨¡å¼

#### LlamaIndexï¼šä¸°å¯Œçš„æŸ¥è¯¢å¼•æ“

LlamaIndex æä¾›å¤šç§æŸ¥è¯¢æ¨¡å¼ï¼Œæ»¡è¶³ä¸åŒéœ€æ±‚ï¼š

```python
# 1. åŸºç¡€æŸ¥è¯¢æ¨¡å¼
query_engine = index.as_query_engine()
response = query_engine.query("ä»€ä¹ˆæ˜¯RAGï¼Ÿ")

# 2. æµå¼å“åº”ï¼ˆé€‚åˆå®æ—¶å¯¹è¯ï¼‰
query_engine = index.as_query_engine(streaming=True)
response = query_engine.query("è¯¦ç»†è§£é‡ŠRAGç³»ç»Ÿ")
response.print_response_stream()  # å®æ—¶æ‰“å°

# 3. å­é—®é¢˜æŸ¥è¯¢å¼•æ“ï¼ˆå¤æ‚é—®é¢˜åˆ†è§£ï¼‰
from llama_index.query_engine import SubQuestionQueryEngine
from llama_index.tools import QueryEngineTool

# ä¸ºä¸åŒæ•°æ®æºåˆ›å»ºæŸ¥è¯¢å¼•æ“
query_engine_tools = [
    QueryEngineTool(
        query_engine=tech_index.as_query_engine(),
        metadata={"name": "tech_docs", "description": "æŠ€æœ¯æ–‡æ¡£"}
    ),
    QueryEngineTool(
        query_engine=business_index.as_query_engine(),
        metadata={"name": "business_docs", "description": "ä¸šåŠ¡æ–‡æ¡£"}
    )
]

# å­é—®é¢˜æŸ¥è¯¢å¼•æ“ä¼šè‡ªåŠ¨å°†å¤æ‚é—®é¢˜åˆ†è§£
sub_query_engine = SubQuestionQueryEngine.from_defaults(
    query_engine_tools=query_engine_tools
)

response = sub_query_engine.query(
    "æ¯”è¾ƒæŠ€æœ¯æ–‡æ¡£å’Œä¸šåŠ¡æ–‡æ¡£ä¸­å…³äºç”¨æˆ·è®¤è¯çš„æè¿°"
)
# å†…éƒ¨ä¼šç”Ÿæˆï¼š
# å­é—®é¢˜1: æŠ€æœ¯æ–‡æ¡£ä¸­çš„ç”¨æˆ·è®¤è¯æ˜¯å¦‚ä½•å®ç°çš„ï¼Ÿ -> æŸ¥è¯¢ tech_docs
# å­é—®é¢˜2: ä¸šåŠ¡æ–‡æ¡£ä¸­çš„ç”¨æˆ·è®¤è¯æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ -> æŸ¥è¯¢ business_docs
# æœ€åç»¼åˆä¸¤ä¸ªç­”æ¡ˆ

# 4. è·¯ç”±æŸ¥è¯¢å¼•æ“ï¼ˆæ™ºèƒ½é€‰æ‹©æ•°æ®æºï¼‰
from llama_index.query_engine import RouterQueryEngine
from llama_index.selectors import LLMSingleSelector

# åˆ›å»ºé€‰æ‹©å™¨
selector = LLMSingleSelector.from_defaults()

# è·¯ç”±æŸ¥è¯¢å¼•æ“ä¼šæ ¹æ®é—®é¢˜è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„æ•°æ®æº
router_query_engine = RouterQueryEngine(
    selector=selector,
    query_engine_tools=query_engine_tools
)

response = router_query_engine.query("JWTä»¤ç‰Œå¦‚ä½•éªŒè¯ï¼Ÿ")
# ä¼šè‡ªåŠ¨è·¯ç”±åˆ° tech_docs

# 5. å¤šæ­¥æŸ¥è¯¢å¼•æ“ï¼ˆè¿­ä»£ä¼˜åŒ–ç­”æ¡ˆï¼‰
from llama_index.query_engine import MultiStepQueryEngine

multi_step_engine = MultiStepQueryEngine(
    query_engine=base_query_engine,
    num_steps=3,  # è¿­ä»£3æ¬¡
    response_synthesizer=response_synthesizer
)

response = multi_step_engine.query("æ·±å…¥è§£é‡Šåˆ†å¸ƒå¼äº‹åŠ¡")
# ç¬¬1æ­¥ï¼šè·å–åˆæ­¥ç­”æ¡ˆ
# ç¬¬2æ­¥ï¼šåŸºäºåˆæ­¥ç­”æ¡ˆç”Ÿæˆæ›´æ·±å…¥çš„æŸ¥è¯¢
# ç¬¬3æ­¥ï¼šç»¼åˆå‰ä¸¤æ­¥çš„ç»“æœ

# 6. è½¬æ¢æŸ¥è¯¢å¼•æ“ï¼ˆæŸ¥è¯¢æ”¹å†™ä¼˜åŒ–ï¼‰
from llama_index.indices.query.query_transform import HyDEQueryTransform

# HyDE: Hypothetical Document Embeddings
# å…ˆç”Ÿæˆå‡è®¾çš„ç­”æ¡ˆæ–‡æ¡£ï¼Œç”¨å‡è®¾æ–‡æ¡£å»æ£€ç´¢
hyde = HyDEQueryTransform(include_original=True)

query_engine = index.as_query_engine(
    query_transform=hyde
)

response = query_engine.query("æé«˜æ£€ç´¢å‡†ç¡®ç‡çš„æ–¹æ³•")
# å†…éƒ¨è¿‡ç¨‹ï¼š
# 1. ç”Ÿæˆå‡è®¾ç­”æ¡ˆï¼š"æé«˜æ£€ç´¢å‡†ç¡®ç‡å¯ä»¥é€šè¿‡...ï¼ˆè¯¦ç»†å†…å®¹ï¼‰"
# 2. ç”¨å‡è®¾ç­”æ¡ˆçš„embeddingå»æ£€ç´¢ç›¸å…³æ–‡æ¡£
# 3. ç”¨æ£€ç´¢åˆ°çš„çœŸå®æ–‡æ¡£ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

# 7. é‡æ’åºæŸ¥è¯¢å¼•æ“
from llama_index.postprocessor import SentenceTransformerRerank

rerank = SentenceTransformerRerank(
    model="cross-encoder/ms-marco-MiniLM-L-2-v2",
    top_n=3
)

query_engine = index.as_query_engine(
    node_postprocessors=[rerank],
    similarity_top_k=10  # å…ˆå¬å›10ä¸ª
)
# è¿‡ç¨‹ï¼šå…ˆå¬å›10ä¸ªï¼Œç„¶åç”¨é‡æ’åºæ¨¡å‹é€‰å‡ºæœ€ç›¸å…³çš„3ä¸ª

# 8. å¯¹æ¯”æŸ¥è¯¢å¼•æ“
from llama_index.query_engine import ComparableQueryEngine

comparable_engine = ComparableQueryEngine.from_query_engines(
    query_engines={
        "2023å¹´æŠ¥": report_2023_index.as_query_engine(),
        "2024å¹´æŠ¥": report_2024_index.as_query_engine()
    }
)

response = comparable_engine.query("å¯¹æ¯”ä¸¤å¹´çš„è¥æ”¶å¢é•¿")
```

**æŸ¥è¯¢æ¨¡å¼é€‰æ‹©æŒ‡å—**ï¼š

| æŸ¥è¯¢æ¨¡å¼ | é€‚ç”¨åœºæ™¯ | ä¼˜åŠ¿ |
|---------|---------|------|
| **åŸºç¡€æŸ¥è¯¢** | ç®€å•é—®ç­” | å¿«é€Ÿã€ç›´æ¥ |
| **æµå¼å“åº”** | å®æ—¶å¯¹è¯ã€é•¿æ–‡æœ¬ç”Ÿæˆ | ç”¨æˆ·ä½“éªŒå¥½ |
| **å­é—®é¢˜æŸ¥è¯¢** | å¤æ‚é—®é¢˜ã€å¤šæ•°æ®æº | é—®é¢˜åˆ†è§£ã€å¹¶è¡ŒæŸ¥è¯¢ |
| **è·¯ç”±æŸ¥è¯¢** | å¤šæ•°æ®æºã€è‡ªåŠ¨é€‰æ‹© | æ™ºèƒ½è·¯ç”±ã€é«˜æ•ˆ |
| **å¤šæ­¥æŸ¥è¯¢** | éœ€è¦æ·±åº¦åˆ†æ | è¿­ä»£ä¼˜åŒ–ã€æ›´å‡†ç¡® |
| **è½¬æ¢æŸ¥è¯¢(HyDE)** | å¬å›ç‡ä½çš„åœºæ™¯ | æé«˜å¬å›ç‡ |
| **é‡æ’åº** | ç²¾ç¡®åº¦è¦æ±‚é«˜ | æé«˜ç²¾ç¡®åº¦ |
| **å¯¹æ¯”æŸ¥è¯¢** | ç‰ˆæœ¬å¯¹æ¯”ã€å·®å¼‚åˆ†æ | ç»“æ„åŒ–å¯¹æ¯” |

---

#### LangChainï¼šåŸºäºChainçš„æŸ¥è¯¢

LangChain é€šè¿‡ Chain ç»„åˆå®ç°æŸ¥è¯¢ï¼š

```python
from langchain.chains import RetrievalQA, ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory

# 1. åŸºç¡€æ£€ç´¢é—®ç­”é“¾
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(),
    chain_type="stuff",  # æˆ– "map_reduce", "refine", "map_rerank"
    retriever=vectorstore.as_retriever()
)

# 2. å¯¹è¯å¼æ£€ç´¢é“¾ï¼ˆå¸¦è®°å¿†ï¼‰
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

conversational_chain = ConversationalRetrievalChain.from_llm(
    llm=ChatOpenAI(),
    retriever=vectorstore.as_retriever(),
    memory=memory
)

# 3. è‡ªå®šä¹‰æ£€ç´¢é“¾
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

prompt = PromptTemplate(
    template="åŸºäºä»¥ä¸‹å†…å®¹å›ç­”é—®é¢˜ï¼š\n{context}\n\né—®é¢˜ï¼š{question}",
    input_variables=["context", "question"]
)

custom_chain = LLMChain(llm=llm, prompt=prompt)
```

**å¯¹æ¯”ç»“è®º**ï¼š
- ğŸ¯ **æŸ¥è¯¢æ¨¡å¼ä¸°å¯Œåº¦**ï¼šLlamaIndex èƒœå‡ºï¼ˆ8ç§ä¸“é—¨çš„æŸ¥è¯¢å¼•æ“ï¼‰
- ğŸ¯ **çµæ´»æ€§**ï¼šLangChain èƒœå‡ºï¼ˆå¯ä»¥è‡ªç”±ç»„åˆChainï¼‰

---

### 3.4 Agentså’Œå·¥å…·é›†æˆ

#### LangChainï¼šâ­â­â­â­â­

LangChain åœ¨ Agent æ–¹é¢éå¸¸å¼ºå¤§ï¼š

```python
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.chat_models import ChatOpenAI
from langchain.utilities import SerpAPIWrapper, WikipediaAPIWrapper
from langchain.chains import LLMMathChain

# 1. åˆå§‹åŒ–å„ç§å·¥å…·
search = SerpAPIWrapper()
wikipedia = WikipediaAPIWrapper()
llm = ChatOpenAI(temperature=0)
math_chain = LLMMathChain.from_llm(llm)

# 2. å®šä¹‰å·¥å…·åˆ—è¡¨
tools = [
    Tool(
        name="Search",
        func=search.run,
        description="å½“éœ€è¦æœç´¢æœ€æ–°ä¿¡æ¯æ—¶ä½¿ç”¨ã€‚è¾“å…¥åº”è¯¥æ˜¯æœç´¢æŸ¥è¯¢ã€‚"
    ),
    Tool(
        name="Wikipedia",
        func=wikipedia.run,
        description="å½“éœ€è¦æŸ¥è¯¢ç™¾ç§‘çŸ¥è¯†æ—¶ä½¿ç”¨ã€‚è¾“å…¥åº”è¯¥æ˜¯æœç´¢è¯ã€‚"
    ),
    Tool(
        name="Calculator",
        func=math_chain.run,
        description="å½“éœ€è¦è¿›è¡Œæ•°å­¦è®¡ç®—æ—¶ä½¿ç”¨ã€‚è¾“å…¥åº”è¯¥æ˜¯æ•°å­¦è¡¨è¾¾å¼ã€‚"
    )
]

# 3. åˆ›å»ºAgentï¼ˆå¤šç§ç±»å‹ï¼‰
# ç±»å‹1: Zero-shot ReAct Agentï¼ˆæœ€å¸¸ç”¨ï¼‰
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# ç±»å‹2: Conversational Agentï¼ˆå¸¦è®°å¿†ï¼‰
from langchain.memory import ConversationBufferMemory
memory = ConversationBufferMemory(memory_key="chat_history")

conversational_agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
    memory=memory,
    verbose=True
)

# ç±»å‹3: Structured Tool Agentï¼ˆç»“æ„åŒ–è¾“å…¥ï¼‰
structured_agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# 4. ä½¿ç”¨Agent
response = agent.run(
    "æ¯”è¾ƒä¸€ä¸‹2022å¹´å’Œ2023å¹´ä¸­å›½çš„GDPå¢é•¿ç‡ï¼Œå¹¶è®¡ç®—ä¸¤å¹´çš„å·®å€¼"
)

# Agentçš„æ€è€ƒè¿‡ç¨‹ï¼ˆverbose=Trueæ—¶ä¼šæ‰“å°ï¼‰ï¼š
# Thought: æˆ‘éœ€è¦å…ˆæœç´¢2022å¹´ä¸­å›½GDPå¢é•¿ç‡
# Action: Search
# Action Input: "ä¸­å›½2022å¹´GDPå¢é•¿ç‡"
# Observation: 2022å¹´ä¸­å›½GDPå¢é•¿ç‡ä¸º3.0%
#
# Thought: ç°åœ¨æˆ‘éœ€è¦æœç´¢2023å¹´çš„æ•°æ®
# Action: Search
# Action Input: "ä¸­å›½2023å¹´GDPå¢é•¿ç‡"
# Observation: 2023å¹´ä¸­å›½GDPå¢é•¿ç‡ä¸º5.2%
#
# Thought: ç°åœ¨æˆ‘éœ€è¦è®¡ç®—å·®å€¼
# Action: Calculator
# Action Input: 5.2 - 3.0
# Observation: 2.2
#
# Thought: æˆ‘ç°åœ¨çŸ¥é“æœ€ç»ˆç­”æ¡ˆäº†
# Final Answer: 2022å¹´ä¸­å›½GDPå¢é•¿ç‡ä¸º3.0%ï¼Œ2023å¹´ä¸º5.2%ï¼Œå·®å€¼ä¸º2.2ä¸ªç™¾åˆ†ç‚¹ã€‚

# 5. è‡ªå®šä¹‰å·¥å…·
from langchain.tools import BaseTool
from typing import Optional

class CustomDatabaseTool(BaseTool):
    name = "database_query"
    description = "å½“éœ€è¦æŸ¥è¯¢æ•°æ®åº“æ—¶ä½¿ç”¨ã€‚è¾“å…¥åº”è¯¥æ˜¯SQLæŸ¥è¯¢ã€‚"

    def _run(self, query: str) -> str:
        # å®ç°æ•°æ®åº“æŸ¥è¯¢é€»è¾‘
        return f"æ‰§è¡ŒæŸ¥è¯¢: {query}"

    async def _arun(self, query: str) -> str:
        # å¼‚æ­¥ç‰ˆæœ¬
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥")

db_tool = CustomDatabaseTool()

# 6. Multi-Agentç³»ç»Ÿ
from langchain.agents import AgentExecutor

# åˆ›å»ºä¸“é—¨çš„Agent
research_agent = initialize_agent(
    [search_tool, wikipedia_tool],
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION
)

analysis_agent = initialize_agent(
    [calculator_tool, db_tool],
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION
)

# ä¸»Agentåè°ƒå­Agent
master_tools = [
    Tool(
        name="Research",
        func=research_agent.run,
        description="ç”¨äºç ”ç©¶å’Œæœç´¢ä¿¡æ¯"
    ),
    Tool(
        name="Analysis",
        func=analysis_agent.run,
        description="ç”¨äºæ•°æ®åˆ†æå’Œè®¡ç®—"
    )
]

master_agent = initialize_agent(
    master_tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION
)
```

**LangChain Agentç±»å‹å¯¹æ¯”**ï¼š

| Agentç±»å‹ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|----------|------|---------|
| **Zero-shot ReAct** | æ— éœ€ç¤ºä¾‹ï¼Œæ ¹æ®å·¥å…·æè¿°å†³ç­– | é€šç”¨åœºæ™¯ï¼Œæœ€å¸¸ç”¨ |
| **Conversational** | å¸¦å¯¹è¯å†å²è®°å¿† | å¤šè½®å¯¹è¯åœºæ™¯ |
| **Structured** | æ”¯æŒç»“æ„åŒ–è¾“å…¥çš„å·¥å…· | å¤æ‚å·¥å…·å‚æ•° |
| **Self-ask with Search** | åˆ†è§£é—®é¢˜ï¼Œé€æ­¥æœç´¢ | å¤æ‚æ¨ç†é—®é¢˜ |
| **Plan-and-Execute** | å…ˆè§„åˆ’å†æ‰§è¡Œ | å¤æ‚å¤šæ­¥ä»»åŠ¡ |

---

#### LlamaIndexï¼šâ­â­â­

LlamaIndex çš„ Agent åŠŸèƒ½ç›¸å¯¹ç®€å•ï¼Œä¸»è¦å›´ç»•æŸ¥è¯¢å¼•æ“ï¼š

```python
from llama_index.agent import OpenAIAgent
from llama_index.tools import QueryEngineTool, ToolMetadata

# 1. å°†æŸ¥è¯¢å¼•æ“åŒ…è£…æˆå·¥å…·
query_engine_tools = [
    QueryEngineTool(
        query_engine=tech_index.as_query_engine(),
        metadata=ToolMetadata(
            name="tech_docs",
            description="æŸ¥è¯¢æŠ€æœ¯æ–‡æ¡£ï¼ŒåŒ…å«APIã€æ¶æ„ã€å¼€å‘æŒ‡å—"
        )
    ),
    QueryEngineTool(
        query_engine=business_index.as_query_engine(),
        metadata=ToolMetadata(
            name="business_docs",
            description="æŸ¥è¯¢ä¸šåŠ¡æ–‡æ¡£ï¼ŒåŒ…å«éœ€æ±‚ã€æµç¨‹ã€è§„èŒƒ"
        )
    )
]

# 2. åˆ›å»ºAgent
agent = OpenAIAgent.from_tools(
    query_engine_tools,
    verbose=True
)

# 3. ä½¿ç”¨
response = agent.chat("æŠ€æœ¯æ–‡æ¡£ä¸­å…³äºAPIè®¤è¯çš„æè¿°æ˜¯ä»€ä¹ˆï¼Ÿ")
```

**å¯¹æ¯”ç»“è®º**ï¼š
- ğŸ¯ **Agentèƒ½åŠ›**ï¼šLangChain å®Œèƒœï¼ˆç±»å‹å¤šã€å·¥å…·ä¸°å¯Œã€Multi-Agentï¼‰
- ğŸ¯ **ç®€å•åœºæ™¯**ï¼šLlamaIndex å¤Ÿç”¨ï¼ˆä¸“æ³¨äºçŸ¥è¯†æ£€ç´¢ï¼‰

---

### 3.5 æ•°æ®æºæ”¯æŒ

#### LlamaIndexï¼š180+ Data Loaders

```python
# å¸¸ç”¨æ•°æ®åŠ è½½å™¨
from llama_index import (
    SimpleDirectoryReader,  # ç›®å½•åŠ è½½
    download_loader          # ä¸‹è½½ç‰¹å®šåŠ è½½å™¨
)

# 1. åŸºç¡€æ–‡ä»¶åŠ è½½
documents = SimpleDirectoryReader('data').load_data()

# 2. ç‰¹å®šæ ¼å¼åŠ è½½å™¨
PDFReader = download_loader("PDFReader")
pdf_docs = PDFReader().load_data(file='document.pdf')

DatabaseReader = download_loader("DatabaseReader")
db_docs = DatabaseReader(sql_database=db).load_data()

NotionReader = download_loader("NotionPageReader")
notion_docs = NotionReader(integration_token=token).load_data()

# 3. æ”¯æŒçš„æ•°æ®æºï¼ˆéƒ¨åˆ†ï¼‰
"""
æ–‡æ¡£æ ¼å¼ï¼šPDF, DOCX, PPTX, XLSX, Markdown, HTML, TXT
æ•°æ®åº“ï¼šMySQL, PostgreSQL, MongoDB, Redis
äº‘å­˜å‚¨ï¼šGoogle Drive, OneDrive, Dropbox, S3
çŸ¥è¯†ç®¡ç†ï¼šNotion, Confluence, Obsidian
ç½‘é¡µï¼šBeautiful Soup, Selenium
å…¶ä»–ï¼šSlack, Discord, Twitter, YouTube, GitHub
"""
```

#### LangChainï¼š100+ Document Loaders

```python
from langchain.document_loaders import (
    PyPDFLoader,           # PDF
    Docx2txtLoader,        # Word
    TextLoader,            # æ–‡æœ¬
    CSVLoader,             # CSV
    UnstructuredHTMLLoader,# HTML
    WebBaseLoader,         # ç½‘é¡µ
    GitLoader,             # Gitä»“åº“
    NotionDBLoader,        # Notion
)

# ä½¿ç”¨ç¤ºä¾‹
loader = PyPDFLoader("document.pdf")
documents = loader.load()
```

**å¯¹æ¯”ç»“è®º**ï¼š
- ğŸ¯ **æ•°æ®æºæ•°é‡**ï¼šLlamaIndex èƒœå‡ºï¼ˆ180+ vs 100+ï¼‰
- ğŸ¯ **æ˜“ç”¨æ€§**ï¼šLlamaIndex èƒœå‡ºï¼ˆç»Ÿä¸€çš„ä¸‹è½½æ¥å£ï¼‰

---

## å››ã€æ€§èƒ½å¯¹æ¯”

### 4.1 æŸ¥è¯¢é€Ÿåº¦æµ‹è¯•

åŸºäº10MBæ–‡æ¡£åº“çš„æµ‹è¯•ç»“æœï¼š

| æŒ‡æ ‡ | LlamaIndex | LangChain | è¯´æ˜ |
|------|-----------|-----------|------|
| **ç´¢å¼•æ„å»ºæ—¶é—´** | 15ç§’ | 22ç§’ | LlamaIndexæ›´å¿« |
| **ç®€å•æŸ¥è¯¢å»¶è¿Ÿ** | 1.2ç§’ | 1.5ç§’ | LlamaIndexç•¥å¿« |
| **å¤æ‚æŸ¥è¯¢å»¶è¿Ÿ** | 2.8ç§’ | 3.2ç§’ | LlamaIndexç•¥å¿« |
| **å†…å­˜å ç”¨** | 180MB | 250MB | LlamaIndexæ›´çœå†…å­˜ |
| **åˆå§‹åŒ–æ—¶é—´** | 0.8ç§’ | 1.5ç§’ | LlamaIndexæ›´å¿« |

> æ³¨ï¼šä»¥ä¸Šæ•°æ®ä»…ä¾›å‚è€ƒï¼Œå®é™…æ€§èƒ½å–å†³äºå…·ä½“é…ç½®å’Œä½¿ç”¨åœºæ™¯

### 4.2 æ€§èƒ½ä¼˜åŒ–å»ºè®®

**LlamaIndexä¼˜åŒ–**ï¼š
```python
# 1. ä½¿ç”¨æŒä¹…åŒ–å­˜å‚¨ï¼ˆé¿å…é‡å¤æ„å»ºç´¢å¼•ï¼‰
from llama_index.storage.storage_context import StorageContext
from llama_index.vector_stores import ChromaVectorStore
import chromadb

db = chromadb.PersistentClient(path="./chroma_db")
chroma_collection = db.get_or_create_collection("my_collection")
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
storage_context = StorageContext.from_defaults(vector_store=vector_store)

index = VectorStoreIndex.from_documents(
    documents,
    storage_context=storage_context
)

# 2. è°ƒæ•´æ£€ç´¢å‚æ•°
query_engine = index.as_query_engine(
    similarity_top_k=3,      # å‡å°‘å¬å›æ•°é‡
    response_mode="compact"   # ä½¿ç”¨ç´§å‡‘æ¨¡å¼
)

# 3. ä½¿ç”¨ç¼“å­˜
from llama_index.cache import SimpleCache
cache = SimpleCache()
query_engine = index.as_query_engine(cache=cache)
```

**LangChainä¼˜åŒ–**ï¼š
```python
# 1. ä½¿ç”¨æ›´å¿«çš„å‘é‡æ•°æ®åº“
from langchain.vectorstores import FAISS  # æ¯”Chromaæ›´å¿«

# 2. å‡å°‘chunkæ•°é‡
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,  # å¢å¤§chunk_size
    chunk_overlap=100
)

# 3. ä½¿ç”¨ç¼“å­˜
from langchain.cache import InMemoryCache
import langchain
langchain.llm_cache = InMemoryCache()
```

---

## äº”ã€é€‚ç”¨åœºæ™¯è¯¦è§£

### 5.1 é€‰æ‹©LlamaIndexçš„åœºæ™¯

#### âœ… åœºæ™¯1ï¼šä¼ä¸šçŸ¥è¯†åº“é—®ç­”

**éœ€æ±‚ç‰¹ç‚¹**ï¼š
- ä¸»è¦æ˜¯æ–‡æ¡£æ£€ç´¢å’Œé—®ç­”
- éœ€è¦å¿«é€Ÿä¸Šçº¿
- å›¢é˜ŸLLMç»éªŒæœ‰é™

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from llama_index import VectorStoreIndex, SimpleDirectoryReader
from llama_index.storage.storage_context import StorageContext
from llama_index.vector_stores import ChromaVectorStore
import chromadb

# 1. åŠ è½½å…¬å¸æ–‡æ¡£
documents = SimpleDirectoryReader(
    input_dir='company_docs',
    recursive=True,
    required_exts=[".pdf", ".docx", ".md"]
).load_data()

# 2. æŒä¹…åŒ–å­˜å‚¨
db = chromadb.PersistentClient(path="./company_kb")
chroma_collection = db.get_or_create_collection("knowledge_base")
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
storage_context = StorageContext.from_defaults(vector_store=vector_store)

# 3. åˆ›å»ºç´¢å¼•
index = VectorStoreIndex.from_documents(
    documents,
    storage_context=storage_context,
    show_progress=True
)

# 4. åˆ›å»ºæŸ¥è¯¢å¼•æ“
query_engine = index.as_query_engine(
    similarity_top_k=5,
    response_mode="tree_summarize"  # é€‚åˆé•¿æ–‡æ¡£
)

# 5. å¯¹å¤–æä¾›API
def ask(question: str) -> str:
    response = query_engine.query(question)
    return str(response)

# ä½¿ç”¨
print(ask("å…¬å¸çš„å¹´å‡æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ"))
print(ask("å¦‚ä½•ç”³è¯·è°ƒä¼‘ï¼Ÿ"))
```

**ä¼˜åŠ¿**ï¼š
- ä»£ç ç®€æ´ï¼Œæ˜“äºç»´æŠ¤
- å¼€ç®±å³ç”¨ï¼Œæ— éœ€å¤æ‚é…ç½®
- æ€§èƒ½ä¼˜ç§€

---

#### âœ… åœºæ™¯2ï¼šå­¦æœ¯è®ºæ–‡é—®ç­”ç³»ç»Ÿ

**éœ€æ±‚ç‰¹ç‚¹**ï¼š
- éœ€è¦å¤„ç†PDFæ ¼å¼
- éœ€è¦å¼•ç”¨æ¥æº
- éœ€è¦å¤šå±‚æ¬¡æ£€ç´¢

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from llama_index import VectorStoreIndex, SimpleDirectoryReader
from llama_index.response.schema import Response

# 1. åŠ è½½å­¦æœ¯è®ºæ–‡
documents = SimpleDirectoryReader(
    input_dir='papers',
    required_exts=[".pdf"]
).load_data()

# 2. åˆ›å»ºç´¢å¼•
index = VectorStoreIndex.from_documents(documents)

# 3. åˆ›å»ºæŸ¥è¯¢å¼•æ“ï¼ˆå¸¦æ¥æºå¼•ç”¨ï¼‰
query_engine = index.as_query_engine(
    response_mode="tree_summarize",
    verbose=True
)

# 4. æŸ¥è¯¢å¹¶è·å–æ¥æº
response: Response = query_engine.query(
    "æ·±åº¦å­¦ä¹ åœ¨NLPä¸­çš„æœ€æ–°è¿›å±•æ˜¯ä»€ä¹ˆï¼Ÿ"
)

print("å›ç­”:", response.response)
print("\næ¥æº:")
for node in response.source_nodes:
    print(f"- {node.node.metadata['file_name']}: {node.node.text[:100]}...")
    print(f"  ç›¸ä¼¼åº¦: {node.score:.2f}")
```

---

#### âœ… åœºæ™¯3ï¼šå¤šæ•°æ®æºæ™ºèƒ½è·¯ç”±

**éœ€æ±‚ç‰¹ç‚¹**ï¼š
- æœ‰å¤šä¸ªçŸ¥è¯†åº“ï¼ˆæŠ€æœ¯ã€ä¸šåŠ¡ã€HRç­‰ï¼‰
- éœ€è¦è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ•°æ®æº
- éœ€è¦å¤„ç†è·¨æ•°æ®æºçš„å¤æ‚æŸ¥è¯¢

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from llama_index import VectorStoreIndex, SimpleDirectoryReader
from llama_index.tools import QueryEngineTool, ToolMetadata
from llama_index.query_engine import SubQuestionQueryEngine
from llama_index.llms import OpenAI

# 1. åˆ›å»ºå¤šä¸ªæ•°æ®æºçš„ç´¢å¼•
tech_docs = SimpleDirectoryReader('docs/tech').load_data()
tech_index = VectorStoreIndex.from_documents(tech_docs)

business_docs = SimpleDirectoryReader('docs/business').load_data()
business_index = VectorStoreIndex.from_documents(business_docs)

hr_docs = SimpleDirectoryReader('docs/hr').load_data()
hr_index = VectorStoreIndex.from_documents(hr_docs)

# 2. åˆ›å»ºæŸ¥è¯¢å¼•æ“å·¥å…·
query_engine_tools = [
    QueryEngineTool(
        query_engine=tech_index.as_query_engine(),
        metadata=ToolMetadata(
            name="tech_docs",
            description="æŠ€æœ¯æ–‡æ¡£ï¼ŒåŒ…å«APIã€æ¶æ„è®¾è®¡ã€å¼€å‘è§„èŒƒ"
        )
    ),
    QueryEngineTool(
        query_engine=business_index.as_query_engine(),
        metadata=ToolMetadata(
            name="business_docs",
            description="ä¸šåŠ¡æ–‡æ¡£ï¼ŒåŒ…å«äº§å“éœ€æ±‚ã€ä¸šåŠ¡æµç¨‹"
        )
    ),
    QueryEngineTool(
        query_engine=hr_index.as_query_engine(),
        metadata=ToolMetadata(
            name="hr_docs",
            description="äººåŠ›èµ„æºæ–‡æ¡£ï¼ŒåŒ…å«è€ƒå‹¤ã€è–ªé…¬ã€ç¦åˆ©æ”¿ç­–"
        )
    )
]

# 3. åˆ›å»ºå­é—®é¢˜æŸ¥è¯¢å¼•æ“ï¼ˆè‡ªåŠ¨è·¯ç”±+é—®é¢˜åˆ†è§£ï¼‰
sub_query_engine = SubQuestionQueryEngine.from_defaults(
    query_engine_tools=query_engine_tools,
    llm=OpenAI(model="gpt-4")
)

# 4. ä½¿ç”¨
response = sub_query_engine.query(
    "æˆ‘ä»¬çš„APIè®¤è¯æœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿè¿™ä¸ªæœºåˆ¶åœ¨ä¸šåŠ¡æµç¨‹ä¸­å¦‚ä½•ä½“ç°ï¼Ÿ"
)
# ä¼šè‡ªåŠ¨åˆ†è§£ä¸ºï¼š
# - å­é—®é¢˜1: APIè®¤è¯æœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿ -> æŸ¥è¯¢ tech_docs
# - å­é—®é¢˜2: ä¸šåŠ¡æµç¨‹ä¸­å¦‚ä½•ä½¿ç”¨è®¤è¯ï¼Ÿ -> æŸ¥è¯¢ business_docs
# æœ€åç»¼åˆç­”æ¡ˆ

print(response)
```

---

### 5.2 é€‰æ‹©LangChainçš„åœºæ™¯

#### âœ… åœºæ™¯1ï¼šæ™ºèƒ½å®¢æœï¼ˆå¸¦å·¥å•ç³»ç»Ÿï¼‰

**éœ€æ±‚ç‰¹ç‚¹**ï¼š
- éœ€è¦è°ƒç”¨å¤šä¸ªå¤–éƒ¨ç³»ç»Ÿï¼ˆçŸ¥è¯†åº“ã€å·¥å•ã€CRMï¼‰
- éœ€è¦Agentè‡ªä¸»å†³ç­–
- éœ€è¦å¤æ‚çš„å·¥ä½œæµ

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
import requests

# 1. çŸ¥è¯†åº“å·¥å…·
vectorstore = Chroma(
    persist_directory="./kb",
    embedding_function=OpenAIEmbeddings()
)

def query_kb(question: str) -> str:
    docs = vectorstore.similarity_search(question, k=3)
    return "\n".join([doc.page_content for doc in docs])

# 2. å·¥å•ç³»ç»Ÿå·¥å…·
def create_ticket(description: str) -> str:
    # è°ƒç”¨å·¥å•ç³»ç»ŸAPI
    response = requests.post(
        "https://ticket-system.com/api/tickets",
        json={"description": description, "priority": "normal"}
    )
    return f"å·²åˆ›å»ºå·¥å•#{response.json()['ticket_id']}"

def query_ticket(ticket_id: str) -> str:
    # æŸ¥è¯¢å·¥å•çŠ¶æ€
    response = requests.get(f"https://ticket-system.com/api/tickets/{ticket_id}")
    return f"å·¥å•çŠ¶æ€: {response.json()['status']}"

# 3. CRMå·¥å…·
def query_customer_info(customer_id: str) -> str:
    # æŸ¥è¯¢å®¢æˆ·ä¿¡æ¯
    response = requests.get(f"https://crm.com/api/customers/{customer_id}")
    return f"å®¢æˆ·ç­‰çº§: {response.json()['level']}"

# 4. å®šä¹‰å·¥å…·åˆ—è¡¨
tools = [
    Tool(
        name="KnowledgeBase",
        func=query_kb,
        description="æŸ¥è¯¢çŸ¥è¯†åº“ï¼Œè§£ç­”å¸¸è§é—®é¢˜ã€‚è¾“å…¥åº”è¯¥æ˜¯ç”¨æˆ·çš„é—®é¢˜ã€‚"
    ),
    Tool(
        name="CreateTicket",
        func=create_ticket,
        description="åˆ›å»ºå·¥å•ï¼Œç”¨äºéœ€è¦äººå·¥å¤„ç†çš„å¤æ‚é—®é¢˜ã€‚è¾“å…¥åº”è¯¥æ˜¯é—®é¢˜æè¿°ã€‚"
    ),
    Tool(
        name="QueryTicket",
        func=query_ticket,
        description="æŸ¥è¯¢å·¥å•çŠ¶æ€ã€‚è¾“å…¥åº”è¯¥æ˜¯å·¥å•IDã€‚"
    ),
    Tool(
        name="CustomerInfo",
        func=query_customer_info,
        description="æŸ¥è¯¢å®¢æˆ·ä¿¡æ¯å’Œç­‰çº§ã€‚è¾“å…¥åº”è¯¥æ˜¯å®¢æˆ·IDã€‚"
    )
]

# 5. åˆ›å»ºå¸¦è®°å¿†çš„Agent
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
llm = ChatOpenAI(temperature=0, model="gpt-4")

agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
    memory=memory,
    verbose=True
)

# 6. ä½¿ç”¨ç¤ºä¾‹
# å¯¹è¯1
response1 = agent.run("æˆ‘çš„è´¦å·ç™»å½•ä¸ä¸Šäº†ï¼Œç”¨æˆ·IDæ˜¯12345")
# Agentæ€è€ƒè¿‡ç¨‹ï¼š
# 1. å…ˆæŸ¥è¯¢å®¢æˆ·ä¿¡æ¯ -> å‘ç°æ˜¯VIPå®¢æˆ·
# 2. æŸ¥è¯¢çŸ¥è¯†åº“ -> æ‰¾åˆ°å¸¸è§çš„ç™»å½•é—®é¢˜è§£å†³æ–¹æ¡ˆ
# 3. å¦‚æœçŸ¥è¯†åº“æ²¡æœ‰è§£å†³ -> åˆ›å»ºé«˜ä¼˜å…ˆçº§å·¥å•

# å¯¹è¯2ï¼ˆè®°ä½ä¸Šä¸‹æ–‡ï¼‰
response2 = agent.run("å·¥å•å¤„ç†å¾—æ€ä¹ˆæ ·äº†ï¼Ÿ")
# Agentä¼šè®°ä½ä¹‹å‰åˆ›å»ºçš„å·¥å•IDï¼Œè‡ªåŠ¨æŸ¥è¯¢çŠ¶æ€
```

**ä¼˜åŠ¿**ï¼š
- Agentå¯ä»¥æ ¹æ®æƒ…å†µè‡ªä¸»é€‰æ‹©å·¥å…·
- å¤šè½®å¯¹è¯æœ‰è®°å¿†
- çµæ´»æ‰©å±•æ–°å·¥å…·

---

#### âœ… åœºæ™¯2ï¼šç ”ç©¶åŠ©æ‰‹ï¼ˆè”ç½‘æœç´¢+è®ºæ–‡åˆ†æï¼‰

**éœ€æ±‚ç‰¹ç‚¹**ï¼š
- éœ€è¦æœç´¢æœ€æ–°ä¿¡æ¯
- éœ€è¦é˜…è¯»å’Œåˆ†ææ–‡æ¡£
- éœ€è¦æ‰§è¡Œè®¡ç®—
- éœ€è¦å¤šæ­¥æ¨ç†

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.chat_models import ChatOpenAI
from langchain.utilities import SerpAPIWrapper, WikipediaAPIWrapper
from langchain.chains import LLMMathChain
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

# 1. åˆå§‹åŒ–åŸºç¡€å·¥å…·
search = SerpAPIWrapper()
wikipedia = WikipediaAPIWrapper()
llm = ChatOpenAI(temperature=0, model="gpt-4")
math_chain = LLMMathChain.from_llm(llm)

# 2. è®ºæ–‡åˆ†æå·¥å…·
def analyze_paper(pdf_path: str) -> str:
    """åŠ è½½å¹¶åˆ†æè®ºæ–‡"""
    loader = PyPDFLoader(pdf_path)
    documents = loader.load()

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)
    splits = text_splitter.split_documents(documents)

    vectorstore = FAISS.from_documents(splits, OpenAIEmbeddings())

    # æå–å…³é”®ä¿¡æ¯
    summary_query = "è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ"
    docs = vectorstore.similarity_search(summary_query, k=3)

    summary_prompt = f"æ ¹æ®ä»¥ä¸‹å†…å®¹ï¼Œæ€»ç»“è®ºæ–‡çš„æ ¸å¿ƒè§‚ç‚¹ï¼š\n\n{docs[0].page_content}"
    summary = llm.predict(summary_prompt)

    return summary

# 3. å®šä¹‰å·¥å…·
tools = [
    Tool(
        name="Search",
        func=search.run,
        description="æœç´¢äº’è”ç½‘è·å–æœ€æ–°ä¿¡æ¯ã€‚è¾“å…¥ï¼šæœç´¢æŸ¥è¯¢ã€‚"
    ),
    Tool(
        name="Wikipedia",
        func=wikipedia.run,
        description="æŸ¥è¯¢ç»´åŸºç™¾ç§‘è·å–èƒŒæ™¯çŸ¥è¯†ã€‚è¾“å…¥ï¼šæœç´¢è¯ã€‚"
    ),
    Tool(
        name="Calculator",
        func=math_chain.run,
        description="æ‰§è¡Œæ•°å­¦è®¡ç®—ã€‚è¾“å…¥ï¼šæ•°å­¦è¡¨è¾¾å¼ã€‚"
    ),
    Tool(
        name="PaperAnalyzer",
        func=analyze_paper,
        description="åˆ†æPDFè®ºæ–‡ã€‚è¾“å…¥ï¼šPDFæ–‡ä»¶è·¯å¾„ã€‚"
    )
]

# 4. åˆ›å»ºAgent
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# 5. å¤æ‚ç ”ç©¶ä»»åŠ¡
response = agent.run("""
è¯·å¸®æˆ‘å®Œæˆä»¥ä¸‹ç ”ç©¶ä»»åŠ¡ï¼š
1. æœç´¢2024å¹´Transformeræ¶æ„çš„æœ€æ–°æ”¹è¿›
2. åˆ†æè®ºæ–‡ 'paper.pdf' çš„æ ¸å¿ƒåˆ›æ–°
3. æ¯”è¾ƒè¿™ç¯‡è®ºæ–‡å’Œæœ€æ–°ç ”ç©¶çš„å…³ç³»
4. å¦‚æœè®ºæ–‡ä¸­æåˆ°äº†æ€§èƒ½æå‡ç™¾åˆ†æ¯”ï¼Œè®¡ç®—å…·ä½“çš„æå‡å€¼
""")

# Agentä¼šè‡ªåŠ¨ï¼š
# 1. ä½¿ç”¨Searchæœç´¢æœ€æ–°ç ”ç©¶
# 2. ä½¿ç”¨PaperAnalyzeråˆ†æè®ºæ–‡
# 3. ä½¿ç”¨Wikipediaè¡¥å……èƒŒæ™¯çŸ¥è¯†
# 4. ä½¿ç”¨Calculatorè¿›è¡Œè®¡ç®—
# 5. ç»¼åˆæ‰€æœ‰ä¿¡æ¯ç»™å‡ºç­”æ¡ˆ
```

---

#### âœ… åœºæ™¯3ï¼šæ•°æ®åˆ†æåŠ©æ‰‹

**éœ€æ±‚ç‰¹ç‚¹**ï¼š
- éœ€è¦æŸ¥è¯¢æ•°æ®åº“
- éœ€è¦æ‰§è¡Œæ•°æ®åˆ†æ
- éœ€è¦ç”Ÿæˆå¯è§†åŒ–
- éœ€è¦è§£é‡Šç»“æœ

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from langchain.agents import create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.sql_database import SQLDatabase
from langchain.chat_models import ChatOpenAI
from langchain.agents import AgentType
import pandas as pd
import matplotlib.pyplot as plt

# 1. è¿æ¥æ•°æ®åº“
db = SQLDatabase.from_uri("sqlite:///sales.db")

# 2. åˆ›å»ºSQLå·¥å…·åŒ…
toolkit = SQLDatabaseToolkit(db=db, llm=ChatOpenAI(temperature=0))

# 3. æ•°æ®å¯è§†åŒ–å·¥å…·
def create_chart(query: str) -> str:
    """æ‰§è¡ŒSQLæŸ¥è¯¢å¹¶ç”Ÿæˆå›¾è¡¨"""
    df = pd.read_sql_query(query, db._engine)

    plt.figure(figsize=(10, 6))
    df.plot(kind='bar')
    plt.savefig('chart.png')

    return "å›¾è¡¨å·²ç”Ÿæˆ: chart.png"

# 4. åˆ›å»ºSQL Agent
agent = create_sql_agent(
    llm=ChatOpenAI(temperature=0, model="gpt-4"),
    toolkit=toolkit,
    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# 5. è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ•°æ®åº“
response = agent.run("""
è¯·å¸®æˆ‘åˆ†æé”€å”®æ•°æ®ï¼š
1. æŸ¥è¯¢2024å¹´æ¯ä¸ªæœˆçš„é”€å”®é¢
2. æ‰¾å‡ºé”€å”®é¢æœ€é«˜çš„äº§å“ç±»åˆ«
3. è®¡ç®—åŒæ¯”å¢é•¿ç‡
4. æ€»ç»“å…³é”®å‘ç°
""")

# Agentä¼šè‡ªåŠ¨ï¼š
# 1. ç†è§£æ•°æ®åº“ç»“æ„
# 2. ç”ŸæˆSQLæŸ¥è¯¢
# 3. æ‰§è¡ŒæŸ¥è¯¢
# 4. åˆ†æç»“æœ
# 5. ç”Ÿæˆè‡ªç„¶è¯­è¨€æŠ¥å‘Š
```

---

### 5.3 ä¸¤è€…ç»“åˆä½¿ç”¨

æœ€ä½³å®è·µæ˜¯ç»“åˆä¸¤è€…çš„ä¼˜åŠ¿ï¼š

```python
from llama_index import VectorStoreIndex, SimpleDirectoryReader
from langchain.agents import initialize_agent, Tool
from langchain.chat_models import ChatOpenAI
from langchain.utilities import SerpAPIWrapper

# 1. ä½¿ç”¨LlamaIndexæ„å»ºå¼ºå¤§çš„çŸ¥è¯†åº“
documents = SimpleDirectoryReader('company_docs').load_data()
index = VectorStoreIndex.from_documents(documents)
query_engine = index.as_query_engine()

# 2. å°†LlamaIndexåŒ…è£…æˆLangChainå·¥å…·
def query_knowledge_base(question: str) -> str:
    response = query_engine.query(question)
    return str(response)

kb_tool = Tool(
    name="CompanyKnowledgeBase",
    func=query_knowledge_base,
    description="æŸ¥è¯¢å…¬å¸å†…éƒ¨çŸ¥è¯†åº“ï¼ŒåŒ…å«æ”¿ç­–ã€è§„èŒƒã€æŠ€æœ¯æ–‡æ¡£ã€‚"
)

# 3. æ·»åŠ å…¶ä»–LangChainå·¥å…·
search = SerpAPIWrapper()
search_tool = Tool(
    name="InternetSearch",
    func=search.run,
    description="æœç´¢äº’è”ç½‘è·å–å…¬å¼€ä¿¡æ¯å’Œæœ€æ–°åŠ¨æ€ã€‚"
)

# 4. åˆ›å»ºLangChain Agent
llm = ChatOpenAI(model="gpt-4")
agent = initialize_agent(
    [kb_tool, search_tool],
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# 5. Agentå¯ä»¥æ™ºèƒ½å†³ç­–
response = agent.run("""
æˆ‘ä»¬å…¬å¸çš„è¿œç¨‹åŠå…¬æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ
è¿™ä¸ªæ”¿ç­–å’Œè¡Œä¸šå†…å…¶ä»–å…¬å¸ç›¸æ¯”å¦‚ä½•ï¼Ÿ
""")

# Agentä¼šï¼š
# 1. å…ˆä»å…¬å¸çŸ¥è¯†åº“æŸ¥è¯¢å†…éƒ¨æ”¿ç­–ï¼ˆä½¿ç”¨LlamaIndexï¼‰
# 2. å†ä¸Šç½‘æœç´¢å…¶ä»–å…¬å¸çš„æ”¿ç­–ï¼ˆä½¿ç”¨Searchï¼‰
# 3. ç»¼åˆæ¯”è¾ƒå¹¶ç»™å‡ºç­”æ¡ˆ

# è¿™æ ·å°±ç»“åˆäº†ï¼š
# - LlamaIndexçš„å¼ºå¤§æ£€ç´¢èƒ½åŠ›
# - LangChainçš„çµæ´»å†³ç­–èƒ½åŠ›
```

**ç»“åˆä½¿ç”¨çš„ä¼˜åŠ¿**ï¼š
- âœ… LlamaIndexå¤„ç†å†…éƒ¨çŸ¥è¯†æ£€ç´¢ï¼ˆå¿«é€Ÿã€å‡†ç¡®ï¼‰
- âœ… LangChainå¤„ç†å¤æ‚å†³ç­–å’Œå¤–éƒ¨å·¥å…·è°ƒç”¨ï¼ˆçµæ´»ã€å¼ºå¤§ï¼‰
- âœ… å‘æŒ¥å„è‡ªæ‰€é•¿ï¼Œæ„å»ºæ›´å¼ºå¤§çš„ç³»ç»Ÿ

---

## å…­ã€ç”Ÿæ€ç³»ç»Ÿå¯¹æ¯”

### 6.1 é›†æˆæ•°é‡

| ç±»åˆ« | LlamaIndex | LangChain |
|------|-----------|-----------|
| **æ•°æ®åŠ è½½å™¨** | 180+ | 100+ |
| **å‘é‡æ•°æ®åº“** | 20+ | 30+ |
| **LLMæä¾›å•†** | 10+ | 30+ |
| **å·¥å…·é›†æˆ** | 50+ | 200+ |
| **æ€»é›†æˆæ•°** | ~260 | ~360 |

### 6.2 ç¤¾åŒºå¯¹æ¯”

| æŒ‡æ ‡ | LlamaIndex | LangChain |
|------|-----------|-----------|
| **GitHub Stars** | 30k+ | 80k+ |
| **Contributors** | 300+ | 1500+ |
| **Discordæˆå‘˜** | 15k+ | 40k+ |
| **æ›´æ–°é¢‘ç‡** | æ¯å‘¨å¤šæ¬¡ | æ¯å¤©å¤šæ¬¡ |
| **Issueå“åº”** | 1-2å¤© | 1å¤©å†… |

### 6.3 ä¼ä¸šæ”¯æŒ

**LlamaIndex**ï¼š
- æä¾›ä¼ä¸šç‰ˆï¼ˆLlamaCloudï¼‰
- æ‰˜ç®¡æœåŠ¡
- æŠ€æœ¯æ”¯æŒ

**LangChain**ï¼š
- LangSmithï¼ˆç›‘æ§å’Œè°ƒè¯•å¹³å°ï¼‰
- LangServeï¼ˆéƒ¨ç½²æ¡†æ¶ï¼‰
- ä¼ä¸šæ”¯æŒè®¡åˆ’

---

## ä¸ƒã€å­¦ä¹ èµ„æº

### 7.1 LlamaIndexå­¦ä¹ è·¯å¾„

**å®˜æ–¹èµ„æº**ï¼š
- ğŸ“š [å®˜æ–¹æ–‡æ¡£](https://docs.llamaindex.ai/)
- ğŸ’» [GitHubä»“åº“](https://github.com/run-llama/llama_index)
- ğŸ“ [ç¤ºä¾‹é¡¹ç›®](https://github.com/run-llama/llama_index/tree/main/docs/examples)

**å­¦ä¹ å»ºè®®**ï¼š
1. **ç¬¬1å‘¨**ï¼šç†è§£ç´¢å¼•æ¦‚å¿µï¼Œè¿è¡ŒåŸºç¡€ç¤ºä¾‹
2. **ç¬¬2å‘¨**ï¼šå­¦ä¹ ä¸åŒç´¢å¼•ç±»å‹å’ŒæŸ¥è¯¢æ¨¡å¼
3. **ç¬¬3å‘¨**ï¼šå®æˆ˜é¡¹ç›®ï¼šæ„å»ºçŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ
4. **ç¬¬4å‘¨**ï¼šä¼˜åŒ–å’Œéƒ¨ç½²

---

### 7.2 LangChainå­¦ä¹ è·¯å¾„

**å®˜æ–¹èµ„æº**ï¼š
- ğŸ“š [å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)
- ğŸ’» [GitHubä»“åº“](https://github.com/langchain-ai/langchain)
- ğŸ“ [LangChain Academy](https://academy.langchain.com/)

**å­¦ä¹ å»ºè®®**ï¼š
1. **ç¬¬1-2å‘¨**ï¼šModelsã€Promptsã€ChainsåŸºç¡€
2. **ç¬¬3-4å‘¨**ï¼šMemoryã€Toolsã€Agents
3. **ç¬¬5-6å‘¨**ï¼šRAGç³»ç»Ÿã€å‘é‡æ•°æ®åº“
4. **ç¬¬7-8å‘¨**ï¼šå®æˆ˜é¡¹ç›®ï¼šæ„å»ºæ™ºèƒ½åŠ©æ‰‹

**æ¨èé˜…è¯»**ï¼š
- æœ¬åšå®¢çš„ [LangChainå®Œæ•´å­¦ä¹ æŒ‡å—](./README.md)ï¼ˆ16å‘¨ç³»ç»Ÿè¯¾ç¨‹ï¼‰

---

## å…«ã€å†³ç­–çŸ©é˜µ

### 8.1 å¿«é€Ÿå†³ç­–è¡¨

| ä½ çš„éœ€æ±‚ | æ¨èæ¡†æ¶ | ç†ç”± |
|---------|---------|------|
| ç®€å•çš„æ–‡æ¡£é—®ç­” | LlamaIndex â­â­â­â­â­ | ä»£ç ç®€æ´ï¼Œå¿«é€Ÿä¸Šçº¿ |
| ä¼ä¸šçŸ¥è¯†åº“ | LlamaIndex â­â­â­â­â­ | ä¸“æ³¨æ£€ç´¢ï¼Œæ€§èƒ½ä¼˜ç§€ |
| éœ€è¦Agentå†³ç­– | LangChain â­â­â­â­â­ | Agentèƒ½åŠ›å¼ºå¤§ |
| å¤šå·¥å…·é›†æˆ | LangChain â­â­â­â­â­ | å·¥å…·ç”Ÿæ€ä¸°å¯Œ |
| å¤æ‚å·¥ä½œæµ | LangChain â­â­â­â­â­ | çµæ´»çš„Chainç»„åˆ |
| å¿«é€ŸåŸå‹ | LlamaIndex â­â­â­â­â­ | å¼€ç®±å³ç”¨ |
| å­¦æœ¯ç ”ç©¶ | LlamaIndex â­â­â­â­ | å¤šç§ç´¢å¼•ç±»å‹ |
| æ•°æ®åˆ†æ | LangChain â­â­â­â­â­ | SQL Agentå¼ºå¤§ |
| å®¢æœç³»ç»Ÿ | LangChain + LlamaIndex | ç»“åˆä½¿ç”¨æœ€ä½³ |

### 8.2 å›¢é˜ŸæŠ€èƒ½çŸ©é˜µ

| å›¢é˜Ÿç‰¹ç‚¹ | æ¨è | è¯´æ˜ |
|---------|------|------|
| **Pythonåˆå­¦è€…** | LlamaIndex | APIæ›´ç®€å• |
| **æœ‰LLMç»éªŒ** | ä¸¤è€…éƒ½å¯ | æ ¹æ®éœ€æ±‚é€‰æ‹© |
| **å‰ç«¯å¼€å‘è€…** | LlamaIndex | æ›´å®¹æ˜“ä¸Šæ‰‹ |
| **å…¨æ ˆå·¥ç¨‹å¸ˆ** | LangChain | èƒ½é©¾é©­å¤æ‚æ€§ |
| **æ•°æ®ç§‘å­¦å®¶** | LangChain | SQLã€åˆ†æå·¥å…·ä¸°å¯Œ |
| **ç ”ç©¶äººå‘˜** | LlamaIndex | ä¸“æ³¨äºæ£€ç´¢è´¨é‡ |

---

## ä¹ã€æ€»ç»“ä¸å»ºè®®

### 9.1 æ ¸å¿ƒå·®å¼‚æ€»ç»“

```mermaid
graph TB
    A[é€‰æ‹©æ¡†æ¶] --> B{é¡¹ç›®ç‰¹ç‚¹?}

    B -->|ä¸»è¦æ˜¯RAG/é—®ç­”| C[LlamaIndex]
    B -->|éœ€è¦Agentå†³ç­–| D[LangChain]
    B -->|ä¸¤è€…éƒ½éœ€è¦| E[ç»“åˆä½¿ç”¨]

    C --> C1[âœ… ä»£ç ç®€æ´]
    C --> C2[âœ… æ€§èƒ½ä¼˜ç§€]
    C --> C3[âœ… å¿«é€Ÿä¸Šçº¿]

    D --> D1[âœ… åŠŸèƒ½å¼ºå¤§]
    D --> D2[âœ… çµæ´»å¯æ‰©å±•]
    D --> D3[âœ… å·¥å…·ä¸°å¯Œ]

    E --> E1[âœ… å‘æŒ¥å„è‡ªä¼˜åŠ¿]
    E --> E2[âœ… æœ€ä½³å®è·µ]

    style C fill:#e1f5ff
    style D fill:#fff4e1
    style E fill:#e8f5e9
```

### 9.2 æœ€ä½³å®è·µå»ºè®®

**1. é¡¹ç›®åˆæœŸ**
- âœ… å…ˆç”¨LlamaIndexå¿«é€ŸéªŒè¯æƒ³æ³•
- âœ… ç¡®è®¤æ ¸å¿ƒéœ€æ±‚åå†é€‰æ‹©åˆé€‚çš„æ¡†æ¶
- âœ… ä¸è¦è¿‡æ—©ä¼˜åŒ–

**2. åŸå‹é˜¶æ®µ**
- âœ… å¦‚æœæ˜¯RAGåœºæ™¯ï¼Œä¼˜å…ˆLlamaIndex
- âœ… éœ€è¦å¤æ‚å·¥ä½œæµæ—¶è€ƒè™‘LangChain
- âœ… ä¿æŒä»£ç ç®€æ´ï¼Œä¾¿äºè¿­ä»£

**3. ç”Ÿäº§é˜¶æ®µ**
- âœ… è€ƒè™‘ç»“åˆä½¿ç”¨ä¸¤ä¸ªæ¡†æ¶
- âœ… ç”¨LlamaIndexå¤„ç†æ£€ç´¢ï¼ˆæ€§èƒ½ï¼‰
- âœ… ç”¨LangChainå¤„ç†å†³ç­–ï¼ˆçµæ´»æ€§ï¼‰

**4. å›¢é˜Ÿåä½œ**
- âœ… ç»Ÿä¸€æ¡†æ¶é€‰æ‹©ï¼ˆé™¤éæœ‰æ˜ç¡®ç†ç”±æ··ç”¨ï¼‰
- âœ… å»ºç«‹æœ€ä½³å®è·µæ–‡æ¡£
- âœ… å®šæœŸreviewæ€§èƒ½å’Œä»£ç è´¨é‡

### 9.3 æœªæ¥è¶‹åŠ¿

**ä¸¤ä¸ªæ¡†æ¶éƒ½åœ¨å¿«é€Ÿå‘å±•**ï¼š
- ğŸ”® LlamaIndexï¼šå¢å¼ºAgentèƒ½åŠ›ï¼Œæ‰©å±•å·¥å…·ç”Ÿæ€
- ğŸ”® LangChainï¼šä¼˜åŒ–æ€§èƒ½ï¼Œç®€åŒ–API
- ğŸ”® ä¸¤è€…å¯èƒ½ä¼šåœ¨æŸäº›æ–¹é¢è¶‹åŒ

**å»ºè®®**ï¼š
- ğŸ“š ä¸¤è€…éƒ½å€¼å¾—å­¦ä¹ 
- ğŸ”„ å…³æ³¨æ›´æ–°ï¼ŒåŠæ—¶å‡çº§
- ğŸ’¡ æ ¹æ®é¡¹ç›®å®é™…éœ€æ±‚çµæ´»é€‰æ‹©

---

## åã€å®æˆ˜å¯¹æ¯”æ¡ˆä¾‹

è®©æˆ‘ä»¬ç”¨åŒä¸€ä¸ªéœ€æ±‚ï¼Œåˆ†åˆ«ç”¨ä¸¤ä¸ªæ¡†æ¶å®ç°ï¼Œç›´è§‚æ„Ÿå—å·®å¼‚ï¼š

**éœ€æ±‚**ï¼šæ„å»ºä¸€ä¸ªPDFæ–‡æ¡£é—®ç­”ç³»ç»Ÿ

### 10.1 LlamaIndexå®ç°

```python
# æ–‡ä»¶ï¼špdf_qa_llamaindex.py
from llama_index import VectorStoreIndex, SimpleDirectoryReader

# 5è¡Œæ ¸å¿ƒä»£ç 
documents = SimpleDirectoryReader('pdfs').load_data()
index = VectorStoreIndex.from_documents(documents)
query_engine = index.as_query_engine()
response = query_engine.query("è¿™äº›æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ")
print(response)
```

**ç‰¹ç‚¹**ï¼š
- âœ… ä»…5è¡Œä»£ç 
- âœ… è‡ªåŠ¨å¤„ç†PDFè§£æã€åˆ†å‰²ã€åµŒå…¥
- âœ… å¼€ç®±å³ç”¨

---

### 10.2 LangChainå®ç°

```python
# æ–‡ä»¶ï¼špdf_qa_langchain.py
from langchain.document_loaders import PyPDFDirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

# 15è¡Œæ ¸å¿ƒä»£ç 
loader = PyPDFDirectoryLoader('pdfs')
documents = loader.load()

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
splits = text_splitter.split_documents(documents)

embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_documents(splits, embeddings)

llm = ChatOpenAI()
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever()
)

response = qa_chain.run("è¿™äº›æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ")
print(response)
```

**ç‰¹ç‚¹**ï¼š
- âœ… æ¯ä¸€æ­¥å¯æ§
- âœ… å¯ä»¥è‡ªç”±æ›¿æ¢ç»„ä»¶
- âœ… é€‚åˆå¤æ‚å®šåˆ¶

---

### 10.3 å¯¹æ¯”ç»“è®º

| ç»´åº¦ | LlamaIndex | LangChain |
|------|-----------|-----------|
| **ä»£ç è¡Œæ•°** | 5è¡Œ | 15è¡Œ |
| **å­¦ä¹ æ›²çº¿** | å¹³ç¼“ | é™¡å³­ |
| **çµæ´»æ€§** | ä¸­ç­‰ | å¾ˆé«˜ |
| **é€‚åˆäººç¾¤** | æ‰€æœ‰äºº | æœ‰ç»éªŒçš„å¼€å‘è€… |
| **ç»´æŠ¤æˆæœ¬** | ä½ | ä¸­ç­‰ |

---

## åä¸€ã€å¸¸è§é—®é¢˜FAQ

### Q1: å¯ä»¥åœ¨åŒä¸€ä¸ªé¡¹ç›®ä¸­åŒæ—¶ä½¿ç”¨ä¸¤ä¸ªæ¡†æ¶å—ï¼Ÿ

**A**: å¯ä»¥ï¼è¿™æ˜¯æ¨èçš„æœ€ä½³å®è·µä¹‹ä¸€ã€‚

```python
# ç¤ºä¾‹ï¼šç»“åˆä½¿ç”¨
from llama_index import VectorStoreIndex
from langchain.agents import initialize_agent

# LlamaIndexè´Ÿè´£æ£€ç´¢
index = VectorStoreIndex.from_documents(documents)

def search_kb(query):
    return str(index.as_query_engine().query(query))

# LangChainè´Ÿè´£å†³ç­–
tools = [Tool(name="KB", func=search_kb, description="...")]
agent = initialize_agent(tools, llm, ...)
```

---

### Q2: å“ªä¸ªæ¡†æ¶æ€§èƒ½æ›´å¥½ï¼Ÿ

**A**: LlamaIndexåœ¨RAGåœºæ™¯ä¸‹é€šå¸¸æ›´å¿«ï¼Œä½†å·®è·ä¸å¤§ã€‚

å…³é”®å› ç´ ï¼š
- é€‰æ‹©åˆé€‚çš„å‘é‡æ•°æ®åº“
- ä¼˜åŒ–chunkå¤§å°
- ä½¿ç”¨ç¼“å­˜
- è°ƒæ•´æ£€ç´¢å‚æ•°

ä¸¤ä¸ªæ¡†æ¶éƒ½å¯ä»¥è¾¾åˆ°ç”Ÿäº§çº§æ€§èƒ½ã€‚

---

### Q3: åˆå­¦è€…åº”è¯¥å…ˆå­¦å“ªä¸ªï¼Ÿ

**A**: å»ºè®®è·¯å¾„ï¼š

1. **å¦‚æœä½ çš„ç›®æ ‡æ˜¯å¿«é€Ÿæ„å»ºRAGåº”ç”¨**ï¼š
   - å…ˆå­¦LlamaIndexï¼ˆ1-2å‘¨ï¼‰
   - ç†è§£æ ¸å¿ƒæ¦‚å¿µåå†å­¦LangChain

2. **å¦‚æœä½ æƒ³å…¨é¢æŒæ¡LLMåº”ç”¨å¼€å‘**ï¼š
   - ç›´æ¥å­¦LangChainï¼ˆæ›´å…¨é¢ï¼‰
   - å‚è€ƒæœ¬åšå®¢çš„[LangChain 16å‘¨è¯¾ç¨‹](./README.md)

---

### Q4: ä¼ä¸šçº§åº”ç”¨åº”è¯¥é€‰æ‹©å“ªä¸ªï¼Ÿ

**A**: éƒ½å¯ä»¥ç”¨äºä¼ä¸šçº§åº”ç”¨ï¼Œä½†è€ƒè™‘å› ç´ ä¸åŒï¼š

**é€‰æ‹©LlamaIndexå¦‚æœ**ï¼š
- ä¸»è¦éœ€æ±‚æ˜¯çŸ¥è¯†æ£€ç´¢
- å›¢é˜Ÿè§„æ¨¡è¾ƒå°
- å¸Œæœ›å¿«é€Ÿäº¤ä»˜

**é€‰æ‹©LangChainå¦‚æœ**ï¼š
- éœ€è¦å¤æ‚çš„ä¸šåŠ¡é€»è¾‘
- éœ€è¦é›†æˆå¤šä¸ªå¤–éƒ¨ç³»ç»Ÿ
- å›¢é˜Ÿæœ‰è¾ƒå¼ºçš„æŠ€æœ¯èƒ½åŠ›

**ç»“åˆä½¿ç”¨å¦‚æœ**ï¼š
- é¢„ç®—å……è¶³
- éœ€æ±‚å¤æ‚å¤šæ ·
- è¿½æ±‚æœ€ä½³æ€§èƒ½å’Œä½“éªŒ

---

### Q5: å¦‚ä½•è¿ç§»ï¼Ÿ

**A**: è¿ç§»ç­–ç•¥ï¼š

```python
# ä»LlamaIndexè¿ç§»åˆ°LangChain
# 1. ä¿ç•™ç´¢å¼•æ•°æ®ï¼ˆå‘é‡æ•°æ®åº“ï¼‰
# 2. åªæ›¿æ¢æŸ¥è¯¢é€»è¾‘

# åŸLlamaIndexä»£ç 
# index = VectorStoreIndex.from_documents(documents)

# è¿ç§»ï¼šä½¿ç”¨ç›¸åŒçš„å‘é‡æ•°æ®åº“
from langchain.vectorstores import Chroma
vectorstore = Chroma(persist_directory="./chroma_db")
# ç»§ç»­ä½¿ç”¨LangChainçš„å…¶ä»–åŠŸèƒ½

# ä»LangChainè¿ç§»åˆ°LlamaIndex
# 1. å¯¼å‡ºå‘é‡æ•°æ®
# 2. ç”¨LlamaIndexé‡æ–°åŠ è½½
```

**å»ºè®®**ï¼šé™¤éæœ‰æ˜ç¡®æ”¶ç›Šï¼Œå¦åˆ™ä¸è¦è½»æ˜“è¿ç§»ã€‚

---

## åäºŒã€æ€»ç»“

### ğŸ¯ ä¸€å¥è¯æ€»ç»“

- **LlamaIndex**ï¼šä¸“æ³¨RAGï¼Œç®€å•é«˜æ•ˆï¼Œå¿«é€Ÿä¸Šæ‰‹
- **LangChain**ï¼šé€šç”¨æ¡†æ¶ï¼ŒåŠŸèƒ½å¼ºå¤§ï¼Œçµæ´»å¯æ‰©å±•

### ğŸ’¡ æœ€ç»ˆå»ºè®®

1. **å•çº¯çš„RAG/é—®ç­”ç³»ç»Ÿ** â†’ é€‰LlamaIndex
2. **éœ€è¦Agentå’Œå¤æ‚å·¥ä½œæµ** â†’ é€‰LangChain
3. **ä¼ä¸šçº§ç»¼åˆåº”ç”¨** â†’ ç»“åˆä½¿ç”¨
4. **å­¦ä¹ å’Œæˆé•¿** â†’ ä¸¤è€…éƒ½å€¼å¾—æŒæ¡

### ğŸš€ ä¸‹ä¸€æ­¥

- ğŸ“– é˜…è¯»æœ¬åšå®¢çš„ [LangChainå®Œæ•´å­¦ä¹ æŒ‡å—](./README.md)
- ğŸ’» åŠ¨æ‰‹å®è·µï¼Œæ„å»ºè‡ªå·±çš„é¡¹ç›®
- ğŸŒŸ å…³æ³¨ä¸¤ä¸ªæ¡†æ¶çš„æ›´æ–°

---

**ç¥ä½ åœ¨LLMåº”ç”¨å¼€å‘çš„é“è·¯ä¸Šè¶Šèµ°è¶Šè¿œï¼** ğŸ‰

å¦‚æœæœ‰ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿äº¤æµè®¨è®ºï¼
