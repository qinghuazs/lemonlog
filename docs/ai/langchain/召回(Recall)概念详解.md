---
title: å¬å›(Recall)æ¦‚å¿µè¯¦è§£
date: 2025-01-30
permalink: /ai/langchain/recall-concept.html
tags:
  - AI
  - RAG
  - å¬å›
  - æ£€ç´¢
categories:
  - AI
  - LangChain
---

# å¬å›(Recall)æ¦‚å¿µè¯¦è§£

::: tip å­¦ä¹ ç›®æ ‡
- ğŸ¯ ç†è§£å¬å›çš„å®šä¹‰å’Œé‡è¦æ€§
- ğŸ“Š æŒæ¡å¬å›ç‡å’Œç²¾ç¡®ç‡çš„åŒºåˆ«
- ğŸ” å­¦ä¹ å¤šç§å¬å›ç­–ç•¥
- ğŸš€ ä¼˜åŒ– RAG ç³»ç»Ÿçš„å¬å›æ•ˆæœ
- ğŸ’¡ å®ç°é«˜è´¨é‡çš„æ£€ç´¢ç³»ç»Ÿ
:::

## ä¸€ã€å¬å›çš„å®šä¹‰

### 1.1 ä»€ä¹ˆæ˜¯å¬å›ï¼Ÿ

**å¬å›ï¼ˆRecallï¼‰** æ˜¯æŒ‡åœ¨æ£€ç´¢ç³»ç»Ÿä¸­ï¼Œ**æ‰¾å›æ‰€æœ‰ç›¸å…³ç»“æœçš„èƒ½åŠ›**ã€‚

ç®€å•æ¥è¯´ï¼š
- ğŸ“š **å¬å›** = åœ¨æ‰€æœ‰ç›¸å…³æ–‡æ¡£ä¸­ï¼Œæ£€ç´¢ç³»ç»Ÿæ‰¾åˆ°äº†å¤šå°‘
- ğŸ¯ å…³æ³¨çš„æ˜¯"**æŸ¥å…¨ç‡**"ï¼Œå³ä¸è¦é—æ¼ç›¸å…³å†…å®¹

```mermaid
graph TB
    A[æ–‡æ¡£åº“<br/>10000ç¯‡æ–‡æ¡£] --> B{æ£€ç´¢ç³»ç»Ÿ}
    B --> C[å¬å›ç»“æœ<br/>100ç¯‡]

    D[çœŸæ­£ç›¸å…³çš„æ–‡æ¡£<br/>150ç¯‡] --> E{å¬å›ç‡è®¡ç®—}
    C --> E

    E --> F[å¬å›ç‡ = 100 / 150 = 66.7%]

    style A fill:#E3F2FD
    style C fill:#FFE082
    style D fill:#C8E6C9
    style F fill:#81C784
```

### 1.2 å½¢è±¡ç†è§£

**ç”Ÿæ´»ä¸­çš„ä¾‹å­ï¼š**

```
åœºæ™¯ï¼šåœ¨è¶…å¸‚æ‰¾"æ‰€æœ‰çš„è‹¹æœ"

æƒ…å†µ1ï¼šè¶…å¸‚æœ‰100ä¸ªè‹¹æœï¼Œä½ æ‰¾åˆ°äº†80ä¸ª
â†’ å¬å›ç‡ = 80/100 = 80%

æƒ…å†µ2ï¼šè¶…å¸‚æœ‰100ä¸ªè‹¹æœï¼Œä½ æ‰¾åˆ°äº†95ä¸ª
â†’ å¬å›ç‡ = 95/100 = 95%ï¼ˆæ›´å¥½çš„å¬å›ï¼‰
```

**å…³é”®ç‚¹ï¼š**
- âœ… å¬å›ç‡é«˜ = æ‰¾åˆ°äº†å¤§éƒ¨åˆ†ç›¸å…³å†…å®¹
- âŒ å¬å›ç‡ä½ = é—æ¼äº†å¾ˆå¤šç›¸å…³å†…å®¹

---

## äºŒã€å¬å› vs ç²¾ç¡®ç‡

### 2.1 ä¸¤ä¸ªæ ¸å¿ƒæŒ‡æ ‡

åœ¨ä¿¡æ¯æ£€ç´¢ä¸­ï¼Œå¬å›å’Œç²¾ç¡®ç‡æ˜¯ä¸€å¯¹é‡è¦çš„è¯„ä¼°æŒ‡æ ‡ï¼š

```mermaid
graph LR
    A[æ£€ç´¢è¯„ä¼°] --> B[å¬å›ç‡ Recall<br/>æŸ¥å…¨ç‡]
    A --> C[ç²¾ç¡®ç‡ Precision<br/>æŸ¥å‡†ç‡]

    B --> B1[æ‰¾åˆ°äº†å¤šå°‘ç›¸å…³çš„ï¼Ÿ]
    C --> C1[æ‰¾åˆ°çš„æœ‰å¤šå‡†ç¡®ï¼Ÿ]

    style A fill:#E3F2FD
    style B fill:#C8E6C9
    style C fill:#FFE082
```

### 2.2 å®šä¹‰å¯¹æ¯”

| æŒ‡æ ‡ | å®šä¹‰ | å…³æ³¨ç‚¹ | å…¬å¼ | è‹±æ–‡ |
|------|------|--------|------|------|
| **å¬å›ç‡** | æ‰¾å›äº†å¤šå°‘ç›¸å…³ç»“æœ | æŸ¥å…¨ç‡ï¼ˆä¸é—æ¼ï¼‰ | æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£ / æ‰€æœ‰ç›¸å…³æ–‡æ¡£ | Recall |
| **ç²¾ç¡®ç‡** | æ‰¾å›çš„ç»“æœæœ‰å¤šå‡†ç¡® | æŸ¥å‡†ç‡ï¼ˆä¸é”™è¯¯ï¼‰ | æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£ / æ£€ç´¢åˆ°çš„æ‰€æœ‰æ–‡æ¡£ | Precision |

### 2.3 å›¾ç¤ºè¯´æ˜

```
å‡è®¾ï¼š
- æ•°æ®åº“æœ‰ 100 æœ¬ Python ä¹¦ç±ï¼ˆçœŸæ­£ç›¸å…³çš„ï¼‰
- è¿˜æœ‰ 900 æœ¬å…¶ä»–ä¹¦ç±
- ä½ çš„æ£€ç´¢ç³»ç»Ÿè¿”å›äº† 80 æœ¬ä¹¦

ç»“æœï¼š
- å…¶ä¸­ 70 æœ¬ç¡®å®æ˜¯ Python ä¹¦ç±
- å¦å¤– 10 æœ¬æ˜¯å…¶ä»–ä¹¦ç±

è®¡ç®—ï¼š
å¬å›ç‡ = 70 / 100 = 70%    ï¼ˆæ‰¾åˆ°äº†70%çš„Pythonä¹¦ï¼‰
ç²¾ç¡®ç‡ = 70 / 80 = 87.5%   ï¼ˆè¿”å›çš„ä¹¦ä¸­87.5%æ˜¯å¯¹çš„ï¼‰
```

**å¯è§†åŒ–ï¼š**

```
æ•°æ®åº“æ€»ä½“ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pythonä¹¦ç±(100æœ¬)  â”‚  å…¶ä»–ä¹¦ç±(900æœ¬) â”‚
â”‚                    â”‚                  â”‚
â”‚  [æ‰¾åˆ°70æœ¬]        â”‚   [è¯¯æ‰¾10æœ¬]     â”‚
â”‚  [æ¼æ‰30æœ¬]        â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å¬å›ç‡ = 70/(70+30) = 70%  â† å…³æ³¨"æ²¡æ‰¾åˆ°çš„30æœ¬"
ç²¾ç¡®ç‡ = 70/(70+10) = 87.5% â† å…³æ³¨"è¯¯æ‰¾çš„10æœ¬"
```

### 2.4 å®é™…æ¡ˆä¾‹

**åœºæ™¯ï¼šå›¾ä¹¦é¦†æ£€ç´¢ç³»ç»Ÿ**

```python
"""
å›¾ä¹¦æ£€ç´¢æ¡ˆä¾‹
"""
# å‡è®¾æ•°æ®
total_relevant = 100      # å›¾ä¹¦é¦†æœ‰100æœ¬Pythonä¹¦
retrieved = 80            # ç³»ç»Ÿè¿”å›äº†80æœ¬ä¹¦
true_positives = 70       # å…¶ä¸­70æœ¬ç¡®å®æ˜¯Pythonä¹¦

# è®¡ç®—æŒ‡æ ‡
recall = true_positives / total_relevant
precision = true_positives / retrieved

print(f"å¬å›ç‡: {recall:.1%}")      # 70%
print(f"ç²¾ç¡®ç‡: {precision:.1%}")   # 87.5%

# åˆ†æ
print("\nåˆ†æï¼š")
print(f"- é—æ¼äº† {total_relevant - true_positives} æœ¬ç›¸å…³ä¹¦ç±")
print(f"- é”™è¯¯è¿”å›äº† {retrieved - true_positives} æœ¬æ— å…³ä¹¦ç±")
```

**è¾“å‡ºï¼š**
```
å¬å›ç‡: 70.0%
ç²¾ç¡®ç‡: 87.5%

åˆ†æï¼š
- é—æ¼äº† 30 æœ¬ç›¸å…³ä¹¦ç±
- é”™è¯¯è¿”å›äº† 10 æœ¬æ— å…³ä¹¦ç±
```

### 2.5 å¬å›ä¸ç²¾ç¡®ç‡çš„æƒè¡¡

```mermaid
graph TB
    A[æ£€ç´¢ç³»ç»Ÿè°ƒä¼˜] --> B{ä¼˜åŒ–æ–¹å‘}

    B -->|å®½æ¾ç­–ç•¥| C[æé«˜å¬å›ç‡]
    C --> C1[è¿”å›æ›´å¤šç»“æœ]
    C1 --> C2[å¯èƒ½é™ä½ç²¾ç¡®ç‡]

    B -->|ä¸¥æ ¼ç­–ç•¥| D[æé«˜ç²¾ç¡®ç‡]
    D --> D1[æ›´ä¸¥æ ¼çš„è¿‡æ»¤]
    D1 --> D2[å¯èƒ½é™ä½å¬å›ç‡]

    B -->|å¹³è¡¡ç­–ç•¥| E[F1 Score]
    E --> E1[å¬å›å’Œç²¾ç¡®ç‡çš„è°ƒå’Œå¹³å‡]

    style C fill:#C8E6C9
    style D fill:#FFE082
    style E fill:#81C784
```

**æƒè¡¡ç¤ºä¾‹ï¼š**

```python
"""
è°ƒæ•´æ£€ç´¢é˜ˆå€¼çš„å½±å“
"""
import numpy as np

# æ¨¡æ‹Ÿä¸åŒé˜ˆå€¼ä¸‹çš„å¬å›ç‡å’Œç²¾ç¡®ç‡
thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]
recalls = [0.95, 0.85, 0.75, 0.60, 0.40]
precisions = [0.60, 0.70, 0.80, 0.88, 0.95]

print("é˜ˆå€¼  å¬å›ç‡  ç²¾ç¡®ç‡  F1-Score")
print("-" * 40)

for t, r, p in zip(thresholds, recalls, precisions):
    f1 = 2 * (p * r) / (p + r)  # F1 Score
    print(f"{t:.1f}   {r:.2%}   {p:.2%}    {f1:.2%}")

print("\nè§‚å¯Ÿï¼š")
print("- é˜ˆå€¼é™ä½ â†’ å¬å›ç‡â†‘ï¼Œç²¾ç¡®ç‡â†“")
print("- é˜ˆå€¼å‡é«˜ â†’ å¬å›ç‡â†“ï¼Œç²¾ç¡®ç‡â†‘")
```

**è¾“å‡ºï¼š**
```
é˜ˆå€¼  å¬å›ç‡  ç²¾ç¡®ç‡  F1-Score
----------------------------------------
0.5   95.00%   60.00%    73.85%
0.6   85.00%   70.00%    76.74%
0.7   75.00%   80.00%    77.42%  â† æœ€ä½³å¹³è¡¡ç‚¹
0.8   60.00%   88.00%    71.43%
0.9   40.00%   95.00%    56.34%

è§‚å¯Ÿï¼š
- é˜ˆå€¼é™ä½ â†’ å¬å›ç‡â†‘ï¼Œç²¾ç¡®ç‡â†“
- é˜ˆå€¼å‡é«˜ â†’ å¬å›ç‡â†“ï¼Œç²¾ç¡®ç‡â†‘
```

---

## ä¸‰ã€RAG ç³»ç»Ÿä¸­çš„å¬å›

### 3.1 å¬å›åœ¨ RAG ä¸­çš„ä½ç½®

**RAGï¼ˆRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰** ç³»ç»Ÿçš„æ ¸å¿ƒæµç¨‹ï¼š

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·æŸ¥è¯¢
    participant R as å¬å›æ¨¡å—
    participant V as å‘é‡æ•°æ®åº“
    participant Re as é‡æ’åº
    participant L as LLMç”Ÿæˆ

    U->>R: "LangChainçš„æ ¸å¿ƒç»„ä»¶æ˜¯ä»€ä¹ˆï¼Ÿ"
    Note over R: ç¬¬1æ­¥ï¼šå¬å›é˜¶æ®µ<br/>å®½æ³›æ£€ç´¢ï¼Œé«˜å¬å›
    R->>V: å‘é‡ç›¸ä¼¼åº¦æœç´¢
    V->>R: è¿”å› Top-50 å€™é€‰

    Note over Re: ç¬¬2æ­¥ï¼šé‡æ’åºé˜¶æ®µ<br/>ç²¾ç»†æ’åºï¼Œé«˜ç²¾ç¡®ç‡
    R->>Re: 50ä¸ªå€™é€‰æ–‡æ¡£
    Re->>Re: é‡æ–°è®¡ç®—ç›¸å…³æ€§
    Re->>L: Top-5 ç²¾é€‰æ–‡æ¡£

    Note over L: ç¬¬3æ­¥ï¼šç”Ÿæˆé˜¶æ®µ<br/>åŸºäºå¬å›å†…å®¹ç”Ÿæˆç­”æ¡ˆ
    L->>L: é˜…è¯»æ–‡æ¡£ + ç”Ÿæˆç­”æ¡ˆ
    L->>U: æœ€ç»ˆç­”æ¡ˆ
```

### 3.2 å¬å›é˜¶æ®µçš„ä»»åŠ¡

å¬å›æ¨¡å—è´Ÿè´£ä»å¤§é‡æ–‡æ¡£ä¸­å¿«é€Ÿæ‰¾åˆ°**å¯èƒ½ç›¸å…³**çš„å€™é€‰é›†ï¼š

**æ ¸å¿ƒä»»åŠ¡ï¼š**

1. **å‘é‡åŒ–æŸ¥è¯¢**
   ```python
   # å°†ç”¨æˆ·é—®é¢˜è½¬ä¸ºå‘é‡
   query_embedding = embeddings.embed_query("ä»€ä¹ˆæ˜¯LangChainï¼Ÿ")
   ```

2. **ç›¸ä¼¼åº¦æœç´¢**
   ```python
   # åœ¨å‘é‡æ•°æ®åº“ä¸­æœç´¢
   candidates = vectorstore.similarity_search(
       query,
       k=50  # å¬å›50ä¸ªå€™é€‰
   )
   ```

3. **è¿”å›å€™é€‰é›†**
   ```python
   # è¿”å›æœ€ç›¸ä¼¼çš„ Top-K æ–‡æ¡£
   return candidates[:k]
   ```

### 3.3 RAG å¬å›ç¤ºä¾‹

```python
"""
RAG ç³»ç»Ÿä¸­çš„å¬å›å®ç°
"""
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader

class RAGWithRecall:
    """å¸¦å¬å›å¯è§†åŒ–çš„RAGç³»ç»Ÿ"""

    def __init__(self, documents):
        # åˆå§‹åŒ–
        self.embeddings = OpenAIEmbeddings()
        self.llm = ChatOpenAI(model="gpt-3.5-turbo")

        # æ–‡æ¡£å¤„ç†
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        self.chunks = splitter.split_documents(documents)

        # åˆ›å»ºå‘é‡å­˜å‚¨
        self.vectorstore = FAISS.from_documents(
            self.chunks,
            self.embeddings
        )

        print(f"âœ… å·²ç´¢å¼• {len(self.chunks)} ä¸ªæ–‡æ¡£å—")

    def recall_documents(self, query: str, k: int = 10):
        """
        å¬å›ç›¸å…³æ–‡æ¡£

        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            k: å¬å›æ•°é‡

        è¿”å›:
            å¬å›çš„æ–‡æ¡£åˆ—è¡¨
        """
        print(f"\nğŸ” æ­£åœ¨å¬å›ç›¸å…³æ–‡æ¡£...")
        print(f"   æŸ¥è¯¢: {query}")
        print(f"   å¬å›æ•°é‡: {k}")

        # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
        docs = self.vectorstore.similarity_search(query, k=k)

        print(f"âœ… æˆåŠŸå¬å› {len(docs)} ä¸ªæ–‡æ¡£")

        # æ˜¾ç¤ºå¬å›ç»“æœ
        print("\nå¬å›çš„æ–‡æ¡£ç‰‡æ®µ:")
        for i, doc in enumerate(docs, 1):
            preview = doc.page_content[:100].replace('\n', ' ')
            print(f"  {i}. {preview}...")

        return docs

    def recall_with_scores(self, query: str, k: int = 10):
        """
        å¬å›æ–‡æ¡£å¹¶è¿”å›ç›¸ä¼¼åº¦åˆ†æ•°
        """
        docs_with_scores = self.vectorstore.similarity_search_with_score(
            query, k=k
        )

        print(f"\nå¬å›ç»“æœï¼ˆå¸¦ç›¸ä¼¼åº¦åˆ†æ•°ï¼‰:")
        for i, (doc, score) in enumerate(docs_with_scores, 1):
            preview = doc.page_content[:80].replace('\n', ' ')
            print(f"  {i}. ç›¸ä¼¼åº¦: {score:.4f} | {preview}...")

        return docs_with_scores

    def analyze_recall_quality(self, query: str, ground_truth_ids: list):
        """
        åˆ†æå¬å›è´¨é‡

        å‚æ•°:
            query: æŸ¥è¯¢
            ground_truth_ids: çœŸæ­£ç›¸å…³çš„æ–‡æ¡£IDåˆ—è¡¨
        """
        # å¬å›æ–‡æ¡£
        recalled_docs = self.recall_documents(query, k=20)
        recalled_ids = [doc.metadata.get('id') for doc in recalled_docs]

        # è®¡ç®—å¬å›ç‡
        recalled_relevant = len(set(recalled_ids) & set(ground_truth_ids))
        recall_rate = recalled_relevant / len(ground_truth_ids)

        # è®¡ç®—ç²¾ç¡®ç‡
        precision = recalled_relevant / len(recalled_docs)

        print(f"\nğŸ“Š å¬å›è´¨é‡åˆ†æ:")
        print(f"   çœŸæ­£ç›¸å…³çš„æ–‡æ¡£: {len(ground_truth_ids)} ä¸ª")
        print(f"   å¬å›çš„æ–‡æ¡£: {len(recalled_docs)} ä¸ª")
        print(f"   å¬å›çš„ç›¸å…³æ–‡æ¡£: {recalled_relevant} ä¸ª")
        print(f"   å¬å›ç‡: {recall_rate:.1%}")
        print(f"   ç²¾ç¡®ç‡: {precision:.1%}")

        return {
            'recall': recall_rate,
            'precision': precision
        }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åŠ è½½æ–‡æ¡£
    loader = TextLoader("langchain_docs.txt", encoding="utf-8")
    documents = loader.load()

    # åˆ›å»ºRAGç³»ç»Ÿ
    rag = RAGWithRecall(documents)

    # æµ‹è¯•å¬å›
    query = "LangChain çš„æ ¸å¿ƒç»„ä»¶æœ‰å“ªäº›ï¼Ÿ"
    docs = rag.recall_documents(query, k=5)

    # æŸ¥çœ‹å¸¦åˆ†æ•°çš„å¬å›
    docs_with_scores = rag.recall_with_scores(query, k=5)
```

---

## å››ã€å¬å›ç­–ç•¥

### 4.1 å¯†é›†æ£€ç´¢ï¼ˆDense Retrievalï¼‰

**å¯†é›†æ£€ç´¢**ä½¿ç”¨ç¥ç»ç½‘ç»œç”Ÿæˆçš„ç¨ å¯†å‘é‡è¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢ã€‚

#### 4.1.1 åŸç†

```mermaid
graph LR
    A[æ–‡æœ¬] --> B[Embeddingæ¨¡å‹]
    B --> C[ç¨ å¯†å‘é‡<br/>768ç»´]

    D[æŸ¥è¯¢] --> E[Embeddingæ¨¡å‹]
    E --> F[æŸ¥è¯¢å‘é‡<br/>768ç»´]

    C --> G[ä½™å¼¦ç›¸ä¼¼åº¦]
    F --> G
    G --> H[ç›¸ä¼¼åº¦åˆ†æ•°]

    style A fill:#E3F2FD
    style D fill:#FFE082
    style H fill:#C8E6C9
```

#### 4.1.2 å®ç°

```python
"""
å¯†é›†æ£€ç´¢å®ç°
"""
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

class DenseRetrieval:
    """å¯†é›†æ£€ç´¢å™¨"""

    def __init__(self, documents):
        self.embeddings = OpenAIEmbeddings()

        # åˆ›å»ºå‘é‡å­˜å‚¨
        self.vectorstore = FAISS.from_documents(
            documents,
            self.embeddings
        )

    def search(self, query: str, k: int = 5):
        """
        è¯­ä¹‰æœç´¢

        ç‰¹ç‚¹ï¼š
        - ç†è§£è¯­ä¹‰ï¼Œä¸ä»…ä»…æ˜¯å…³é”®è¯åŒ¹é…
        - å¯ä»¥æ‰¾åˆ°åŒä¹‰è¯ã€ç›¸å…³æ¦‚å¿µ
        """
        # ç›¸ä¼¼åº¦æœç´¢
        results = self.vectorstore.similarity_search(query, k=k)

        return results

# ç¤ºä¾‹
retriever = DenseRetrieval(documents)

# å³ä½¿æŸ¥è¯¢å’Œæ–‡æ¡£ç”¨è¯ä¸åŒï¼Œä¹Ÿèƒ½æ‰¾åˆ°ç›¸å…³å†…å®¹
results = retriever.search("AIæ¡†æ¶æœ‰å“ªäº›ï¼Ÿ", k=3)
# èƒ½æ‰¾åˆ°åŒ…å«"LangChain"ã€"æœºå™¨å­¦ä¹ å·¥å…·"ç­‰å†…å®¹
```

**ä¼˜ç‚¹ï¼š**
- âœ… è¯­ä¹‰ç†è§£èƒ½åŠ›å¼º
- âœ… å¯ä»¥å¤„ç†åŒä¹‰è¯ã€ç›¸å…³æ¦‚å¿µ
- âœ… ä¸ä¾èµ–ç²¾ç¡®çš„å…³é”®è¯åŒ¹é…

**ç¼ºç‚¹ï¼š**
- âŒ è®¡ç®—æˆæœ¬é«˜ï¼ˆéœ€è¦embeddingï¼‰
- âŒ å¯¹ç½•è§è¯æ±‡æ•ˆæœå¯èƒ½ä¸å¥½

### 4.2 ç¨€ç–æ£€ç´¢ï¼ˆSparse Retrievalï¼‰

**ç¨€ç–æ£€ç´¢**åŸºäºä¼ ç»Ÿçš„å…³é”®è¯åŒ¹é…ï¼ˆå¦‚BM25ç®—æ³•ï¼‰ã€‚

#### 4.2.1 BM25 åŸç†

BM25 æ˜¯ä¸€ç§ç»å…¸çš„å…³é”®è¯æ£€ç´¢ç®—æ³•ï¼Œè€ƒè™‘ï¼š
- è¯é¢‘ï¼ˆTFï¼‰ï¼šè¯åœ¨æ–‡æ¡£ä¸­å‡ºç°çš„é¢‘ç‡
- é€†æ–‡æ¡£é¢‘ç‡ï¼ˆIDFï¼‰ï¼šè¯çš„ç¨€æœ‰ç¨‹åº¦
- æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–

#### 4.2.2 å®ç°

```python
"""
ç¨€ç–æ£€ç´¢å®ç°ï¼ˆBM25ï¼‰
"""
from langchain.retrievers import BM25Retriever
from langchain.schema import Document

class SparseRetrieval:
    """ç¨€ç–æ£€ç´¢å™¨ï¼ˆBM25ï¼‰"""

    def __init__(self, documents):
        # åˆ›å»ºBM25æ£€ç´¢å™¨
        self.retriever = BM25Retriever.from_documents(documents)
        self.retriever.k = 5  # è¿”å›Top-5

    def search(self, query: str):
        """
        å…³é”®è¯æœç´¢

        ç‰¹ç‚¹ï¼š
        - åŸºäºå…³é”®è¯ç²¾ç¡®åŒ¹é…
        - é€Ÿåº¦å¿«ï¼Œæ— éœ€GPU
        - å¯¹ç½•è§è¯æ±‡æ•ˆæœå¥½
        """
        results = self.retriever.get_relevant_documents(query)
        return results

# ç¤ºä¾‹
documents = [
    Document(page_content="LangChain æ˜¯ä¸€ä¸ªå¼ºå¤§çš„AIæ¡†æ¶"),
    Document(page_content="Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€"),
    Document(page_content="OpenAI æä¾› GPT æ¨¡å‹")
]

retriever = SparseRetrieval(documents)

# ç²¾ç¡®åŒ¹é…å…³é”®è¯
results = retriever.search("LangChain æ¡†æ¶")
# ä¼šæ‰¾åˆ°åŒ…å«"LangChain"å’Œ"æ¡†æ¶"çš„æ–‡æ¡£
```

**ä¼˜ç‚¹ï¼š**
- âœ… é€Ÿåº¦å¿«ï¼Œä¸éœ€è¦GPU
- âœ… å¯¹ç²¾ç¡®å…³é”®è¯åŒ¹é…æ•ˆæœå¥½
- âœ… å¯¹ç½•è§è¯æ±‡æ•æ„Ÿ

**ç¼ºç‚¹ï¼š**
- âŒ ä¸ç†è§£è¯­ä¹‰
- âŒ æ— æ³•å¤„ç†åŒä¹‰è¯
- âŒ å¯¹æ‹¼å†™é”™è¯¯æ•æ„Ÿ

### 4.3 æ··åˆæ£€ç´¢ï¼ˆHybrid Retrievalï¼‰

**æ··åˆæ£€ç´¢**ç»“åˆå¯†é›†æ£€ç´¢å’Œç¨€ç–æ£€ç´¢çš„ä¼˜ç‚¹ã€‚

#### 4.3.1 æ¶æ„

```mermaid
graph TB
    A[ç”¨æˆ·æŸ¥è¯¢] --> B[å¯†é›†æ£€ç´¢]
    A --> C[ç¨€ç–æ£€ç´¢]

    B --> D[è¯­ä¹‰ç›¸ä¼¼æ–‡æ¡£<br/>Top-20]
    C --> E[å…³é”®è¯åŒ¹é…æ–‡æ¡£<br/>Top-20]

    D --> F[èåˆæ’åº]
    E --> F

    F --> G[æœ€ç»ˆç»“æœ<br/>Top-10]

    style A fill:#E3F2FD
    style F fill:#FFE082
    style G fill:#C8E6C9
```

#### 4.3.2 å®ç°

```python
"""
æ··åˆæ£€ç´¢å®ç°
"""
from langchain.retrievers import EnsembleRetriever
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.retrievers import BM25Retriever

class HybridRetrieval:
    """æ··åˆæ£€ç´¢å™¨"""

    def __init__(self, documents):
        # 1. å¯†é›†æ£€ç´¢å™¨ï¼ˆè¯­ä¹‰ï¼‰
        embeddings = OpenAIEmbeddings()
        vectorstore = FAISS.from_documents(documents, embeddings)
        self.dense_retriever = vectorstore.as_retriever(
            search_kwargs={"k": 10}
        )

        # 2. ç¨€ç–æ£€ç´¢å™¨ï¼ˆå…³é”®è¯ï¼‰
        self.sparse_retriever = BM25Retriever.from_documents(documents)
        self.sparse_retriever.k = 10

        # 3. é›†æˆæ£€ç´¢å™¨
        self.ensemble_retriever = EnsembleRetriever(
            retrievers=[self.dense_retriever, self.sparse_retriever],
            weights=[0.5, 0.5]  # å„å 50%æƒé‡
        )

    def search(self, query: str, k: int = 5):
        """
        æ··åˆæœç´¢

        ä¼˜ç‚¹ï¼š
        - ç»“åˆè¯­ä¹‰ç†è§£å’Œå…³é”®è¯åŒ¹é…
        - æ›´å…¨é¢ã€æ›´å‡†ç¡®
        """
        results = self.ensemble_retriever.get_relevant_documents(query)
        return results[:k]

# ä½¿ç”¨
hybrid = HybridRetrieval(documents)
results = hybrid.search("LangChain AIæ¡†æ¶", k=5)

print("æ··åˆæ£€ç´¢ç»“æœï¼š")
for i, doc in enumerate(results, 1):
    print(f"{i}. {doc.page_content[:100]}...")
```

#### 4.3.3 æƒé‡è°ƒæ•´

å¯ä»¥æ ¹æ®åœºæ™¯è°ƒæ•´ä¸¤ç§æ£€ç´¢æ–¹å¼çš„æƒé‡ï¼š

```python
"""
åŠ¨æ€æƒé‡è°ƒæ•´
"""
# åœºæ™¯1ï¼šæ›´ä¾èµ–è¯­ä¹‰ç†è§£
semantic_heavy = EnsembleRetriever(
    retrievers=[dense_retriever, sparse_retriever],
    weights=[0.7, 0.3]  # è¯­ä¹‰70%ï¼Œå…³é”®è¯30%
)

# åœºæ™¯2ï¼šæ›´ä¾èµ–ç²¾ç¡®åŒ¹é…
keyword_heavy = EnsembleRetriever(
    retrievers=[dense_retriever, sparse_retriever],
    weights=[0.3, 0.7]  # è¯­ä¹‰30%ï¼Œå…³é”®è¯70%
)

# åœºæ™¯3ï¼šå‡è¡¡
balanced = EnsembleRetriever(
    retrievers=[dense_retriever, sparse_retriever],
    weights=[0.5, 0.5]  # å„50%
)
```

### 4.4 ä¸‰ç§ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | åŸç† | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|------|---------|
| **å¯†é›†æ£€ç´¢** | å‘é‡è¯­ä¹‰ç›¸ä¼¼åº¦ | è¯­ä¹‰ç†è§£å¼º | è®¡ç®—æˆæœ¬é«˜ | æ¦‚å¿µæ€§æŸ¥è¯¢ã€è·¨è¯­è¨€ |
| **ç¨€ç–æ£€ç´¢** | å…³é”®è¯BM25 | é€Ÿåº¦å¿«ã€ç²¾ç¡®åŒ¹é… | æ— è¯­ä¹‰ç†è§£ | ä¸“æœ‰åè¯ã€ç²¾ç¡®æŸ¥è¯¢ |
| **æ··åˆæ£€ç´¢** | ä¸¤è€…ç»“åˆ | å…¼é¡¾è¯­ä¹‰å’Œç²¾ç¡®æ€§ | å®ç°å¤æ‚ | é€šç”¨åœºæ™¯ï¼ˆæ¨èï¼‰ |

---

## äº”ã€å¬å›ä¼˜åŒ–æŠ€å·§

### 5.1 å¢åŠ å¬å›æ•°é‡ï¼ˆè°ƒæ•´ k å€¼ï¼‰

æœ€ç®€å•çš„ä¼˜åŒ–æ–¹æ³•ï¼šå¬å›æ›´å¤šå€™é€‰æ–‡æ¡£ã€‚

```python
"""
è°ƒæ•´å¬å›æ•°é‡
"""
# é»˜è®¤å¬å›
retriever_default = vectorstore.as_retriever(
    search_kwargs={"k": 4}  # é»˜è®¤4ä¸ª
)

# å¢åŠ å¬å›
retriever_more = vectorstore.as_retriever(
    search_kwargs={"k": 20}  # å¢åŠ åˆ°20ä¸ª
)

# å¯¹æ¯”æ•ˆæœ
query = "LangChain çš„æ ¸å¿ƒç»„ä»¶"

docs_default = retriever_default.get_relevant_documents(query)
docs_more = retriever_more.get_relevant_documents(query)

print(f"é»˜è®¤å¬å›: {len(docs_default)} ä¸ªæ–‡æ¡£")
print(f"å¢åŠ å¬å›: {len(docs_more)} ä¸ªæ–‡æ¡£")

# é€šå¸¸ï¼šå¬å›æ•°é‡ â†‘ â†’ å¬å›ç‡ â†‘ï¼Œä½†ç²¾ç¡®ç‡å¯èƒ½ â†“
```

**æ¨èç­–ç•¥ï¼š**

```python
"""
ä¸¤é˜¶æ®µå¬å›
"""
# ç¬¬1é˜¶æ®µï¼šå®½æ³›å¬å›ï¼ˆé«˜å¬å›ç‡ï¼‰
candidates = vectorstore.similarity_search(query, k=50)

# ç¬¬2é˜¶æ®µï¼šé‡æ’åºï¼ˆé«˜ç²¾ç¡®ç‡ï¼‰
top_results = rerank(candidates, query, k=5)
```

### 5.2 é‡æ’åºï¼ˆRe-rankingï¼‰

å¬å›å¤§é‡å€™é€‰åï¼Œç”¨æ›´ç²¾ç¡®çš„æ¨¡å‹é‡æ–°æ’åºã€‚

#### 5.2.1 åŸºäº LLM çš„é‡æ’åº

```python
"""
ä½¿ç”¨ LLM é‡æ’åº
"""
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor
from langchain_openai import ChatOpenAI

class RerankerRetrieval:
    """å¸¦é‡æ’åºçš„æ£€ç´¢å™¨"""

    def __init__(self, documents):
        embeddings = OpenAIEmbeddings()
        vectorstore = FAISS.from_documents(documents, embeddings)

        # åŸºç¡€æ£€ç´¢å™¨ï¼ˆå®½æ³›å¬å›ï¼‰
        base_retriever = vectorstore.as_retriever(
            search_kwargs={"k": 20}  # å¬å›20ä¸ªå€™é€‰
        )

        # LLM é‡æ’åºå™¨
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        compressor = LLMChainExtractor.from_llm(llm)

        # å‹ç¼©æ£€ç´¢å™¨ï¼ˆä¼šé‡æ’åºï¼‰
        self.retriever = ContextualCompressionRetriever(
            base_compressor=compressor,
            base_retriever=base_retriever
        )

    def search(self, query: str):
        """
        ä¸¤é˜¶æ®µæ£€ç´¢ï¼š
        1. å‘é‡å¬å› 20 ä¸ªå€™é€‰
        2. LLM é‡æ’åºï¼Œè¿”å›æœ€ç›¸å…³çš„
        """
        results = self.retriever.get_relevant_documents(query)
        return results

# ä½¿ç”¨
reranker = RerankerRetrieval(documents)
results = reranker.search("LangChain çš„æ ¸å¿ƒç»„ä»¶æ˜¯ä»€ä¹ˆï¼Ÿ")

print(f"é‡æ’åºåè¿”å› {len(results)} ä¸ªæ–‡æ¡£")
```

#### 5.2.2 åŸºäº Embedding çš„é‡æ’åº

```python
"""
ä½¿ç”¨ Embedding ç›¸ä¼¼åº¦é‡æ’åº
"""
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import EmbeddingsFilter

class EmbeddingReranker:
    """åŸºäº Embedding çš„é‡æ’åº"""

    def __init__(self, documents, similarity_threshold=0.7):
        embeddings = OpenAIEmbeddings()
        vectorstore = FAISS.from_documents(documents, embeddings)

        # åŸºç¡€æ£€ç´¢å™¨
        base_retriever = vectorstore.as_retriever(
            search_kwargs={"k": 30}  # å¬å›30ä¸ª
        )

        # Embedding è¿‡æ»¤å™¨ï¼ˆé‡æ’åºï¼‰
        embeddings_filter = EmbeddingsFilter(
            embeddings=embeddings,
            similarity_threshold=similarity_threshold  # ç›¸ä¼¼åº¦é˜ˆå€¼
        )

        # ç»„åˆ
        self.retriever = ContextualCompressionRetriever(
            base_compressor=embeddings_filter,
            base_retriever=base_retriever
        )

    def search(self, query: str):
        """
        æµç¨‹ï¼š
        1. å¬å›30ä¸ªå€™é€‰
        2. è®¡ç®—æ›´ç²¾ç¡®çš„ç›¸ä¼¼åº¦
        3. è¿‡æ»¤ä½äºé˜ˆå€¼çš„æ–‡æ¡£
        4. è¿”å›é«˜è´¨é‡ç»“æœ
        """
        return self.retriever.get_relevant_documents(query)

# ä½¿ç”¨
reranker = EmbeddingReranker(documents, similarity_threshold=0.75)
results = reranker.search("ä»€ä¹ˆæ˜¯ RAGï¼Ÿ")
```

### 5.3 å¤šè·¯å¬å›

ä»ä¸åŒæ¥æºå¬å›ï¼Œç„¶ååˆå¹¶å»é‡ã€‚

```python
"""
å¤šè·¯å¬å›ç­–ç•¥
"""
class MultiSourceRetrieval:
    """å¤šè·¯å¬å›æ£€ç´¢å™¨"""

    def __init__(self, vector_store, bm25_retriever, database_retriever=None):
        self.vector_retriever = vector_store.as_retriever(search_kwargs={"k": 10})
        self.bm25_retriever = bm25_retriever
        self.database_retriever = database_retriever

    def search(self, query: str):
        """
        å¤šè·¯å¬å›ç­–ç•¥
        """
        all_docs = []

        # è·¯å¾„1ï¼šå‘é‡æ£€ç´¢
        print("è·¯å¾„1ï¼šå‘é‡è¯­ä¹‰æ£€ç´¢...")
        vector_docs = self.vector_retriever.get_relevant_documents(query)
        all_docs.extend(vector_docs)
        print(f"  å¬å› {len(vector_docs)} ä¸ªæ–‡æ¡£")

        # è·¯å¾„2ï¼šå…³é”®è¯æ£€ç´¢
        print("è·¯å¾„2ï¼šå…³é”®è¯æ£€ç´¢...")
        keyword_docs = self.bm25_retriever.get_relevant_documents(query)
        all_docs.extend(keyword_docs)
        print(f"  å¬å› {len(keyword_docs)} ä¸ªæ–‡æ¡£")

        # è·¯å¾„3ï¼šæ•°æ®åº“æŸ¥è¯¢ï¼ˆå¯é€‰ï¼‰
        if self.database_retriever:
            print("è·¯å¾„3ï¼šæ•°æ®åº“æŸ¥è¯¢...")
            db_docs = self.database_retriever.get_relevant_documents(query)
            all_docs.extend(db_docs)
            print(f"  å¬å› {len(db_docs)} ä¸ªæ–‡æ¡£")

        # å»é‡ï¼ˆåŸºäºå†…å®¹hashï¼‰
        unique_docs = self._deduplicate(all_docs)

        print(f"\næ€»è®¡å¬å› {len(all_docs)} ä¸ªæ–‡æ¡£")
        print(f"å»é‡åå‰©ä½™ {len(unique_docs)} ä¸ªæ–‡æ¡£")

        return unique_docs

    def _deduplicate(self, documents):
        """å»é‡"""
        seen = set()
        unique = []

        for doc in documents:
            # ä½¿ç”¨å†…å®¹hashå»é‡
            content_hash = hash(doc.page_content)
            if content_hash not in seen:
                seen.add(content_hash)
                unique.append(doc)

        return unique

# ä½¿ç”¨
multi_retriever = MultiSourceRetrieval(
    vector_store=vectorstore,
    bm25_retriever=bm25_retriever
)

results = multi_retriever.search("LangChain æ•™ç¨‹")
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
è·¯å¾„1ï¼šå‘é‡è¯­ä¹‰æ£€ç´¢...
  å¬å› 10 ä¸ªæ–‡æ¡£
è·¯å¾„2ï¼šå…³é”®è¯æ£€ç´¢...
  å¬å› 10 ä¸ªæ–‡æ¡£
è·¯å¾„3ï¼šæ•°æ®åº“æŸ¥è¯¢...
  å¬å› 5 ä¸ªæ–‡æ¡£

æ€»è®¡å¬å› 25 ä¸ªæ–‡æ¡£
å»é‡åå‰©ä½™ 18 ä¸ªæ–‡æ¡£
```

### 5.4 æŸ¥è¯¢æ‰©å±•

æ‰©å±•ç”¨æˆ·æŸ¥è¯¢ï¼Œæé«˜å¬å›æ•ˆæœã€‚

```python
"""
æŸ¥è¯¢æ‰©å±•æŠ€æœ¯
"""
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage

class QueryExpansion:
    """æŸ¥è¯¢æ‰©å±•"""

    def __init__(self, retriever):
        self.retriever = retriever
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)

    def expand_query(self, query: str):
        """
        ä½¿ç”¨ LLM ç”ŸæˆæŸ¥è¯¢å˜ä½“
        """
        prompt = f"""åŸå§‹æŸ¥è¯¢: {query}

è¯·ç”Ÿæˆ3ä¸ªæ„æ€ç›¸è¿‘ä½†è¡¨è¿°ä¸åŒçš„æŸ¥è¯¢å˜ä½“ï¼š
1.
2.
3.
"""
        response = self.llm.invoke([HumanMessage(content=prompt)])

        # è§£æå˜ä½“ï¼ˆç®€åŒ–ç‰ˆï¼‰
        lines = response.content.strip().split('\n')
        variants = [line.split('. ', 1)[1] for line in lines if '. ' in line]

        return [query] + variants

    def search_with_expansion(self, query: str, k: int = 5):
        """
        ä½¿ç”¨æŸ¥è¯¢æ‰©å±•è¿›è¡Œæ£€ç´¢
        """
        # ç”ŸæˆæŸ¥è¯¢å˜ä½“
        queries = self.expand_query(query)
        print(f"åŸå§‹æŸ¥è¯¢: {query}")
        print(f"æ‰©å±•æŸ¥è¯¢: {queries[1:]}\n")

        # å¯¹æ¯ä¸ªæŸ¥è¯¢è¿›è¡Œæ£€ç´¢
        all_docs = []
        for q in queries:
            docs = self.retriever.get_relevant_documents(q)
            all_docs.extend(docs)

        # å»é‡å¹¶è¿”å›
        unique_docs = self._deduplicate(all_docs)
        return unique_docs[:k]

    def _deduplicate(self, documents):
        """å»é‡"""
        seen = set()
        unique = []
        for doc in documents:
            if doc.page_content not in seen:
                seen.add(doc.page_content)
                unique.append(doc)
        return unique

# ä½¿ç”¨
expander = QueryExpansion(retriever)
results = expander.search_with_expansion("LangChainæ€ä¹ˆç”¨ï¼Ÿ", k=5)
```

### 5.5 è¿‡æ»¤å’Œåå¤„ç†

å¬å›åè¿›è¡Œè´¨é‡è¿‡æ»¤ã€‚

```python
"""
å¬å›ç»“æœåå¤„ç†
"""
class RecallPostProcessor:
    """å¬å›åå¤„ç†å™¨"""

    def __init__(self, retriever):
        self.retriever = retriever

    def search_with_filters(
        self,
        query: str,
        min_length: int = 50,
        max_length: int = 2000,
        exclude_keywords: list = None
    ):
        """
        å¸¦è¿‡æ»¤çš„æ£€ç´¢

        å‚æ•°:
            query: æŸ¥è¯¢
            min_length: æœ€å°æ–‡æ¡£é•¿åº¦
            max_length: æœ€å¤§æ–‡æ¡£é•¿åº¦
            exclude_keywords: æ’é™¤åŒ…å«è¿™äº›å…³é”®è¯çš„æ–‡æ¡£
        """
        # å¬å›
        docs = self.retriever.get_relevant_documents(query)

        # è¿‡æ»¤
        filtered = []
        for doc in docs:
            content = doc.page_content

            # é•¿åº¦è¿‡æ»¤
            if len(content) < min_length or len(content) > max_length:
                continue

            # å…³é”®è¯è¿‡æ»¤
            if exclude_keywords:
                if any(kw in content for kw in exclude_keywords):
                    continue

            filtered.append(doc)

        print(f"å¬å› {len(docs)} ä¸ªæ–‡æ¡£")
        print(f"è¿‡æ»¤åå‰©ä½™ {len(filtered)} ä¸ªæ–‡æ¡£")

        return filtered

# ä½¿ç”¨
processor = RecallPostProcessor(retriever)

results = processor.search_with_filters(
    query="Python æ•™ç¨‹",
    min_length=100,           # è‡³å°‘100å­—ç¬¦
    max_length=1000,          # æœ€å¤š1000å­—ç¬¦
    exclude_keywords=["å¹¿å‘Š", "æ¨å¹¿"]  # æ’é™¤å¹¿å‘Š
)
```

---

## å…­ã€å¬å›è¯„ä¼°

### 6.1 è¯„ä¼°æŒ‡æ ‡

```python
"""
å¬å›è¯„ä¼°ç³»ç»Ÿ
"""
from typing import List, Dict
import numpy as np

class RecallEvaluator:
    """å¬å›è¯„ä¼°å™¨"""

    def __init__(self, retriever):
        self.retriever = retriever

    def evaluate(
        self,
        test_cases: List[Dict],
        k: int = 10
    ):
        """
        è¯„ä¼°å¬å›è´¨é‡

        å‚æ•°:
            test_cases: æµ‹è¯•æ¡ˆä¾‹åˆ—è¡¨ï¼Œæ ¼å¼ï¼š
                [
                    {
                        'query': 'æŸ¥è¯¢',
                        'relevant_ids': [1, 3, 5, 7]  # çœŸæ­£ç›¸å…³çš„æ–‡æ¡£ID
                    },
                    ...
                ]
            k: å¬å›æ•°é‡

        è¿”å›:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        recalls = []
        precisions = []
        f1_scores = []

        for case in test_cases:
            query = case['query']
            relevant_ids = set(case['relevant_ids'])

            # å¬å›æ–‡æ¡£
            docs = self.retriever.get_relevant_documents(query)
            retrieved_ids = set([doc.metadata.get('id') for doc in docs[:k]])

            # è®¡ç®—æŒ‡æ ‡
            true_positives = len(retrieved_ids & relevant_ids)

            recall = true_positives / len(relevant_ids) if relevant_ids else 0
            precision = true_positives / len(retrieved_ids) if retrieved_ids else 0
            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

            recalls.append(recall)
            precisions.append(precision)
            f1_scores.append(f1)

        # æ±‡æ€»ç»“æœ
        results = {
            'recall': np.mean(recalls),
            'precision': np.mean(precisions),
            'f1_score': np.mean(f1_scores),
            'num_queries': len(test_cases)
        }

        return results

    def detailed_evaluation(self, test_cases: List[Dict], k: int = 10):
        """è¯¦ç»†è¯„ä¼°æŠ¥å‘Š"""
        print("=" * 60)
        print("å¬å›è¯„ä¼°æŠ¥å‘Š")
        print("=" * 60)

        results = self.evaluate(test_cases, k)

        print(f"\næµ‹è¯•æŸ¥è¯¢æ•°é‡: {results['num_queries']}")
        print(f"å¬å›æ•°é‡ (k): {k}")
        print(f"\nå¹³å‡å¬å›ç‡: {results['recall']:.2%}")
        print(f"å¹³å‡ç²¾ç¡®ç‡: {results['precision']:.2%}")
        print(f"å¹³å‡ F1 åˆ†æ•°: {results['f1_score']:.2%}")

        # é€ä¸ªæ¡ˆä¾‹åˆ†æ
        print(f"\n{'='*60}")
        print("é€æ¡ˆä¾‹åˆ†æ:")
        print(f"{'='*60}")

        for i, case in enumerate(test_cases, 1):
            query = case['query']
            relevant_ids = set(case['relevant_ids'])

            docs = self.retriever.get_relevant_documents(query)
            retrieved_ids = set([doc.metadata.get('id') for doc in docs[:k]])

            tp = len(retrieved_ids & relevant_ids)
            recall = tp / len(relevant_ids)
            precision = tp / len(retrieved_ids) if retrieved_ids else 0

            print(f"\næŸ¥è¯¢ {i}: {query}")
            print(f"  ç›¸å…³æ–‡æ¡£: {len(relevant_ids)} ä¸ª")
            print(f"  å¬å›æ–‡æ¡£: {len(retrieved_ids)} ä¸ª")
            print(f"  æ­£ç¡®å¬å›: {tp} ä¸ª")
            print(f"  å¬å›ç‡: {recall:.2%}")
            print(f"  ç²¾ç¡®ç‡: {precision:.2%}")

        return results

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_cases = [
        {
            'query': 'LangChain æ ¸å¿ƒç»„ä»¶',
            'relevant_ids': [1, 5, 8, 12, 15]
        },
        {
            'query': 'RAG ç³»ç»Ÿå®ç°',
            'relevant_ids': [3, 7, 9, 14]
        },
        {
            'query': 'Agents å·¥ä½œåŸç†',
            'relevant_ids': [2, 6, 10, 11, 13]
        }
    ]

    # è¯„ä¼°
    evaluator = RecallEvaluator(retriever)
    results = evaluator.detailed_evaluation(test_cases, k=10)
```

### 6.2 A/B æµ‹è¯•

å¯¹æ¯”ä¸åŒå¬å›ç­–ç•¥çš„æ•ˆæœã€‚

```python
"""
A/B æµ‹è¯•æ¡†æ¶
"""
class RecallABTest:
    """å¬å›ç­–ç•¥ A/B æµ‹è¯•"""

    def __init__(self, retriever_a, retriever_b, name_a="ç­–ç•¥A", name_b="ç­–ç•¥B"):
        self.retriever_a = retriever_a
        self.retriever_b = retriever_b
        self.name_a = name_a
        self.name_b = name_b

    def compare(self, test_cases: List[Dict], k: int = 10):
        """
        å¯¹æ¯”ä¸¤ç§ç­–ç•¥
        """
        evaluator_a = RecallEvaluator(self.retriever_a)
        evaluator_b = RecallEvaluator(self.retriever_b)

        results_a = evaluator_a.evaluate(test_cases, k)
        results_b = evaluator_b.evaluate(test_cases, k)

        # æ‰“å°å¯¹æ¯”
        print("=" * 60)
        print("A/B æµ‹è¯•ç»“æœå¯¹æ¯”")
        print("=" * 60)

        print(f"\n{'æŒ‡æ ‡':<15} {self.name_a:<20} {self.name_b:<20} å·®å¼‚")
        print("-" * 60)

        metrics = ['recall', 'precision', 'f1_score']
        for metric in metrics:
            val_a = results_a[metric]
            val_b = results_b[metric]
            diff = val_b - val_a

            symbol = "ğŸ”º" if diff > 0 else "ğŸ”»" if diff < 0 else "="

            print(f"{metric:<15} {val_a:<20.2%} {val_b:<20.2%} {symbol} {abs(diff):.2%}")

        # ç»“è®º
        print("\n" + "=" * 60)
        if results_b['f1_score'] > results_a['f1_score']:
            winner = self.name_b
            improvement = (results_b['f1_score'] - results_a['f1_score']) / results_a['f1_score']
            print(f"ğŸ† èƒœè€…: {winner}")
            print(f"ğŸ“ˆ F1æå‡: {improvement:.1%}")
        else:
            winner = self.name_a
            improvement = (results_a['f1_score'] - results_b['f1_score']) / results_b['f1_score']
            print(f"ğŸ† èƒœè€…: {winner}")
            print(f"ğŸ“ˆ F1æå‡: {improvement:.1%}")

        return results_a, results_b

# ä½¿ç”¨ç¤ºä¾‹
# ç­–ç•¥Aï¼šçº¯å‘é‡æ£€ç´¢
retriever_a = vectorstore.as_retriever(search_kwargs={"k": 10})

# ç­–ç•¥Bï¼šæ··åˆæ£€ç´¢
retriever_b = EnsembleRetriever(
    retrievers=[dense_retriever, sparse_retriever],
    weights=[0.5, 0.5]
)

# A/B æµ‹è¯•
ab_test = RecallABTest(
    retriever_a,
    retriever_b,
    name_a="çº¯å‘é‡æ£€ç´¢",
    name_b="æ··åˆæ£€ç´¢"
)

results_a, results_b = ab_test.compare(test_cases, k=10)
```

---

## ä¸ƒã€å®æˆ˜æ¡ˆä¾‹

### 7.1 æ„å»ºé«˜è´¨é‡å¬å›ç³»ç»Ÿ

```python
"""
å®Œæ•´çš„é«˜è´¨é‡å¬å›ç³»ç»Ÿ
"""
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever
from langchain.retrievers.document_compressors import EmbeddingsFilter
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from typing import List, Dict
import time

class ProductionRecallSystem:
    """ç”Ÿäº§çº§å¬å›ç³»ç»Ÿ"""

    def __init__(
        self,
        documents_path: str,
        chunk_size: int = 500,
        chunk_overlap: int = 50
    ):
        """
        åˆå§‹åŒ–å¬å›ç³»ç»Ÿ

        å‚æ•°:
            documents_path: æ–‡æ¡£ç›®å½•è·¯å¾„
            chunk_size: æ–‡æ¡£åˆ†å—å¤§å°
            chunk_overlap: åˆ†å—é‡å å¤§å°
        """
        print("ğŸš€ åˆå§‹åŒ–å¬å›ç³»ç»Ÿ...")

        # 1. åŠ è½½æ–‡æ¡£
        print("  [1/5] åŠ è½½æ–‡æ¡£...")
        loader = DirectoryLoader(
            documents_path,
            glob="**/*.txt",
            loader_cls=TextLoader,
            loader_kwargs={'encoding': 'utf-8'}
        )
        documents = loader.load()
        print(f"    åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")

        # 2. æ–‡æ¡£åˆ†å‰²
        print("  [2/5] åˆ†å‰²æ–‡æ¡£...")
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )
        self.chunks = splitter.split_documents(documents)
        print(f"    åˆ†å‰²æˆ {len(self.chunks)} ä¸ªå—")

        # 3. åˆ›å»ºå‘é‡å­˜å‚¨
        print("  [3/5] åˆ›å»ºå‘é‡ç´¢å¼•...")
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = FAISS.from_documents(
            self.chunks,
            self.embeddings
        )
        print("    âœ… å‘é‡ç´¢å¼•åˆ›å»ºå®Œæˆ")

        # 4. åˆ›å»ºå¤šå±‚æ£€ç´¢å™¨
        print("  [4/5] é…ç½®æ£€ç´¢ç­–ç•¥...")
        self._setup_retrievers()
        print("    âœ… æ£€ç´¢å™¨é…ç½®å®Œæˆ")

        # 5. æ€§èƒ½ç›‘æ§
        print("  [5/5] å¯åŠ¨ç›‘æ§...")
        self.stats = {
            'total_queries': 0,
            'total_time': 0,
            'recalls': []
        }
        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ\n")

    def _setup_retrievers(self):
        """é…ç½®å¤šå±‚æ£€ç´¢ç­–ç•¥"""

        # ç¬¬1å±‚ï¼šå®½æ³›å¬å›ï¼ˆé«˜å¬å›ç‡ï¼‰
        self.broad_retriever = self.vectorstore.as_retriever(
            search_kwargs={"k": 50}  # å¬å›50ä¸ªå€™é€‰
        )

        # ç¬¬2å±‚ï¼šç²¾ç¡®è¿‡æ»¤ï¼ˆé«˜ç²¾ç¡®ç‡ï¼‰
        embeddings_filter = EmbeddingsFilter(
            embeddings=self.embeddings,
            similarity_threshold=0.7
        )

        self.precise_retriever = ContextualCompressionRetriever(
            base_compressor=embeddings_filter,
            base_retriever=self.broad_retriever
        )

    def recall(
        self,
        query: str,
        k: int = 5,
        strategy: str = "precise"
    ) -> List:
        """
        å¬å›æ–‡æ¡£

        å‚æ•°:
            query: æŸ¥è¯¢
            k: è¿”å›æ•°é‡
            strategy: å¬å›ç­–ç•¥
                - "broad": å®½æ³›å¬å›ï¼ˆé«˜å¬å›ç‡ï¼‰
                - "precise": ç²¾ç¡®å¬å›ï¼ˆé«˜ç²¾ç¡®ç‡ï¼‰

        è¿”å›:
            å¬å›çš„æ–‡æ¡£åˆ—è¡¨
        """
        start_time = time.time()

        # é€‰æ‹©ç­–ç•¥
        if strategy == "broad":
            docs = self.broad_retriever.get_relevant_documents(query)
        else:  # precise
            docs = self.precise_retriever.get_relevant_documents(query)

        # é™åˆ¶è¿”å›æ•°é‡
        results = docs[:k]

        # è®°å½•ç»Ÿè®¡
        elapsed = time.time() - start_time
        self.stats['total_queries'] += 1
        self.stats['total_time'] += elapsed

        return results

    def recall_with_details(
        self,
        query: str,
        k: int = 5
    ) -> Dict:
        """
        å¬å›å¹¶è¿”å›è¯¦ç»†ä¿¡æ¯
        """
        start_time = time.time()

        # å¬å›
        docs = self.precise_retriever.get_relevant_documents(query)
        results = docs[:k]

        # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
        docs_with_scores = self.vectorstore.similarity_search_with_score(
            query, k=k
        )

        elapsed = time.time() - start_time

        return {
            'query': query,
            'documents': results,
            'scores': [score for _, score in docs_with_scores],
            'count': len(results),
            'elapsed_time': elapsed
        }

    def get_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        avg_time = (
            self.stats['total_time'] / self.stats['total_queries']
            if self.stats['total_queries'] > 0 else 0
        )

        return {
            'total_queries': self.stats['total_queries'],
            'total_time': self.stats['total_time'],
            'average_time': avg_time
        }

    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_stats()

        print("=" * 60)
        print("å¬å›ç³»ç»Ÿæ€§èƒ½ç»Ÿè®¡")
        print("=" * 60)
        print(f"æ€»æŸ¥è¯¢æ•°: {stats['total_queries']}")
        print(f"æ€»è€—æ—¶: {stats['total_time']:.2f}ç§’")
        print(f"å¹³å‡è€—æ—¶: {stats['average_time']:.3f}ç§’/æŸ¥è¯¢")
        print("=" * 60)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–ç³»ç»Ÿ
    recall_system = ProductionRecallSystem(
        documents_path="./docs",
        chunk_size=500,
        chunk_overlap=50
    )

    # æµ‹è¯•å¬å›
    queries = [
        "LangChain çš„æ ¸å¿ƒç»„ä»¶æœ‰å“ªäº›ï¼Ÿ",
        "å¦‚ä½•å®ç° RAG ç³»ç»Ÿï¼Ÿ",
        "Agents çš„å·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ"
    ]

    for query in queries:
        print(f"\næŸ¥è¯¢: {query}")
        print("-" * 60)

        # å¬å›
        result = recall_system.recall_with_details(query, k=3)

        print(f"å¬å›æ•°é‡: {result['count']}")
        print(f"è€—æ—¶: {result['elapsed_time']:.3f}ç§’")
        print("\nå¬å›ç»“æœ:")

        for i, (doc, score) in enumerate(zip(result['documents'], result['scores']), 1):
            preview = doc.page_content[:100].replace('\n', ' ')
            print(f"  {i}. [ç›¸ä¼¼åº¦: {score:.4f}] {preview}...")

    # æ‰“å°ç»Ÿè®¡
    print("\n")
    recall_system.print_stats()
```

---

## å…«ã€æœ€ä½³å®è·µæ€»ç»“

### 8.1 å¬å›ç­–ç•¥é€‰æ‹©

```mermaid
graph TD
    A[é€‰æ‹©å¬å›ç­–ç•¥] --> B{åœºæ™¯åˆ†æ}

    B -->|é€šç”¨åœºæ™¯| C[æ··åˆæ£€ç´¢]
    B -->|æ¦‚å¿µæŸ¥è¯¢| D[å¯†é›†æ£€ç´¢]
    B -->|ç²¾ç¡®åŒ¹é…| E[ç¨€ç–æ£€ç´¢]

    C --> F[å®½æ³›å¬å› + é‡æ’åº]
    D --> G[çº¯å‘é‡ç›¸ä¼¼åº¦]
    E --> H[BM25å…³é”®è¯]

    style C fill:#81C784
    style D fill:#FFE082
    style E fill:#FFB74D
```

### 8.2 å‚æ•°æ¨è

| å‚æ•° | æ¨èå€¼ | è¯´æ˜ |
|------|--------|------|
| **å¬å›æ•°é‡ k** | ç¬¬1é˜¶æ®µ: 20-50<br/>ç¬¬2é˜¶æ®µ: 5-10 | å…ˆå®½åç²¾ |
| **chunk_size** | 500-1000 | æ ¹æ®æ–‡æ¡£ç±»å‹è°ƒæ•´ |
| **chunk_overlap** | 50-200 | 10%-20% çš„ chunk_size |
| **ç›¸ä¼¼åº¦é˜ˆå€¼** | 0.7-0.8 | è¿‡æ»¤ä½è´¨é‡ç»“æœ |
| **æ··åˆæƒé‡** | dense: 0.5<br/>sparse: 0.5 | å‡è¡¡ç­–ç•¥ |

### 8.3 ä¼˜åŒ–æ£€æŸ¥æ¸…å•

âœ… **å¬å›ä¼˜åŒ–**
- [ ] ä½¿ç”¨æ··åˆæ£€ç´¢ç­–ç•¥
- [ ] å®æ–½ä¸¤é˜¶æ®µå¬å›ï¼ˆå®½æ³›+ç²¾ç¡®ï¼‰
- [ ] æ·»åŠ æŸ¥è¯¢æ‰©å±•
- [ ] å¤šè·¯å¬å›åˆå¹¶

âœ… **è´¨é‡æ§åˆ¶**
- [ ] è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼
- [ ] æ–‡æ¡£é•¿åº¦è¿‡æ»¤
- [ ] å…³é”®è¯é»‘åå•
- [ ] é‡æ’åºä¼˜åŒ–

âœ… **æ€§èƒ½ä¼˜åŒ–**
- [ ] å‘é‡ç´¢å¼•ä¼˜åŒ–ï¼ˆHNSWï¼‰
- [ ] ç¼“å­˜çƒ­é—¨æŸ¥è¯¢
- [ ] å¼‚æ­¥å¬å›
- [ ] æ‰¹é‡å¤„ç†

âœ… **ç›‘æ§è¯„ä¼°**
- [ ] å¬å›ç‡ç›‘æ§
- [ ] ç²¾ç¡®ç‡ç›‘æ§
- [ ] å“åº”æ—¶é—´ç›‘æ§
- [ ] A/B æµ‹è¯•å¯¹æ¯”

---

## ä¹ã€å¸¸è§é—®é¢˜ FAQ

### Q1: å¬å›ç‡å’Œç²¾ç¡®ç‡å“ªä¸ªæ›´é‡è¦ï¼Ÿ

**ç­”ï¼š** å–å†³äºåº”ç”¨åœºæ™¯ã€‚

- **æœç´¢å¼•æ“**ï¼šå¬å›ç‡æ›´é‡è¦
  - ç”¨æˆ·æœŸæœ›çœ‹åˆ°æ‰€æœ‰ç›¸å…³ç»“æœ
  - å¯ä»¥é€šè¿‡æ’åºæå‡å‰æ’è´¨é‡

- **é—®ç­”ç³»ç»Ÿ**ï¼šç²¾ç¡®ç‡æ›´é‡è¦
  - é”™è¯¯ç­”æ¡ˆä¼šé™ä½ä¿¡ä»»åº¦
  - å®å¯è¯´"ä¸çŸ¥é“"ï¼Œä¸è¦ç»™é”™è¯¯ä¿¡æ¯

- **æ¨èç³»ç»Ÿ**ï¼šéœ€è¦å¹³è¡¡
  - æ—¢è¦è¦†ç›–ç”¨æˆ·å…´è¶£ï¼Œåˆè¦ä¿è¯æ¨èè´¨é‡

### Q2: å¦‚ä½•æé«˜å¬å›ç‡ï¼Ÿ

**æ–¹æ³•ï¼š**
1. å¢åŠ å¬å›æ•°é‡ï¼ˆkå€¼ï¼‰
2. é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼
3. ä½¿ç”¨æŸ¥è¯¢æ‰©å±•
4. å¤šè·¯å¬å›åˆå¹¶
5. ä¼˜åŒ–æ–‡æ¡£åˆ†å‰²ç­–ç•¥

### Q3: å¬å›å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ

**ä¼˜åŒ–æ–¹æ¡ˆï¼š**
1. ä½¿ç”¨æ›´å¿«çš„å‘é‡æ•°æ®åº“ï¼ˆå¦‚ FAISS + HNSWï¼‰
2. å‡å° embedding ç»´åº¦
3. ç¼“å­˜çƒ­é—¨æŸ¥è¯¢
4. å¼‚æ­¥å¬å›
5. é¢„å¬å› + ç¼“å­˜

### Q4: å¦‚ä½•è¯„ä¼°å¬å›æ•ˆæœï¼Ÿ

**è¯„ä¼°æ–¹æ³•ï¼š**
1. å‡†å¤‡æµ‹è¯•é›†ï¼ˆæŸ¥è¯¢ + ç›¸å…³æ–‡æ¡£IDï¼‰
2. è®¡ç®—å¬å›ç‡ã€ç²¾ç¡®ç‡ã€F1
3. è¿›è¡Œ A/B æµ‹è¯•
4. ç”¨æˆ·åé¦ˆæ”¶é›†

### Q5: æ··åˆæ£€ç´¢çš„æƒé‡å¦‚ä½•è°ƒæ•´ï¼Ÿ

**è°ƒæ•´ç­–ç•¥ï¼š**
```python
# æ ¹æ®æŸ¥è¯¢ç±»å‹åŠ¨æ€è°ƒæ•´
if is_concept_query(query):
    weights = [0.7, 0.3]  # è¯­ä¹‰ä¸ºä¸»
elif is_keyword_query(query):
    weights = [0.3, 0.7]  # å…³é”®è¯ä¸ºä¸»
else:
    weights = [0.5, 0.5]  # å‡è¡¡
```

---

## åã€å­¦ä¹ èµ„æº

### å®˜æ–¹æ–‡æ¡£
- [LangChain Retrievers æ–‡æ¡£](https://python.langchain.com/docs/modules/data_connection/retrievers/)
- [å‘é‡å­˜å‚¨æ–‡æ¡£](https://python.langchain.com/docs/modules/data_connection/vectorstores/)

### æ¨èé˜…è¯»
- [Dense Passage Retrieval è®ºæ–‡](https://arxiv.org/abs/2004.04906)
- [BM25 ç®—æ³•è¯¦è§£](https://en.wikipedia.org/wiki/Okapi_BM25)
- [RAG ç³»ç»Ÿæœ€ä½³å®è·µ](https://blog.langchain.dev/retrieval/)

### ç›¸å…³æŠ€æœ¯
- FAISS: å‘é‡ç›¸ä¼¼åº¦æœç´¢åº“
- Chroma: å¼€æºå‘é‡æ•°æ®åº“
- Pinecone: äº‘ç«¯å‘é‡æ•°æ®åº“

---

## æ€»ç»“

**å¬å›çš„æœ¬è´¨ï¼š**
- ğŸ“š æ‰¾åˆ°æ‰€æœ‰å¯èƒ½ç›¸å…³çš„ä¿¡æ¯ï¼ˆé«˜å¬å›ç‡ï¼‰
- ğŸ¯ ç”¨é‡æ’åºæå‡ç»“æœè´¨é‡ï¼ˆé«˜ç²¾ç¡®ç‡ï¼‰
- âš–ï¸ åœ¨å¬å›å’Œç²¾ç¡®ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ç‚¹

**å…³é”®è¦ç‚¹ï¼š**
1. å¬å›æ˜¯ RAG ç³»ç»Ÿçš„åŸºç¡€ï¼Œå†³å®šäº†ç­”æ¡ˆçš„ä¸Šé™
2. æ¨èä½¿ç”¨ä¸¤é˜¶æ®µç­–ç•¥ï¼šå®½æ³›å¬å› + ç²¾ç¡®é‡æ’
3. æ··åˆæ£€ç´¢é€šå¸¸ä¼˜äºå•ä¸€ç­–ç•¥
4. éœ€è¦æ ¹æ®åœºæ™¯è°ƒæ•´å‚æ•°å’Œç­–ç•¥
5. æŒç»­ç›‘æ§å’Œä¼˜åŒ–å¬å›æ•ˆæœ

**ä¸‹ä¸€æ­¥å­¦ä¹ ï¼š**
- æ·±å…¥å­¦ä¹ å‘é‡æ•°æ®åº“ä¼˜åŒ–
- ç ”ç©¶é«˜çº§é‡æ’åºæŠ€æœ¯
- æ¢ç´¢å¤šæ¨¡æ€å¬å›ï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰
- å®è·µå¤§è§„æ¨¡æ£€ç´¢ç³»ç»Ÿ

---

**ç¥å­¦ä¹ é¡ºåˆ©ï¼** ğŸ¯

å¦‚æœ‰é—®é¢˜ï¼Œæ¬¢è¿åœ¨ç¤¾åŒºè®¨è®ºï¼
