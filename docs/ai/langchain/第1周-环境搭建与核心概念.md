---
title: ç¬¬1å‘¨ - ç¯å¢ƒæ­å»ºä¸æ ¸å¿ƒæ¦‚å¿µ
date: 2025-01-15
permalink: /ai/langchain/week1-setup-core-concepts.html
tags:
  - LangChain
  - Python
  - AI
  - å…¥é—¨æ•™ç¨‹
categories:
  - AI
  - LangChain
---

# ç¬¬1å‘¨ï¼šç¯å¢ƒæ­å»ºä¸æ ¸å¿ƒæ¦‚å¿µ

::: tip æœ¬å‘¨å­¦ä¹ ç›®æ ‡
- ğŸ”§ å®Œæˆ Python å’Œ LangChain å¼€å‘ç¯å¢ƒæ­å»º
- ğŸ§  ç†è§£ LangChain æ ¸å¿ƒæ¶æ„å’Œè®¾è®¡æ€æƒ³
- ğŸ’» è¿è¡Œç¬¬ä¸€ä¸ª LangChain ç¨‹åº
- ğŸ“š æŒæ¡åŸºç¡€è°ƒè¯•æŠ€å·§å’Œå¸¸è§é—®é¢˜è§£å†³æ–¹æ³•
:::

## ä¸€ã€ç¯å¢ƒæ­å»º

### 1.1 ä»€ä¹ˆæ˜¯å¼€å‘ç¯å¢ƒï¼Ÿ

**å¼€å‘ç¯å¢ƒ**æ˜¯æŒ‡è¿è¡Œå’Œå¼€å‘ LangChain åº”ç”¨æ‰€éœ€çš„è½¯ä»¶å’Œå·¥å…·é›†åˆã€‚ä¸€ä¸ªå®Œå–„çš„å¼€å‘ç¯å¢ƒåŒ…æ‹¬ï¼š

- **Python è§£é‡Šå™¨**ï¼šæ‰§è¡Œ Python ä»£ç çš„æ ¸å¿ƒå¼•æ“
- **åŒ…ç®¡ç†å·¥å…·**ï¼šç®¡ç†ç¬¬ä¸‰æ–¹åº“ï¼ˆå¦‚ pipã€condaï¼‰
- **è™šæ‹Ÿç¯å¢ƒ**ï¼šéš”ç¦»ä¸åŒé¡¹ç›®çš„ä¾èµ–
- **ä»£ç ç¼–è¾‘å™¨/IDE**ï¼šç¼–å†™å’Œè°ƒè¯•ä»£ç çš„å·¥å…·
- **APIå¯†é’¥**ï¼šè®¿é—® LLM æœåŠ¡çš„å‡­è¯

### 1.2 ç³»ç»Ÿè¦æ±‚

| é¡¹ç›® | æœ€ä½è¦æ±‚ | æ¨èé…ç½® |
|------|---------|---------|
| **æ“ä½œç³»ç»Ÿ** | Windows 10/macOS 10.14/Ubuntu 18.04 | Windows 11/macOS 13+/Ubuntu 22.04 |
| **Python ç‰ˆæœ¬** | Python 3.8 | Python 3.10+ |
| **å†…å­˜** | 4GB RAM | 8GB+ RAM |
| **ç£ç›˜ç©ºé—´** | 2GB å¯ç”¨ç©ºé—´ | 5GB+ å¯ç”¨ç©ºé—´ |
| **ç½‘ç»œ** | ç¨³å®šçš„äº’è”ç½‘è¿æ¥ | - |

### 1.3 è¯¦ç»†å®‰è£…æ­¥éª¤

#### æ­¥éª¤1ï¼šå®‰è£… Python

**Windows ç”¨æˆ·ï¼š**

```bash
# 1. è®¿é—® Python å®˜ç½‘ä¸‹è½½ Python 3.10+
# https://www.python.org/downloads/

# 2. å®‰è£…æ—¶åŠ¡å¿…å‹¾é€‰ "Add Python to PATH"

# 3. éªŒè¯å®‰è£…
python --version  # åº”è¾“å‡ºï¼šPython 3.10.x
pip --version     # åº”è¾“å‡ºï¼špip 23.x.x
```

**macOS ç”¨æˆ·ï¼š**

```bash
# æ–¹æ³•1ï¼šä½¿ç”¨ Homebrewï¼ˆæ¨èï¼‰
brew install python@3.10

# æ–¹æ³•2ï¼šä½¿ç”¨ pyenvï¼ˆé€‚åˆéœ€è¦ç®¡ç†å¤šä¸ª Python ç‰ˆæœ¬ï¼‰
brew install pyenv
pyenv install 3.10.11
pyenv global 3.10.11

# éªŒè¯å®‰è£…
python3 --version
pip3 --version
```

**Linux ç”¨æˆ·ï¼š**

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install python3.10 python3.10-venv python3-pip

# CentOS/RHEL
sudo yum install python310 python310-pip

# éªŒè¯å®‰è£…
python3.10 --version
pip3 --version
```

#### æ­¥éª¤2ï¼šåˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# 1. åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir langchain-learning
cd langchain-learning

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
# Windows
python -m venv venv

# macOS/Linux
python3 -m venv venv

# 3. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate

# æ¿€æ´»æˆåŠŸåï¼Œå‘½ä»¤è¡Œå‰é¢ä¼šæ˜¾ç¤º (venv)
```

::: warning é‡è¦æç¤º
**ä¸ºä»€ä¹ˆéœ€è¦è™šæ‹Ÿç¯å¢ƒï¼Ÿ**

1. **ä¾èµ–éš”ç¦»**ï¼šä¸åŒé¡¹ç›®ä½¿ç”¨ä¸åŒç‰ˆæœ¬çš„åº“ï¼Œé¿å…å†²çª
2. **ç¯å¢ƒæ¸…æ´**ï¼šä¸æ±¡æŸ“ç³»ç»Ÿçš„å…¨å±€ Python ç¯å¢ƒ
3. **ä¾¿äºè¿ç§»**ï¼šé€šè¿‡ requirements.txt è½»æ¾å¤åˆ¶ç¯å¢ƒ

**æœ€ä½³å®è·µ**ï¼šæ¯ä¸ªé¡¹ç›®éƒ½åº”è¯¥ä½¿ç”¨ç‹¬ç«‹çš„è™šæ‹Ÿç¯å¢ƒï¼
:::

#### æ­¥éª¤3ï¼šå®‰è£… LangChain

```bash
# 1. å‡çº§ pipï¼ˆæ¨èï¼‰
pip install --upgrade pip

# 2. å®‰è£… LangChain æ ¸å¿ƒåº“
pip install langchain==0.1.0

# 3. å®‰è£… LangChain Community æ‰©å±•ï¼ˆåŒ…å«å¸¸ç”¨é›†æˆï¼‰
pip install langchain-community==0.0.10

# 4. å®‰è£… OpenAI é›†æˆ
pip install langchain-openai==0.0.2

# 5. å®‰è£…å…¶ä»–å¸¸ç”¨ä¾èµ–
pip install python-dotenv==1.0.0  # ç¯å¢ƒå˜é‡ç®¡ç†
pip install tiktoken==0.5.2       # Token è®¡æ•°å·¥å…·

# 6. éªŒè¯å®‰è£…
pip list | grep langchain
```

**ä¸€é”®å®‰è£…å‘½ä»¤**ï¼ˆæ¨èï¼‰ï¼š

```bash
# åˆ›å»º requirements.txt æ–‡ä»¶
cat > requirements.txt << EOF
langchain==0.1.0
langchain-community==0.0.10
langchain-openai==0.0.2
python-dotenv==1.0.0
tiktoken==0.5.2
EOF

# å®‰è£…æ‰€æœ‰ä¾èµ–
pip install -r requirements.txt
```

#### æ­¥éª¤4ï¼šé…ç½® API å¯†é’¥

```bash
# 1. åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶
touch .env

# 2. ç¼–è¾‘ .env æ–‡ä»¶ï¼Œæ·»åŠ  API å¯†é’¥
# ä½¿ç”¨æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€ .envï¼Œæ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š
```

```.env
# OpenAI API å¯†é’¥ï¼ˆä» https://platform.openai.com/api-keys è·å–ï¼‰
OPENAI_API_KEY=sk-your-api-key-here

# å¯é€‰ï¼šè®¾ç½® API ä»£ç†ï¼ˆå›½å†…ç”¨æˆ·å¯èƒ½éœ€è¦ï¼‰
# OPENAI_API_BASE=https://your-proxy-url.com/v1

# å¯é€‰ï¼šå…¶ä»– LLM æœåŠ¡çš„å¯†é’¥
# ANTHROPIC_API_KEY=your-anthropic-key
# GOOGLE_API_KEY=your-google-key
```

::: danger å®‰å…¨è­¦å‘Š
**API å¯†é’¥å®‰å…¨æœ€ä½³å®è·µï¼š**

1. âŒ **ç»ä¸è¦**å°† `.env` æ–‡ä»¶æäº¤åˆ° Git ä»“åº“
2. âœ… å°† `.env` æ·»åŠ åˆ° `.gitignore`
3. âœ… ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†å·¥å…·
4. âœ… å®šæœŸè½®æ¢ API å¯†é’¥
5. âœ… ä¸ºä¸åŒç¯å¢ƒä½¿ç”¨ä¸åŒçš„å¯†é’¥ï¼ˆå¼€å‘/æµ‹è¯•/ç”Ÿäº§ï¼‰

```bash
# åˆ›å»º .gitignore æ–‡ä»¶
echo ".env" >> .gitignore
echo "venv/" >> .gitignore
echo "__pycache__/" >> .gitignore
```
:::

#### æ­¥éª¤5ï¼šéªŒè¯ç¯å¢ƒ

åˆ›å»ºæµ‹è¯•è„šæœ¬ `test_setup.py`ï¼š

```python
"""
ç¯å¢ƒéªŒè¯è„šæœ¬
åŠŸèƒ½ï¼šæ£€æŸ¥æ‰€æœ‰ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…
"""
import sys

def check_python_version():
    """æ£€æŸ¥ Python ç‰ˆæœ¬"""
    version = sys.version_info
    print(f"âœ… Python ç‰ˆæœ¬: {version.major}.{version.minor}.{version.micro}")
    if version.major == 3 and version.minor >= 8:
        print("   ç‰ˆæœ¬ç¬¦åˆè¦æ±‚ (>= 3.8)")
        return True
    else:
        print("   âŒ ç‰ˆæœ¬è¿‡ä½ï¼Œè¯·å‡çº§åˆ° Python 3.8+")
        return False

def check_packages():
    """æ£€æŸ¥å¿…è¦çš„åŒ…æ˜¯å¦å·²å®‰è£…"""
    required_packages = {
        "langchain": "LangChain æ ¸å¿ƒåº“",
        "langchain_community": "LangChain ç¤¾åŒºæ‰©å±•",
        "langchain_openai": "OpenAI é›†æˆ",
        "dotenv": "ç¯å¢ƒå˜é‡ç®¡ç†",
        "tiktoken": "Token è®¡æ•°å·¥å…·"
    }

    all_ok = True
    for package, description in required_packages.items():
        try:
            __import__(package)
            print(f"âœ… {package:20s} - {description}")
        except ImportError:
            print(f"âŒ {package:20s} - æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install {package}")
            all_ok = False

    return all_ok

def check_env_file():
    """æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    import os
    if os.path.exists(".env"):
        print("âœ… .env æ–‡ä»¶å­˜åœ¨")
        return True
    else:
        print("âŒ .env æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·åˆ›å»ºå¹¶æ·»åŠ  API å¯†é’¥")
        return False

def main():
    print("=" * 60)
    print("LangChain ç¯å¢ƒæ£€æŸ¥")
    print("=" * 60)

    results = [
        check_python_version(),
        check_packages(),
        check_env_file()
    ]

    print("=" * 60)
    if all(results):
        print("ğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼ç¯å¢ƒé…ç½®å®Œæˆï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºä¿®å¤é—®é¢˜")
    print("=" * 60)

if __name__ == "__main__":
    main()
```

è¿è¡ŒéªŒè¯ï¼š

```bash
python test_setup.py
```

**é¢„æœŸè¾“å‡ºï¼š**

```
============================================================
LangChain ç¯å¢ƒæ£€æŸ¥
============================================================
âœ… Python ç‰ˆæœ¬: 3.10.11
   ç‰ˆæœ¬ç¬¦åˆè¦æ±‚ (>= 3.8)
âœ… langchain          - LangChain æ ¸å¿ƒåº“
âœ… langchain_community - LangChain ç¤¾åŒºæ‰©å±•
âœ… langchain_openai   - OpenAI é›†æˆ
âœ… dotenv             - ç¯å¢ƒå˜é‡ç®¡ç†
âœ… tiktoken           - Token è®¡æ•°å·¥å…·
âœ… .env æ–‡ä»¶å­˜åœ¨
============================================================
ğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼ç¯å¢ƒé…ç½®å®Œæˆï¼
============================================================
```

### 1.4 å¸¸è§å®‰è£…é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

<details>
<summary><b>é—®é¢˜1ï¼špip install é€Ÿåº¦æ…¢æˆ–è¶…æ—¶</b></summary>

**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨å›½å†…é•œåƒæº

```bash
# ä¸´æ—¶ä½¿ç”¨é•œåƒæº
pip install langchain -i https://pypi.tuna.tsinghua.edu.cn/simple

# æ°¸ä¹…é…ç½®é•œåƒæº
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
```
</details>

<details>
<summary><b>é—®é¢˜2ï¼šModuleNotFoundError: No module named 'langchain'</b></summary>

**åŸå› **ï¼šè™šæ‹Ÿç¯å¢ƒæœªæ¿€æ´»æˆ–åœ¨é”™è¯¯çš„ç¯å¢ƒä¸­å®‰è£…

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# 1. ç¡®è®¤è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»ï¼ˆå‘½ä»¤è¡Œå‰åº”æœ‰ (venv) æ ‡è¯†ï¼‰
# 2. é‡æ–°å®‰è£…
pip install langchain

# 3. éªŒè¯å®‰è£…ä½ç½®
pip show langchain
```
</details>

<details>
<summary><b>é—®é¢˜3ï¼šPermission denied é”™è¯¯</b></summary>

**åŸå› **ï¼šå°è¯•å®‰è£…åˆ°ç³»ç»Ÿ Python ç›®å½•

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# ä¸è¦ä½¿ç”¨ sudo pip install
# åº”è¯¥ï¼š
# 1. ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
# 2. æˆ–ä½¿ç”¨ç”¨æˆ·å®‰è£…
pip install --user langchain
```
</details>

<details>
<summary><b>é—®é¢˜4ï¼šSSL Certificate Error</b></summary>

**åŸå› **ï¼šç½‘ç»œæˆ–è¯ä¹¦é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ–¹æ³•1ï¼šå‡çº§ pip å’Œ certifi
pip install --upgrade pip certifi

# æ–¹æ³•2ï¼šä¸´æ—¶ç¦ç”¨ SSL éªŒè¯ï¼ˆä¸æ¨èï¼‰
pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org langchain
```
</details>

---

## äºŒã€LangChain æ ¸å¿ƒæ¦‚å¿µ

### 2.1 ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ

**LangChain** æ˜¯ä¸€ä¸ªç”¨äºå¼€å‘ç”±è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚å®ƒæä¾›äº†æ ‡å‡†åŒ–çš„æ¥å£å’Œå·¥å…·é“¾ï¼Œè®©å¼€å‘è€…èƒ½å¤Ÿè½»æ¾æ„å»ºå¤æ‚çš„ AI åº”ç”¨ã€‚

#### æ ¸å¿ƒä»·å€¼

```mermaid
graph LR
    A[åŸå§‹ LLM API] -->|å¤æ‚| B[æ‰‹åŠ¨ç®¡ç†]
    B --> C[é‡å¤ä»£ç ]
    C --> D[éš¾ä»¥ç»´æŠ¤]

    E[LangChain] -->|ç®€åŒ–| F[æ ‡å‡†åŒ–æ¥å£]
    F --> G[å¯å¤ç”¨ç»„ä»¶]
    G --> H[æ˜“äºæ‰©å±•]

    style E fill:#4CAF50
    style H fill:#4CAF50
    style A fill:#FF9800
    style D fill:#FF9800
```

**LangChain è§£å†³çš„æ ¸å¿ƒé—®é¢˜ï¼š**

1. **ç»Ÿä¸€æ¥å£**ï¼šä¸åŒ LLM æä¾›å•†ï¼ˆOpenAIã€Anthropicã€Googleï¼‰æœ‰ä¸åŒçš„ APIï¼ŒLangChain æä¾›ç»Ÿä¸€æŠ½è±¡
2. **ç»„ä»¶åŒ–å¼€å‘**ï¼šå°† Promptsã€Modelsã€Memoryã€Tools ç­‰æ¨¡å—åŒ–ï¼Œæé«˜ä»£ç å¤ç”¨æ€§
3. **æµç¨‹ç¼–æ’**ï¼šé€šè¿‡ Chains å’Œ Agents ç®¡ç†å¤æ‚çš„è°ƒç”¨æµç¨‹
4. **ç”Ÿæ€é›†æˆ**ï¼šå†…ç½®ä¸æ•°ç™¾ä¸ªå·¥å…·å’ŒæœåŠ¡çš„é›†æˆï¼ˆå‘é‡æ•°æ®åº“ã€æ–‡æ¡£åŠ è½½å™¨ã€æœç´¢å¼•æ“ç­‰ï¼‰

### 2.2 æ ¸å¿ƒæ¶æ„

LangChain é‡‡ç”¨åˆ†å±‚æ¶æ„è®¾è®¡ï¼š

```mermaid
graph TB
    A[åº”ç”¨å±‚<br/>Your Application] --> B[ç¼–æ’å±‚<br/>Chains & Agents]
    B --> C[ç»„ä»¶å±‚<br/>Components]
    C --> D1[Models<br/>æ¨¡å‹]
    C --> D2[Prompts<br/>æç¤ºè¯]
    C --> D3[Memory<br/>è®°å¿†]
    C --> D4[Tools<br/>å·¥å…·]
    C --> D5[Documents<br/>æ–‡æ¡£]
    D1 --> E[é›†æˆå±‚<br/>Integrations]
    D2 --> E
    D3 --> E
    D4 --> E
    D5 --> E
    E --> F1[OpenAI]
    E --> F2[Anthropic]
    E --> F3[Vector DBs]
    E --> F4[APIs]

    style A fill:#E3F2FD
    style B fill:#BBDEFB
    style C fill:#90CAF9
    style E fill:#64B5F6
    style F1 fill:#42A5F5
    style F2 fill:#42A5F5
    style F3 fill:#42A5F5
    style F4 fill:#42A5F5
```

#### 2.2.1 ç»„ä»¶å±‚è¯¦è§£

| ç»„ä»¶ | ä½œç”¨ | ç¤ºä¾‹ |
|------|------|------|
| **Models** | ä¸ LLM äº¤äº’çš„æ¥å£ | ChatOpenAI, Anthropic |
| **Prompts** | ç®¡ç†å’Œä¼˜åŒ–è¾“å…¥æ–‡æœ¬ | PromptTemplate, ChatPromptTemplate |
| **Memory** | å­˜å‚¨å¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡ | ConversationBufferMemory |
| **Tools** | æ‰©å±• LLM èƒ½åŠ›çš„å¤–éƒ¨å·¥å…· | æœç´¢ã€è®¡ç®—å™¨ã€æ•°æ®åº“æŸ¥è¯¢ |
| **Documents** | æ–‡æ¡£åŠ è½½ã€åˆ†å‰²ã€å¤„ç† | TextLoader, RecursiveCharacterTextSplitter |
| **Embeddings** | æ–‡æœ¬å‘é‡åŒ– | OpenAIEmbeddings |
| **Vector Stores** | å­˜å‚¨å’Œæ£€ç´¢å‘é‡ | Chroma, Pinecone, FAISS |

#### 2.2.2 ç¼–æ’å±‚è¯¦è§£

**Chainsï¼ˆé“¾ï¼‰**ï¼šæŒ‰é¡ºåºè¿æ¥å¤šä¸ªç»„ä»¶

```mermaid
graph LR
    A[Input] --> B[Prompt]
    B --> C[Model]
    C --> D[Parser]
    D --> E[Output]

    style A fill:#FFF3E0
    style E fill:#C8E6C9
```

**Agentsï¼ˆæ™ºèƒ½ä½“ï¼‰**ï¼šæ ¹æ®è¾“å…¥åŠ¨æ€å†³å®šä½¿ç”¨å“ªäº›å·¥å…·

```mermaid
graph TD
    A[User Query] --> B{Agent}
    B -->|å†³ç­–1| C[Search Tool]
    B -->|å†³ç­–2| D[Calculator Tool]
    B -->|å†³ç­–3| E[Database Tool]
    C --> F[ç»¼åˆç»“æœ]
    D --> F
    E --> F
    F --> G[Final Answer]

    style B fill:#FFE082
    style G fill:#81C784
```

### 2.3 å…­å¤§æ ¸å¿ƒæ¨¡å—

#### æ¨¡å—1ï¼šModelsï¼ˆæ¨¡å‹ï¼‰

```python
from langchain_openai import ChatOpenAI

# åˆ›å»ºæ¨¡å‹å®ä¾‹
llm = ChatOpenAI(
    model="gpt-3.5-turbo",      # æ¨¡å‹åç§°
    temperature=0.7,             # åˆ›é€ æ€§ï¼ˆ0-1ï¼Œè¶Šé«˜è¶Šéšæœºï¼‰
    max_tokens=1000,             # æœ€å¤§è¾“å‡º token æ•°
    timeout=30,                  # è¯·æ±‚è¶…æ—¶æ—¶é—´
    max_retries=2                # å¤±è´¥é‡è¯•æ¬¡æ•°
)
```

**å…³é”®å‚æ•°è¯´æ˜ï¼š**
- `temperature`ï¼šæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§
  - `0.0`ï¼šç¡®å®šæ€§è¾“å‡ºï¼Œé€‚åˆäº‹å®æ€§é—®ç­”
  - `0.7`ï¼šå¹³è¡¡åˆ›é€ æ€§å’Œå‡†ç¡®æ€§ï¼Œé€‚åˆå¤§å¤šæ•°åœºæ™¯
  - `1.0`ï¼šé«˜åˆ›é€ æ€§ï¼Œé€‚åˆåˆ›æ„å†™ä½œ

#### æ¨¡å—2ï¼šPromptsï¼ˆæç¤ºè¯æ¨¡æ¿ï¼‰

```python
from langchain.prompts import PromptTemplate

# åˆ›å»ºæç¤ºè¯æ¨¡æ¿
template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{role}ã€‚
ç”¨æˆ·é—®é¢˜ï¼š{question}
è¯·ç”¨{language}è¯­è¨€å›ç­”ã€‚"""

prompt = PromptTemplate(
    input_variables=["role", "question", "language"],  # å˜é‡åˆ—è¡¨
    template=template                                   # æ¨¡æ¿å­—ç¬¦ä¸²
)

# ä½¿ç”¨æ¨¡æ¿
formatted = prompt.format(
    role="Python æ•™å¸ˆ",
    question="ä»€ä¹ˆæ˜¯è£…é¥°å™¨ï¼Ÿ",
    language="ç®€ä½“ä¸­æ–‡"
)
```

#### æ¨¡å—3ï¼šMemoryï¼ˆè®°å¿†ç³»ç»Ÿï¼‰

```python
from langchain.memory import ConversationBufferMemory

# åˆ›å»ºè®°å¿†å®ä¾‹
memory = ConversationBufferMemory(
    return_messages=True,        # è¿”å›æ¶ˆæ¯å¯¹è±¡è€Œéå­—ç¬¦ä¸²
    memory_key="chat_history"    # åœ¨ Chain ä¸­çš„é”®å
)

# ä¿å­˜å¯¹è¯
memory.save_context(
    {"input": "ä½ å¥½ï¼"},
    {"output": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"}
)

# åŠ è½½å¯¹è¯å†å²
history = memory.load_memory_variables({})
```

#### æ¨¡å—4ï¼šToolsï¼ˆå·¥å…·é›†æˆï¼‰

```python
from langchain.tools import Tool

# å®šä¹‰è‡ªå®šä¹‰å·¥å…·
def search_knowledge_base(query: str) -> str:
    """åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç­”æ¡ˆ"""
    # å®é™…æœç´¢é€»è¾‘
    return f"æœç´¢ç»“æœï¼š{query}"

# æ³¨å†Œå·¥å…·
search_tool = Tool(
    name="KnowledgeBaseSearch",          # å·¥å…·åç§°
    func=search_knowledge_base,          # å·¥å…·å‡½æ•°
    description="åœ¨å†…éƒ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯"  # å·¥å…·æè¿°ï¼ˆç»™ Agent çœ‹ï¼‰
)
```

#### æ¨¡å—5ï¼šDocumentsï¼ˆæ–‡æ¡£å¤„ç†ï¼‰

```python
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# åŠ è½½æ–‡æ¡£
loader = TextLoader("document.txt", encoding="utf-8")
documents = loader.load()

# åˆ†å‰²æ–‡æ¡£
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,         # æ¯å—æœ€å¤§å­—ç¬¦æ•°
    chunk_overlap=200,       # å—ä¹‹é—´é‡å å­—ç¬¦æ•°
    separators=["\n\n", "\n", "ã€‚", " ", ""]  # åˆ†å‰²ä¼˜å…ˆçº§
)
chunks = splitter.split_documents(documents)
```

#### æ¨¡å—6ï¼šChainsï¼ˆæµç¨‹é“¾ï¼‰

```python
from langchain.chains import LLMChain

# åˆ›å»ºç®€å•é“¾
chain = LLMChain(
    llm=llm,            # è¯­è¨€æ¨¡å‹
    prompt=prompt,      # æç¤ºè¯æ¨¡æ¿
    memory=memory       # è®°å¿†ç³»ç»Ÿï¼ˆå¯é€‰ï¼‰
)

# æ‰§è¡Œé“¾
result = chain.run(
    role="æ•°æ®ç§‘å­¦å®¶",
    question="å¦‚ä½•ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼Ÿ",
    language="ä¸­æ–‡"
)
```

### 2.4 æ•°æ®æµå‘å›¾

å®Œæ•´çš„ LangChain åº”ç”¨æ•°æ®æµï¼š

```mermaid
sequenceDiagram
    participant U as User
    participant A as Application
    participant P as Prompt Template
    participant M as Model (LLM)
    participant T as Tools
    participant Me as Memory
    participant O as Output Parser

    U->>A: è¾“å…¥é—®é¢˜
    A->>P: æ ¼å¼åŒ–è¾“å…¥
    P->>Me: åŠ è½½å†å²å¯¹è¯
    Me-->>P: è¿”å›ä¸Šä¸‹æ–‡
    P->>M: å‘é€å®Œæ•´ Prompt
    M->>M: ç”Ÿæˆå›ç­”
    M->>T: éœ€è¦è°ƒç”¨å·¥å…·ï¼Ÿ
    T-->>M: è¿”å›å·¥å…·ç»“æœ
    M->>O: åŸå§‹è¾“å‡º
    O->>Me: ä¿å­˜æ–°å¯¹è¯
    O->>U: æ ¼å¼åŒ–è¾“å‡º
```

---

## ä¸‰ã€ç¬¬ä¸€ä¸ª LangChain ç¨‹åº

### 3.1 Hello World ç¤ºä¾‹

åˆ›å»º `hello_langchain.py`ï¼š

```python
"""
ç¬¬ä¸€ä¸ª LangChain ç¨‹åºï¼šHello World
åŠŸèƒ½ï¼šä½¿ç”¨ OpenAI æ¨¡å‹è¿›è¡Œç®€å•å¯¹è¯
"""
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

# ========== æ­¥éª¤1ï¼šåŠ è½½ç¯å¢ƒå˜é‡ ==========
load_dotenv()  # ä» .env æ–‡ä»¶åŠ è½½ API å¯†é’¥

# éªŒè¯ API å¯†é’¥æ˜¯å¦å­˜åœ¨
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("âŒ æœªæ‰¾åˆ° OPENAI_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")

print("âœ… API å¯†é’¥åŠ è½½æˆåŠŸ")

# ========== æ­¥éª¤2ï¼šåˆå§‹åŒ–æ¨¡å‹ ==========
llm = ChatOpenAI(
    model="gpt-3.5-turbo",  # ä½¿ç”¨ GPT-3.5 æ¨¡å‹
    temperature=0.7         # è®¾ç½®åˆ›é€ æ€§ä¸º 0.7
)

print("âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")

# ========== æ­¥éª¤3ï¼šæ„å»ºæ¶ˆæ¯åˆ—è¡¨ ==========
messages = [
    # SystemMessageï¼šè®¾å®š AI çš„è§’è‰²å’Œè¡Œä¸º
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ AI åŠ©æ‰‹ï¼Œç”¨ç®€æ´çš„è¯­è¨€å›ç­”é—®é¢˜ã€‚"),

    # HumanMessageï¼šç”¨æˆ·çš„è¾“å…¥
    HumanMessage(content="ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯ LangChainï¼Ÿ")
]

# ========== æ­¥éª¤4ï¼šè°ƒç”¨æ¨¡å‹å¹¶è·å–å›ç­” ==========
print("\næ­£åœ¨è°ƒç”¨ OpenAI API...")
response = llm.invoke(messages)

# ========== æ­¥éª¤5ï¼šè¾“å‡ºç»“æœ ==========
print("\n" + "=" * 60)
print("AI å›ç­”ï¼š")
print(response.content)
print("=" * 60)

# æ‰“å°å…ƒæ•°æ®
print(f"\næ¨¡å‹ï¼š{response.response_metadata.get('model_name', 'N/A')}")
print(f"Token ä½¿ç”¨ï¼š{response.response_metadata.get('token_usage', {})}")
```

**è¿è¡Œç¨‹åºï¼š**

```bash
python hello_langchain.py
```

**é¢„æœŸè¾“å‡ºï¼š**

```
âœ… API å¯†é’¥åŠ è½½æˆåŠŸ
âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ

æ­£åœ¨è°ƒç”¨ OpenAI API...

============================================================
AI å›ç­”ï¼š
LangChain æ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œå¸®åŠ©å¼€å‘è€…æ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨ç¨‹åºï¼Œæä¾›äº†æ¨¡å—åŒ–çš„ç»„ä»¶å’Œå·¥å…·é“¾ã€‚
============================================================

æ¨¡å‹ï¼šgpt-3.5-turbo-0125
Token ä½¿ç”¨ï¼š{'prompt_tokens': 45, 'completion_tokens': 28, 'total_tokens': 73}
```

### 3.2 ä»£ç è¯¦è§£

#### 3.2.1 æ¶ˆæ¯ç±»å‹

LangChain å®šä¹‰äº†ä¸‰ç§ä¸»è¦æ¶ˆæ¯ç±»å‹ï¼š

```python
from langchain.schema import SystemMessage, HumanMessage, AIMessage

# 1. SystemMessageï¼šç³»ç»Ÿæ¶ˆæ¯ï¼Œè®¾å®š AI è§’è‰²
system_msg = SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹")

# 2. HumanMessageï¼šç”¨æˆ·æ¶ˆæ¯
human_msg = HumanMessage(content="å°† 'Hello' ç¿»è¯‘æˆä¸­æ–‡")

# 3. AIMessageï¼šAI å›å¤æ¶ˆæ¯ï¼ˆç”¨äºå¤šè½®å¯¹è¯ï¼‰
ai_msg = AIMessage(content="'Hello' çš„ä¸­æ–‡ç¿»è¯‘æ˜¯ 'ä½ å¥½'")

# å¤šè½®å¯¹è¯ç¤ºä¾‹
messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæ•°å­¦è€å¸ˆ"),
    HumanMessage(content="1+1ç­‰äºå‡ ï¼Ÿ"),
    AIMessage(content="1+1ç­‰äº2"),
    HumanMessage(content="é‚£ 2+2 å‘¢ï¼Ÿ")  # ç»§ç»­å¯¹è¯
]
```

#### 3.2.2 é”™è¯¯å¤„ç†

å®Œå–„çš„é”™è¯¯å¤„ç†ç¤ºä¾‹ï¼š

```python
"""
å®Œå–„çš„ LangChain ç¨‹åºï¼ˆå«é”™è¯¯å¤„ç†ï¼‰
"""
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
import time

load_dotenv()

def create_llm_with_retry(max_retries=3, retry_delay=2):
    """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„ LLM å®ä¾‹"""
    for attempt in range(max_retries):
        try:
            llm = ChatOpenAI(
                model="gpt-3.5-turbo",
                temperature=0.7,
                timeout=30  # 30 ç§’è¶…æ—¶
            )
            # æµ‹è¯•è¿æ¥
            llm.invoke([HumanMessage(content="test")])
            print(f"âœ… æ¨¡å‹è¿æ¥æˆåŠŸï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰")
            return llm
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {str(e)}")
            if attempt < max_retries - 1:
                print(f"â³ {retry_delay} ç§’åé‡è¯•...")
                time.sleep(retry_delay)
            else:
                raise Exception("æ— æ³•è¿æ¥åˆ° OpenAI APIï¼Œè¯·æ£€æŸ¥ç½‘ç»œå’Œ API å¯†é’¥")

def main():
    try:
        # 1. éªŒè¯ç¯å¢ƒå˜é‡
        if not os.getenv("OPENAI_API_KEY"):
            raise ValueError("OPENAI_API_KEY æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")

        # 2. åˆ›å»º LLM å®ä¾‹
        llm = create_llm_with_retry()

        # 3. å‘é€è¯·æ±‚
        messages = [HumanMessage(content="ç”¨ä¸€å¥è¯è§£é‡Š Python è£…é¥°å™¨")]
        response = llm.invoke(messages)

        # 4. è¾“å‡ºç»“æœ
        print(f"\nâœ… AI å›ç­”ï¼š\n{response.content}")

    except ValueError as e:
        print(f"âŒ é…ç½®é”™è¯¯ï¼š{e}")
    except Exception as e:
        print(f"âŒ ç¨‹åºé”™è¯¯ï¼š{e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
```

### 3.3 äº¤äº’å¼é—®ç­”ç¨‹åº

åˆ›å»º `interactive_chat.py`ï¼š

```python
"""
äº¤äº’å¼èŠå¤©ç¨‹åº
åŠŸèƒ½ï¼šä¸ AI è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œæ”¯æŒé€€å‡ºå‘½ä»¤
"""
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage

load_dotenv()

def main():
    # åˆå§‹åŒ–æ¨¡å‹
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)

    # å¯¹è¯å†å²ï¼ˆåŒ…å«ç³»ç»Ÿæ¶ˆæ¯ï¼‰
    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ AI åŠ©æ‰‹ï¼Œæä¾›æœ‰å¸®åŠ©çš„å›ç­”ã€‚")
    ]

    print("=" * 60)
    print("LangChain äº¤äº’å¼èŠå¤©ï¼ˆè¾“å…¥ 'exit' æˆ– 'quit' é€€å‡ºï¼‰")
    print("=" * 60)

    while True:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = input("\nä½ : ").strip()

        # æ£€æŸ¥é€€å‡ºå‘½ä»¤
        if user_input.lower() in ['exit', 'quit', 'é€€å‡º']:
            print("\nå†è§ï¼ğŸ‘‹")
            break

        # è·³è¿‡ç©ºè¾“å…¥
        if not user_input:
            continue

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        messages.append(HumanMessage(content=user_input))

        try:
            # è°ƒç”¨ LLM
            print("\nAI æ­£åœ¨æ€è€ƒ...")
            response = llm.invoke(messages)

            # æ·»åŠ  AI å›å¤åˆ°å†å²
            messages.append(AIMessage(content=response.content))

            # æ‰“å°å›å¤
            print(f"\nAI: {response.content}")

        except Exception as e:
            print(f"\nâŒ é”™è¯¯ï¼š{e}")
            # ç§»é™¤å¤±è´¥çš„ç”¨æˆ·æ¶ˆæ¯
            messages.pop()

if __name__ == "__main__":
    main()
```

**è¿è¡Œæ•ˆæœï¼š**

```
============================================================
LangChain äº¤äº’å¼èŠå¤©ï¼ˆè¾“å…¥ 'exit' æˆ– 'quit' é€€å‡ºï¼‰
============================================================

ä½ : ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ

AI æ­£åœ¨æ€è€ƒ...

AI: Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥ç®€æ´æ˜“è¯»è‘—ç§°ï¼Œå¹¿æ³›ç”¨äº Web å¼€å‘ã€æ•°æ®åˆ†æã€äººå·¥æ™ºèƒ½ç­‰é¢†åŸŸã€‚

ä½ : å®ƒæœ‰å“ªäº›ä¼˜ç‚¹ï¼Ÿ

AI æ­£åœ¨æ€è€ƒ...

AI: Python çš„ä¸»è¦ä¼˜ç‚¹åŒ…æ‹¬ï¼š
1. è¯­æ³•ç®€æ´æ˜“å­¦
2. ä¸°å¯Œçš„ç¬¬ä¸‰æ–¹åº“
3. å¼ºå¤§çš„ç¤¾åŒºæ”¯æŒ
4. è·¨å¹³å°å…¼å®¹
5. é€‚ç”¨äºå¤šç§åº”ç”¨åœºæ™¯

ä½ : exit

å†è§ï¼ğŸ‘‹
```

---

## å››ã€è°ƒè¯•æŠ€å·§ä¸æœ€ä½³å®è·µ

### 4.1 æ—¥å¿—è®°å½•

å¯ç”¨ LangChain è¯¦ç»†æ—¥å¿—ï¼š

```python
"""
å¯ç”¨è¯¦ç»†æ—¥å¿—è®°å½•
"""
import os
os.environ["LANGCHAIN_VERBOSE"] = "true"  # å¯ç”¨è¯¦ç»†è¾“å‡º

from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage

llm = ChatOpenAI(model="gpt-3.5-turbo")
response = llm.invoke([HumanMessage(content="Hello")])

# ä¼šè¾“å‡ºè¯¦ç»†çš„è°ƒç”¨ä¿¡æ¯ï¼š
# > Entering new LLMChain chain...
# > Prompt after formatting: ...
# > Finished chain.
```

### 4.2 Token è®¡æ•°ä¸æˆæœ¬ä¼°ç®—

```python
"""
Token ä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬è®¡ç®—
"""
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
from langchain.callbacks import get_openai_callback

llm = ChatOpenAI(model="gpt-3.5-turbo")

# ä½¿ç”¨ callback è¿½è¸ª Token ä½¿ç”¨
with get_openai_callback() as cb:
    response = llm.invoke([HumanMessage(content="è§£é‡Šé‡å­è®¡ç®—")])

    print("=" * 60)
    print("Token ä½¿ç”¨ç»Ÿè®¡ï¼š")
    print(f"  è¾“å…¥ Token: {cb.prompt_tokens}")
    print(f"  è¾“å‡º Token: {cb.completion_tokens}")
    print(f"  æ€»è®¡ Token: {cb.total_tokens}")
    print(f"  é¢„ä¼°æˆæœ¬: ${cb.total_cost:.6f} USD")
    print("=" * 60)
```

**è¾“å‡ºç¤ºä¾‹ï¼š**

```
============================================================
Token ä½¿ç”¨ç»Ÿè®¡ï¼š
  è¾“å…¥ Token: 12
  è¾“å‡º Token: 85
  æ€»è®¡ Token: 97
  é¢„ä¼°æˆæœ¬: $0.000194 USD
============================================================
```

### 4.3 å¸¸è§é”™è¯¯ä¸è§£å†³æ–¹æ¡ˆ

#### é”™è¯¯1ï¼šRateLimitError

```python
"""
å¤„ç†é€Ÿç‡é™åˆ¶é”™è¯¯
"""
from langchain_openai import ChatOpenAI
from openai import RateLimitError
import time

llm = ChatOpenAI(model="gpt-3.5-turbo")

def call_with_retry(messages, max_retries=3, base_delay=1):
    """æŒ‡æ•°é€€é¿é‡è¯•"""
    for attempt in range(max_retries):
        try:
            return llm.invoke(messages)
        except RateLimitError as e:
            if attempt == max_retries - 1:
                raise e
            delay = base_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿ï¼š1s, 2s, 4s
            print(f"âš ï¸ é€Ÿç‡é™åˆ¶ï¼Œ{delay}ç§’åé‡è¯•...")
            time.sleep(delay)
```

#### é”™è¯¯2ï¼šContext Length Exceeded

```python
"""
å¤„ç†ä¸Šä¸‹æ–‡é•¿åº¦è¶…é™
"""
def truncate_messages(messages, max_tokens=4096):
    """æˆªæ–­æ¶ˆæ¯ä»¥é€‚åº”ä¸Šä¸‹æ–‡çª—å£"""
    import tiktoken

    encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
    current_tokens = sum(len(encoding.encode(msg.content)) for msg in messages)

    if current_tokens <= max_tokens:
        return messages

    # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€æ–°çš„å‡ æ¡æ¶ˆæ¯
    system_msgs = [msg for msg in messages if isinstance(msg, SystemMessage)]
    other_msgs = [msg for msg in messages if not isinstance(msg, SystemMessage)]

    # ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹ä¿ç•™
    truncated = system_msgs.copy()
    for msg in reversed(other_msgs):
        msg_tokens = len(encoding.encode(msg.content))
        if current_tokens - msg_tokens < max_tokens:
            truncated.insert(1, msg)
            current_tokens -= msg_tokens
        else:
            break

    return truncated
```

### 4.4 æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### æŠ€å·§1ï¼šæ‰¹é‡å¤„ç†

```python
"""
æ‰¹é‡è°ƒç”¨æé«˜æ•ˆç‡
"""
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage

llm = ChatOpenAI(model="gpt-3.5-turbo")

# å•æ¬¡è°ƒç”¨ï¼ˆæ…¢ï¼‰
questions = ["ä»€ä¹ˆæ˜¯ Python?", "ä»€ä¹ˆæ˜¯ Java?", "ä»€ä¹ˆæ˜¯ JavaScript?"]
for q in questions:
    response = llm.invoke([HumanMessage(content=q)])

# æ‰¹é‡è°ƒç”¨ï¼ˆå¿«ï¼‰
messages_batch = [[HumanMessage(content=q)] for q in questions]
responses = llm.batch(messages_batch)  # å¹¶è¡Œè°ƒç”¨
```

#### æŠ€å·§2ï¼šä½¿ç”¨ç¼“å­˜

```python
"""
å¯ç”¨å“åº”ç¼“å­˜
"""
from langchain.cache import InMemoryCache
from langchain.globals import set_llm_cache
from langchain_openai import ChatOpenAI

# å¯ç”¨ç¼“å­˜
set_llm_cache(InMemoryCache())

llm = ChatOpenAI(model="gpt-3.5-turbo")

# ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆæ…¢ï¼‰
response1 = llm.invoke([HumanMessage(content="ä»€ä¹ˆæ˜¯ LangChain?")])

# ç›¸åŒé—®é¢˜çš„ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆå¿«ï¼Œç›´æ¥ä»ç¼“å­˜è¿”å›ï¼‰
response2 = llm.invoke([HumanMessage(content="ä»€ä¹ˆæ˜¯ LangChain?")])
```

---

## äº”ã€æœ¬å‘¨ç»ƒä¹ é¢˜

### ç»ƒä¹ 1ï¼šåŸºç¡€è°ƒç”¨ï¼ˆéš¾åº¦ï¼šâ­ï¼‰

**ä»»åŠ¡**ï¼šåˆ›å»ºä¸€ä¸ªç¨‹åºï¼Œè®© AI æ‰®æ¼”ä¸åŒè§’è‰²å›ç­”åŒä¸€ä¸ªé—®é¢˜ã€‚

**è¦æ±‚**ï¼š
1. ä½¿ç”¨ `SystemMessage` è®¾å®š 3 ä¸ªä¸åŒè§’è‰²ï¼ˆå¦‚ï¼šæ•™å¸ˆã€è¯—äººã€ç¨‹åºå‘˜ï¼‰
2. è®©æ¯ä¸ªè§’è‰²å›ç­”ï¼š"ä»€ä¹ˆæ˜¯çˆ±ï¼Ÿ"
3. æ¯”è¾ƒä¸åŒè§’è‰²çš„å›ç­”å·®å¼‚

<details>
<summary><b>æŸ¥çœ‹å‚è€ƒç­”æ¡ˆ</b></summary>

```python
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from dotenv import load_dotenv

load_dotenv()
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.8)

roles = {
    "æ•™å¸ˆ": "ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰è€å¿ƒçš„æ•™å¸ˆï¼Œå–„äºç”¨ç®€å•çš„è¯­è¨€è§£é‡Šå¤æ‚æ¦‚å¿µã€‚",
    "è¯—äºº": "ä½ æ˜¯ä¸€ä¸ªæµªæ¼«çš„è¯—äººï¼Œç”¨è¯—æ„çš„è¯­è¨€è¡¨è¾¾æƒ…æ„Ÿã€‚",
    "ç¨‹åºå‘˜": "ä½ æ˜¯ä¸€ä¸ªç†æ€§çš„ç¨‹åºå‘˜ï¼Œä¹ æƒ¯ç”¨é€»è¾‘å’Œç®—æ³•æ€ç»´çœ‹å¾…é—®é¢˜ã€‚"
}

question = "ä»€ä¹ˆæ˜¯çˆ±ï¼Ÿ"

for role_name, role_description in roles.items():
    messages = [
        SystemMessage(content=role_description),
        HumanMessage(content=question)
    ]
    response = llm.invoke(messages)
    print(f"\n{'=' * 60}")
    print(f"{role_name}çš„å›ç­”ï¼š")
    print(response.content)
```
</details>

### ç»ƒä¹ 2ï¼šå¯¹è¯å†å²ï¼ˆéš¾åº¦ï¼šâ­â­ï¼‰

**ä»»åŠ¡**ï¼šå®ç°ä¸€ä¸ªç®€å•çš„å¤šè½®å¯¹è¯ç³»ç»Ÿï¼Œèƒ½å¤Ÿè®°ä½ä¹‹å‰çš„å¯¹è¯å†…å®¹ã€‚

**è¦æ±‚**ï¼š
1. ç”¨æˆ·å¯ä»¥è¿ç»­æé—®
2. AI èƒ½å¤Ÿå¼•ç”¨ä¹‹å‰çš„å¯¹è¯å†…å®¹
3. æ”¯æŒæŸ¥çœ‹å®Œæ•´å¯¹è¯å†å²

<details>
<summary><b>æŸ¥çœ‹å‚è€ƒç­”æ¡ˆ</b></summary>

```python
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from dotenv import load_dotenv

load_dotenv()
llm = ChatOpenAI(model="gpt-3.5-turbo")

messages = [SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæœ‰è®°å¿†åŠ›çš„AIåŠ©æ‰‹ã€‚")]

def chat(user_input):
    messages.append(HumanMessage(content=user_input))
    response = llm.invoke(messages)
    messages.append(AIMessage(content=response.content))
    return response.content

def show_history():
    print("\n--- å¯¹è¯å†å² ---")
    for i, msg in enumerate(messages[1:], 1):  # è·³è¿‡ç³»ç»Ÿæ¶ˆæ¯
        role = "ä½ " if isinstance(msg, HumanMessage) else "AI"
        print(f"{i}. {role}: {msg.content}")

# æµ‹è¯•
print(chat("æˆ‘å«å°æ˜"))
print(chat("æˆ‘åˆšæ‰è¯´æˆ‘å«ä»€ä¹ˆï¼Ÿ"))
show_history()
```
</details>

### ç»ƒä¹ 3ï¼šé”™è¯¯å¤„ç†ï¼ˆéš¾åº¦ï¼šâ­â­â­ï¼‰

**ä»»åŠ¡**ï¼šå¢å¼ºäº¤äº’å¼èŠå¤©ç¨‹åºï¼Œæ·»åŠ å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•ã€‚

**è¦æ±‚**ï¼š
1. å¤„ç†ç½‘ç»œé”™è¯¯ã€API é”™è¯¯ã€è¶…æ—¶é”™è¯¯
2. æ·»åŠ æ—¥å¿—è®°å½•åˆ°æ–‡ä»¶
3. ç»Ÿè®¡ Token ä½¿ç”¨å’Œæˆæœ¬
4. æ”¯æŒå¯¼å‡ºå¯¹è¯å†å²

<details>
<summary><b>æŸ¥çœ‹å‚è€ƒç­”æ¡ˆ</b></summary>

```python
import os
import logging
from datetime import datetime
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from langchain.callbacks import get_openai_callback

# é…ç½®æ—¥å¿—
logging.basicConfig(
    filename=f'chat_log_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

load_dotenv()

class ChatBot:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
        self.messages = [SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚")]
        self.total_cost = 0.0
        self.total_tokens = 0
        logging.info("ChatBot åˆå§‹åŒ–æˆåŠŸ")

    def chat(self, user_input):
        try:
            self.messages.append(HumanMessage(content=user_input))
            logging.info(f"ç”¨æˆ·è¾“å…¥ï¼š{user_input}")

            with get_openai_callback() as cb:
                response = self.llm.invoke(self.messages)
                self.messages.append(AIMessage(content=response.content))

                self.total_cost += cb.total_cost
                self.total_tokens += cb.total_tokens

                logging.info(f"AIå›å¤ï¼š{response.content}")
                logging.info(f"Tokenä½¿ç”¨ï¼š{cb.total_tokens}, æˆæœ¬ï¼š${cb.total_cost:.6f}")

            return response.content

        except Exception as e:
            logging.error(f"è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
            self.messages.pop()  # ç§»é™¤å¤±è´¥çš„æ¶ˆæ¯
            return f"æŠ±æ­‰ï¼Œå‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

    def export_history(self, filename="chat_history.txt"):
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"å¯¹è¯å¯¼å‡ºæ—¶é—´ï¼š{datetime.now()}\n")
            f.write(f"æ€»Tokenä½¿ç”¨ï¼š{self.total_tokens}\n")
            f.write(f"æ€»æˆæœ¬ï¼š${self.total_cost:.6f}\n")
            f.write("=" * 60 + "\n\n")

            for msg in self.messages[1:]:
                role = "ç”¨æˆ·" if isinstance(msg, HumanMessage) else "AI"
                f.write(f"{role}ï¼š{msg.content}\n\n")

        print(f"âœ… å¯¹è¯å†å²å·²å¯¼å‡ºåˆ° {filename}")
        logging.info(f"å¯¹è¯å†å²å¯¼å‡ºåˆ° {filename}")

def main():
    bot = ChatBot()
    print("èŠå¤©å¼€å§‹ï¼ˆè¾“å…¥ 'exit' é€€å‡ºï¼Œ'export' å¯¼å‡ºå†å²ï¼‰")

    while True:
        user_input = input("\nä½ : ").strip()

        if user_input.lower() == 'exit':
            print(f"\næ€»Tokenä½¿ç”¨ï¼š{bot.total_tokens}")
            print(f"æ€»æˆæœ¬ï¼š${bot.total_cost:.6f}")
            break

        if user_input.lower() == 'export':
            bot.export_history()
            continue

        if not user_input:
            continue

        response = bot.chat(user_input)
        print(f"\nAI: {response}")

if __name__ == "__main__":
    main()
```
</details>

---

## å…­ã€æœ¬å‘¨æ€»ç»“

### 6.1 çŸ¥è¯†ç‚¹æ¸…å•

- [x] Python è™šæ‹Ÿç¯å¢ƒçš„åˆ›å»ºå’Œä½¿ç”¨
- [x] LangChain å’Œç›¸å…³ä¾èµ–çš„å®‰è£…
- [x] API å¯†é’¥çš„é…ç½®å’Œç®¡ç†
- [x] LangChain æ ¸å¿ƒæ¶æ„ç†è§£
- [x] å…­å¤§æ ¸å¿ƒæ¨¡å—ï¼ˆModelsã€Promptsã€Memoryã€Toolsã€Documentsã€Chainsï¼‰
- [x] æ¶ˆæ¯ç±»å‹ï¼ˆSystemMessageã€HumanMessageã€AIMessageï¼‰
- [x] åŸºæœ¬çš„ LLM è°ƒç”¨
- [x] é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
- [x] Token è®¡æ•°å’Œæˆæœ¬ä¼°ç®—

### 6.2 å¸¸è§é—®é¢˜ï¼ˆFAQï¼‰

<details>
<summary><b>Q1ï¼šä¸ºä»€ä¹ˆè¦ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼Ÿ</b></summary>

**A**ï¼šè™šæ‹Ÿç¯å¢ƒæä¾›ä¾èµ–éš”ç¦»ï¼Œé¿å…ä¸åŒé¡¹ç›®ä¹‹é—´çš„åŒ…ç‰ˆæœ¬å†²çªã€‚ä¾‹å¦‚ï¼š
- é¡¹ç›® A éœ€è¦ langchain 0.1.0
- é¡¹ç›® B éœ€è¦ langchain 0.2.0
- ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼Œä¸¤ä¸ªé¡¹ç›®å¯ä»¥å…±å­˜

æœ€ä½³å®è·µï¼šæ¯ä¸ªé¡¹ç›®éƒ½åº”è¯¥æœ‰ç‹¬ç«‹çš„è™šæ‹Ÿç¯å¢ƒã€‚
</details>

<details>
<summary><b>Q2ï¼štemperature å‚æ•°å¦‚ä½•é€‰æ‹©ï¼Ÿ</b></summary>

**A**ï¼šæ ¹æ®åº”ç”¨åœºæ™¯é€‰æ‹©ï¼š

| Temperature | é€‚ç”¨åœºæ™¯ | ç¤ºä¾‹ |
|-------------|---------|------|
| 0.0 - 0.3 | äº‹å®æ€§ä»»åŠ¡ | ç¿»è¯‘ã€æ•°æ®æå–ã€å®¢æœé—®ç­” |
| 0.4 - 0.7 | å¹³è¡¡ä»»åŠ¡ | é€šç”¨å¯¹è¯ã€æ€»ç»“ã€è§£é‡Š |
| 0.8 - 1.0 | åˆ›æ„ä»»åŠ¡ | åˆ›æ„å†™ä½œã€å¤´è„‘é£æš´ |
| > 1.0 | æé«˜éšæœºæ€§ | è‰ºæœ¯åˆ›ä½œï¼ˆä¸æ¨èï¼‰ |
</details>

<details>
<summary><b>Q3ï¼šå¦‚ä½•é™ä½ API è°ƒç”¨æˆæœ¬ï¼Ÿ</b></summary>

**A**ï¼š5 ä¸ªå®ç”¨æŠ€å·§ï¼š

1. **ä½¿ç”¨ç¼“å­˜**ï¼šç›¸åŒé—®é¢˜ä¸é‡å¤è°ƒç”¨
2. **é€‰æ‹©åˆé€‚æ¨¡å‹**ï¼šç®€å•ä»»åŠ¡ç”¨ gpt-3.5-turbo
3. **ä¼˜åŒ– Prompt**ï¼šå‡å°‘ä¸å¿…è¦çš„ä¸Šä¸‹æ–‡
4. **æ‰¹é‡è°ƒç”¨**ï¼šä½¿ç”¨ `batch()` æ–¹æ³•
5. **è®¾ç½® max_tokens**ï¼šé™åˆ¶è¾“å‡ºé•¿åº¦

```python
# ç¤ºä¾‹ï¼šå¯ç”¨ç¼“å­˜
from langchain.cache import InMemoryCache
from langchain.globals import set_llm_cache
set_llm_cache(InMemoryCache())
```
</details>

<details>
<summary><b>Q4ï¼šå¦‚ä½•å¤„ç†ä¸­æ–‡ç¼–ç é—®é¢˜ï¼Ÿ</b></summary>

**A**ï¼šç¡®ä¿æ‰€æœ‰æ–‡ä»¶æ“ä½œä½¿ç”¨ UTF-8 ç¼–ç ï¼š

```python
# è¯»å–æ–‡ä»¶
with open("file.txt", "r", encoding="utf-8") as f:
    content = f.read()

# å†™å…¥æ–‡ä»¶
with open("output.txt", "w", encoding="utf-8") as f:
    f.write("ä¸­æ–‡å†…å®¹")

# åœ¨ Windows ä¸Šè¿˜éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡
import os
os.environ["PYTHONIOENCODING"] = "utf-8"
```
</details>

### 6.3 ä¸‹å‘¨é¢„ä¹ 

**ç¬¬2å‘¨ä¸»é¢˜ï¼šMessages å’Œ Prompts æ·±å…¥**

é¢„ä¹ å†…å®¹ï¼š
1. äº†è§£ Prompt Engineering åŸºæœ¬æ¦‚å¿µ
2. é˜…è¯» [LangChain Prompts æ–‡æ¡£](https://python.langchain.com/docs/modules/model_io/prompts/)
3. æ€è€ƒï¼šå¦‚ä½•è®¾è®¡ä¸€ä¸ªå¥½çš„ Promptï¼Ÿ

**é¢„ä¹ é—®é¢˜**ï¼š
- Few-shot Learning æ˜¯ä»€ä¹ˆï¼Ÿ
- Chain of Thoughtï¼ˆæ€ç»´é“¾ï¼‰æœ‰ä»€ä¹ˆä½œç”¨ï¼Ÿ
- å¦‚ä½•è®© AI è¾“å‡ºç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚ JSONï¼‰ï¼Ÿ

---

## ä¸ƒã€å­¦ä¹ èµ„æº

### å®˜æ–¹æ–‡æ¡£
- [LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)
- [LangChain GitHub](https://github.com/langchain-ai/langchain)
- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs/)

### æ¨èé˜…è¯»
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [LangChain Cookbook](https://github.com/langchain-ai/langchain/tree/master/cookbook)

### ç¤¾åŒºèµ„æº
- [LangChain Discord ç¤¾åŒº](https://discord.gg/langchain)
- [LangChain ä¸­æ–‡ç¤¾åŒº](https://github.com/lijiext/langchain-zh)

---

::: tip å­¦ä¹ å»ºè®®
1. **åŠ¨æ‰‹å®è·µ**ï¼šå®Œæˆæ‰€æœ‰ç»ƒä¹ é¢˜ï¼Œå¹¶å°è¯•ä¿®æ”¹ä»£ç 
2. **è®°å½•ç¬”è®°**ï¼šè®°å½•é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
3. **åŠ å…¥ç¤¾åŒº**ï¼šåœ¨ç¤¾åŒºæé—®å’Œåˆ†äº«ç»éªŒ
4. **æ¯æ—¥ç»ƒä¹ **ï¼šæ¯å¤©è‡³å°‘å†™ 30 åˆ†é’Ÿä»£ç 
:::

**ä¸‹å‘¨ç»§ç»­åŠ æ²¹ï¼ğŸš€**
