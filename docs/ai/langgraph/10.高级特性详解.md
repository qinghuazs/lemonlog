---
title: LangGraph 高级特性详解
date: 2025-01-30
permalink: /ai/langgraph/advanced-features.html
tags:
  - AI
  - LangGraph
  - 高级特性
categories:
  - AI
  - LangGraph
---

# LangGraph 高级特性详解

## 一、高级特性概览

```mermaid
graph TD
    A[高级特性] --> B[子图 Subgraph]
    A --> C[并行处理]
    A --> D[流式执行]
    A --> E[动态图]
    A --> F[中断与恢复]
    A --> G[时间旅行]

    B --> B1[图嵌套]
    B --> B2[模块化]
    B --> B3[复用]

    C --> C1[并行节点]
    C --> C2[Send API]
    C --> C3[Map-Reduce]

    D --> D1[流式输出]
    D --> D2[实时反馈]
    D --> D3[增量处理]

    E --> E1[动态构建]
    E --> E2[条件图]
    E --> E3[插件系统]

    F --> F1[人工审核]
    F --> F2[断点调试]
    F --> F3[状态恢复]

    G --> G1[状态回溯]
    G --> G2[版本管理]
    G --> G3[重放执行]

    style A fill:#e1f5fe
    style B fill:#b3e5fc
    style C fill:#81d4fa
    style D fill:#4fc3f7
    style E fill:#29b6f6
```

## 二、子图 (Subgraph)

### 2.1 子图概述

**什么是子图？**

子图（Subgraph）是 LangGraph 中的一种模块化机制，它允许你将一个完整的图作为另一个图的节点使用。子图本质上是一个**独立的、可编译的图**，可以在其他图中被调用和复用。

**为什么需要子图？**

1. **代码复用**：将常用的处理逻辑封装成子图，在多个工作流中重复使用
2. **模块化设计**：将复杂的工作流分解为多个独立的子图，每个子图负责特定功能
3. **关注点分离**：不同的子图可以有不同的状态结构和处理逻辑
4. **团队协作**：不同团队可以独立开发和维护各自的子图
5. **测试便利**：子图可以独立测试，提高代码质量

**子图的核心特点**

| 特点 | 说明 | 优势 |
|------|------|------|
| **独立编译** | 子图需要先编译成 `CompiledGraph` | 可独立运行和测试 |
| **状态隔离** | 子图有自己的状态类型 | 避免状态污染 |
| **接口清晰** | 通过 invoke() 调用，输入输出明确 | 易于理解和维护 |
| **可嵌套** | 子图内部可以包含其他子图 | 支持多层抽象 |
| **无副作用** | 子图不会直接修改父图状态 | 提高安全性 |

**子图的使用流程**

```mermaid
graph LR
    A[定义子图状态] --> B[创建子图]
    B --> C[添加子图节点]
    C --> D[编译子图]
    D --> E[在主图中调用]
    E --> F[状态转换]

    style A fill:#e1f5fe
    style D fill:#fff3e0
    style F fill:#e8f5e9
```

### 2.2 基本子图实现

下面通过一个完整示例来理解子图的基本用法：

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict

# 1. 定义子图状态（独立的状态结构）
class SubState(TypedDict):
    value: int      # 子图的输入
    result: int     # 子图的输出

# 2. 创建子图工厂函数
def create_subgraph():
    """
    创建可复用的子图

    这个子图实现两个功能：
    1. 对输入值加 1
    2. 对结果乘以 2

    返回: 编译后的子图应用
    """
    def increment(state: SubState) -> dict:
        """子图节点1：递增操作"""
        return {"value": state["value"] + 1}

    def multiply(state: SubState) -> dict:
        """子图节点2：乘法操作"""
        return {"result": state["value"] * 2}

    # 创建子图实例
    subgraph = StateGraph(SubState)

    # 添加子图节点
    subgraph.add_node("increment", increment)
    subgraph.add_node("multiply", multiply)

    # 定义子图流程
    subgraph.set_entry_point("increment")      # 入口：increment
    subgraph.add_edge("increment", "multiply")  # increment → multiply
    subgraph.add_edge("multiply", END)          # multiply → 结束

    # 编译并返回（重要：必须编译才能被调用）
    return subgraph.compile()

# 3. 定义主图状态
class MainState(TypedDict):
    input: int      # 主图输入
    output: int     # 主图输出

# 4. 在主图中使用子图
def create_main_graph_with_subgraph():
    """
    主图包含子图的完整示例

    流程：prepare → subgraph → END
    """
    # 获取编译后的子图（可复用）
    subgraph_app = create_subgraph()

    def prepare(state: MainState) -> dict:
        """主图节点1：准备数据"""
        return {"input": state["input"]}

    def use_subgraph(state: MainState) -> dict:
        """
        主图节点2：调用子图

        关键点：
        1. 构造子图所需的状态（状态转换）
        2. 调用子图的 invoke() 方法
        3. 从子图结果中提取需要的数据
        4. 转换为主图的状态格式
        """
        # 状态转换：主图状态 → 子图状态
        sub_input = {
            "value": state["input"],
            "result": 0
        }

        # 调用子图处理
        sub_result = subgraph_app.invoke(sub_input)

        # 状态转换：子图状态 → 主图状态
        return {"output": sub_result["result"]}

    # 构建主图
    graph = StateGraph(MainState)
    graph.add_node("prepare", prepare)
    graph.add_node("subgraph", use_subgraph)

    graph.set_entry_point("prepare")
    graph.add_edge("prepare", "subgraph")
    graph.add_edge("subgraph", END)

    return graph.compile()

# 5. 测试子图集成
def test_subgraph():
    """
    测试子图功能

    执行流程：
    1. 主图接收 input=5
    2. prepare 节点保持输入
    3. subgraph 节点：
       - 子图 increment: 5 + 1 = 6
       - 子图 multiply: 6 * 2 = 12
    4. 主图输出 output=12
    """
    app = create_main_graph_with_subgraph()
    result = app.invoke({"input": 5, "output": 0})

    print(f"结果: {result['output']}")  # (5+1)*2 = 12
    assert result["output"] == 12

    print("✅ 子图测试通过")
```

**状态转换图示**

```mermaid
graph TB
    subgraph "主图状态空间"
        A[MainState: input=5] --> B[prepare节点]
        B --> C[subgraph节点]
        C --> D[MainState: output=12]
    end

    subgraph "子图状态空间"
        E[SubState: value=5] --> F[increment节点]
        F --> G[SubState: value=6]
        G --> H[multiply节点]
        H --> I[SubState: result=12]
    end

    C -.状态转换.-> E
    I -.结果提取.-> C

    style A fill:#e1f5fe
    style D fill:#e8f5e9
    style E fill:#fff3e0
    style I fill:#f3e5f5
```

**关键要点总结**

1. **子图必须先编译**：使用 `subgraph.compile()` 编译后才能被调用
2. **状态需要转换**：主图状态和子图状态通常不同，需要手动转换
3. **子图是独立的**：子图执行时有自己的状态空间，不会影响主图
4. **可以复用**：编译后的子图可以在多个节点中调用
5. **调用方式**：通过 `subgraph_app.invoke(state)` 同步调用

### 2.3 嵌套子图

**嵌套子图的概念**

嵌套子图是指在一个子图内部调用另一个子图，形成多层级的图结构。这种设计模式在以下场景特别有用：

1. **层次化处理**：将复杂逻辑分解为多个抽象层次
2. **深度模块化**：每一层关注特定的抽象级别
3. **职责分离**：不同层次处理不同粒度的任务
4. **可组合性**：底层子图可以被多个上层子图复用

**嵌套结构示意图**

```mermaid
graph TB
    subgraph "Level 1 - 主图"
        A[execute节点] --> B[调用Level2]
    end

    subgraph "Level 2 - 子图"
        C[transform节点] --> D[调用Level3]
    end

    subgraph "Level 3 - 子子图"
        E[process节点] --> F[+1操作]
    end

    B -.嵌套调用.-> C
    D -.嵌套调用.-> E

    style A fill:#e1f5fe
    style C fill:#fff3e0
    style E fill:#f3e5f5
```

**完整实现示例**

```python
from typing import TypedDict

# 定义三个层次的状态（每层有不同的关注点）
class Level1State(TypedDict):
    data: str           # 顶层：处理字符串数据

class Level2State(TypedDict):
    value: int          # 中层：处理整数值

class Level3State(TypedDict):
    count: int          # 底层：处理计数

# 第三层子图（最内层 - 原子操作）
def create_level3_graph():
    """
    最内层子图：执行基础的原子操作

    功能：对计数加 1
    抽象级别：最低（原子操作）
    """
    def process(state: Level3State) -> dict:
        """原子操作：递增"""
        return {"count": state["count"] + 1}

    graph = StateGraph(Level3State)
    graph.add_node("process", process)
    graph.set_entry_point("process")
    graph.add_edge("process", END)

    return graph.compile()

# 第二层子图（中间层 - 业务逻辑）
def create_level2_graph():
    """
    中间层子图：组合原子操作形成业务逻辑

    功能：调用 Level3 递增，然后乘以 2
    抽象级别：中等（业务逻辑）
    """
    # 获取底层子图
    level3 = create_level3_graph()

    def transform(state: Level2State) -> dict:
        """
        业务逻辑：先递增再翻倍

        执行步骤：
        1. 调用 Level3 子图进行递增
        2. 将结果乘以 2
        """
        # 调用更深层的子图
        result = level3.invoke({"count": state["value"]})

        # 在 Level3 结果基础上继续处理
        return {"value": result["count"] * 2}

    graph = StateGraph(Level2State)
    graph.add_node("transform", transform)
    graph.set_entry_point("transform")
    graph.add_edge("transform", END)

    return graph.compile()

# 第一层主图（顶层 - 工作流编排）
def create_level1_graph():
    """
    顶层主图：编排整个工作流

    功能：处理字符串输入，调用下层子图，返回字符串结果
    抽象级别：最高（工作流编排）
    """
    # 获取中层子图
    level2 = create_level2_graph()

    def execute(state: Level1State) -> dict:
        """
        工作流编排：
        1. 解析字符串为整数
        2. 调用 Level2 子图处理
        3. 格式化结果为字符串
        """
        # 数据转换：字符串 → 整数
        value = int(state["data"])

        # 调用中层子图（内部会调用 Level3）
        result = level2.invoke({"value": value})

        # 数据转换：整数 → 字符串
        return {"data": str(result["value"])}

    graph = StateGraph(Level1State)
    graph.add_node("execute", execute)
    graph.set_entry_point("execute")
    graph.add_edge("execute", END)

    return graph.compile()

# 测试嵌套子图
def test_nested_subgraph():
    """
    测试嵌套子图的执行流程

    执行追踪：
    1. Level1: "5" → int(5)
    2. Level2: 5 → Level3
    3. Level3: 5 + 1 = 6
    4. Level2: 6 * 2 = 12
    5. Level1: str(12) = "12"
    """
    app = create_level1_graph()
    result = app.invoke({"data": "5"})

    print("嵌套子图执行结果:")
    print(f"  输入: '5'")
    print(f"  Level3: 5 + 1 = 6")
    print(f"  Level2: 6 * 2 = 12")
    print(f"  Level1: str(12) = '12'")
    print(f"  输出: {result['data']}")

    # 验证结果：(5+1)*2 = 12
    assert result["data"] == "12"
    print("✅ 嵌套子图测试通过")
```

**嵌套子图的最佳实践**

| 实践 | 说明 | 优势 |
|------|------|------|
| **单一职责** | 每层子图只负责一个抽象级别 | 易于理解和维护 |
| **清晰边界** | 明确定义每层的输入输出 | 减少耦合 |
| **避免过深** | 嵌套层次不超过 3-4 层 | 防止过度复杂 |
| **状态转换** | 每层有独立的状态类型 | 类型安全 |
| **错误处理** | 每层捕获和传递错误 | 可靠性高 |

**何时使用嵌套子图？**

✅ **适用场景**：
- 复杂的多层业务逻辑
- 需要在不同抽象层次重用代码
- 大型团队协作开发
- 需要独立测试各个层次

❌ **不适用场景**：
- 简单的线性流程
- 只有一层抽象的任务
- 性能要求极高的场景（每层调用有开销）

### 2.4 模块化子图

**模块化设计理念**

模块化子图是将子图封装为可复用的功能模块，每个模块专注于单一职责。这种设计模式类似于微服务架构，具有以下特点：

1. **高内聚**：模块内部功能紧密相关
2. **低耦合**：模块之间通过清晰的接口通信
3. **可替换**：模块可以独立升级或替换
4. **可组合**：模块可以自由组合形成不同的工作流

**模块化架构图**

```mermaid
graph LR
    subgraph "模块库"
        M1[ValidationModule]
        M2[ProcessingModule]
        M3[StorageModule]
        M4[NotificationModule]
    end

    subgraph "工作流A"
        M1 --> M2
        M2 --> M3
    end

    subgraph "工作流B"
        M1 --> M2
        M2 --> M4
    end

    style M1 fill:#e1f5fe
    style M2 fill:#fff3e0
    style M3 fill:#e8f5e9
    style M4 fill:#f3e5f5
```

**完整的模块化实现**

```python
from typing import TypedDict, Literal

# ============= 模块1：验证模块 =============
class ValidationModule:
    """
    验证模块（子图）

    职责：验证输入数据的合法性
    输入：待验证的字符串
    输出：验证结果（通过/失败）+ 错误信息
    """

    class State(TypedDict):
        input: str
        valid: bool
        error: str | None

    @staticmethod
    def create():
        """工厂方法：创建验证子图"""
        def validate(state: "ValidationModule.State") -> dict:
            """验证逻辑"""
            # 规则1：不能为空
            if not state["input"]:
                return {"valid": False, "error": "Input cannot be empty"}

            # 规则2：长度限制
            if len(state["input"]) > 100:
                return {"valid": False, "error": "Input too long"}

            # 验证通过
            return {"valid": True, "error": None}

        # 构建子图
        graph = StateGraph(ValidationModule.State)
        graph.add_node("validate", validate)
        graph.set_entry_point("validate")
        graph.add_edge("validate", END)

        return graph.compile()

# ============= 模块2：处理模块 =============
class ProcessingModule:
    """
    处理模块（子图）

    职责：处理业务逻辑
    输入：原始数据
    输出：处理后的数据
    """

    class State(TypedDict):
        data: str
        processed: str

    @staticmethod
    def create():
        """工厂方法：创建处理子图"""
        def process(state: "ProcessingModule.State") -> dict:
            """处理逻辑：转大写"""
            processed = state["data"].upper()
            return {"processed": processed}

        # 构建子图
        graph = StateGraph(ProcessingModule.State)
        graph.add_node("process", process)
        graph.set_entry_point("process")
        graph.add_edge("process", END)

        return graph.compile()

# ============= 组合模块：主工作流 =============
class WorkflowState(TypedDict):
    """主工作流状态"""
    input: str          # 原始输入
    output: str         # 最终输出
    valid: bool         # 验证状态

def create_modular_workflow():
    """
    使用模块化子图的工作流

    架构：ValidationModule → ProcessingModule
    流程：验证 → 处理 → 输出
    """
    # 实例化各个模块（子图）
    validator = ValidationModule.create()
    processor = ProcessingModule.create()

    def validate_step(state: WorkflowState) -> dict:
        """
        步骤1：验证输入

        调用 ValidationModule 检查输入
        """
        # 状态转换：WorkflowState → ValidationModule.State
        result = validator.invoke({
            "input": state["input"],
            "valid": False,
            "error": None
        })

        # 提取验证结果
        return {"valid": result["valid"]}

    def process_step(state: WorkflowState) -> dict:
        """
        步骤2：处理数据

        如果验证通过，调用 ProcessingModule 处理
        """
        # 验证失败，返回错误信息
        if not state["valid"]:
            return {"output": "Invalid input"}

        # 状态转换：WorkflowState → ProcessingModule.State
        result = processor.invoke({
            "data": state["input"],
            "processed": ""
        })

        # 提取处理结果
        return {"output": result["processed"]}

    # 组装主工作流
    graph = StateGraph(WorkflowState)
    graph.add_node("validate", validate_step)
    graph.add_node("process", process_step)

    graph.set_entry_point("validate")
    graph.add_edge("validate", "process")
    graph.add_edge("process", END)

    return graph.compile()

# ============= 测试模块化工作流 =============
def test_modular_workflow():
    """测试模块化子图"""
    app = create_modular_workflow()

    # 测试1：有效输入
    print("=== 测试1：有效输入 ===")
    result1 = app.invoke({
        "input": "hello world",
        "output": "",
        "valid": False
    })
    print(f"输入: 'hello world'")
    print(f"输出: {result1['output']}")  # HELLO WORLD
    assert result1["output"] == "HELLO WORLD"

    # 测试2：空输入
    print("\n=== 测试2：空输入 ===")
    result2 = app.invoke({
        "input": "",
        "output": "",
        "valid": False
    })
    print(f"输入: ''")
    print(f"输出: {result2['output']}")  # Invalid input
    assert result2["output"] == "Invalid input"

    # 测试3：超长输入
    print("\n=== 测试3：超长输入 ===")
    long_input = "x" * 101
    result3 = app.invoke({
        "input": long_input,
        "output": "",
        "valid": False
    })
    print(f"输入: '{long_input[:20]}...' (长度 {len(long_input)})")
    print(f"输出: {result3['output']}")  # Invalid input
    assert result3["output"] == "Invalid input"

    print("\n✅ 所有测试通过")
```

**模块化设计的优势**

| 优势 | 说明 | 实际效果 |
|------|------|---------|
| **独立开发** | 不同模块可以并行开发 | 提高开发效率 |
| **独立测试** | 每个模块单独测试 | 提高代码质量 |
| **易于维护** | 修改模块不影响其他部分 | 降低维护成本 |
| **灵活组合** | 模块可以自由组合 | 支持多种工作流 |
| **版本管理** | 模块可以独立版本化 | 便于升级和回滚 |

**模块化最佳实践**

```python
# ✅ 好的实践：清晰的接口定义
class GoodModule:
    class State(TypedDict):
        # 明确的输入输出
        input: str
        output: str

    @staticmethod
    def create():
        # 工厂方法封装创建逻辑
        return graph.compile()

# ❌ 不好的实践：模块耦合
class BadModule:
    # 直接依赖其他模块的内部状态
    def process(state: AnotherModule.State):
        pass
```

**实际应用场景**

1. **数据处理管道**
   - 验证模块 → 清洗模块 → 转换模块 → 存储模块

2. **API网关**
   - 认证模块 → 限流模块 → 路由模块 → 响应模块

3. **内容审核系统**
   - 预处理模块 → 敏感词检测模块 → AI审核模块 → 人工审核模块

4. **订单处理系统**
   - 验证模块 → 库存检查模块 → 支付模块 → 发货模块

## 三、并行处理

### 3.1 并行处理概述

**什么是并行处理？**

并行处理是指多个节点同时执行，而不是顺序执行。在 LangGraph 中，当多个节点没有依赖关系时，它们可以并发运行，从而显著提升性能。

**为什么需要并行处理？**

1. **提升性能**：多个独立任务同时执行，总时间接近最长任务的时间
2. **资源利用**：充分利用多核 CPU 和异步 I/O
3. **降低延迟**：用户感知的响应时间更短
4. **提高吞吐量**：单位时间内处理更多请求

**串行 vs 并行对比**

```mermaid
graph TB
    subgraph "串行执行 - 总时间 300ms"
        S1[Task A: 100ms] --> S2[Task B: 100ms]
        S2 --> S3[Task C: 100ms]
        S3 --> S4[总计: 300ms]
    end

    subgraph "并行执行 - 总时间 100ms"
        P1[Task A: 100ms]
        P2[Task B: 100ms]
        P3[Task C: 100ms]
        P1 --> P4[总计: 100ms]
        P2 --> P4
        P3 --> P4
    end

    style S4 fill:#ffcdd2
    style P4 fill:#c8e6c9
```

**LangGraph 并行处理的核心机制**

| 机制 | 说明 | 适用场景 |
|------|------|---------|
| **多入口点** | 设置多个 entry_point | 固定数量的并行任务 |
| **Send API** | 动态创建并行任务 | 运行时决定任务数量 |
| **Reducer** | 使用 operator.add 合并结果 | 需要收集所有结果 |
| **同步点** | 所有并行任务完成后继续 | 需要等待所有任务完成 |

### 3.2 多入口点并行

**工作原理**

通过设置多个入口点，LangGraph 会同时启动这些节点的执行。所有入口点节点完成后，才会执行后续节点。

**执行流程图**

```mermaid
graph LR
    Start[开始] --> A[Task A]
    Start --> B[Task B]
    Start --> C[Task C]
    A --> Merge[合并节点]
    B --> Merge
    C --> Merge
    Merge --> End[结束]

    style Start fill:#e1f5fe
    style A fill:#fff3e0
    style B fill:#fff3e0
    style C fill:#fff3e0
    style Merge fill:#c8e6c9
```

**完整实现示例**

```python
from typing import TypedDict, Annotated
import operator
from langgraph.graph import StateGraph, END

# 定义状态（使用 Reducer 合并结果）
class ParallelState(TypedDict):
    input: str
    # 关键：使用 Annotated + operator.add 作为 Reducer
    # 这样多个节点返回的列表会自动合并
    results: Annotated[list[str], operator.add]

def task_a(state: ParallelState) -> dict:
    """
    任务 A：模拟耗时处理

    特点：
    - 独立执行，不依赖其他任务
    - 模拟 100ms 的处理时间
    - 返回结果到 results 列表
    """
    import time
    time.sleep(0.1)  # 模拟耗时操作
    return {"results": [f"Task A processed: {state['input']}"]}

def task_b(state: ParallelState) -> dict:
    """
    任务 B：模拟耗时处理

    与 Task A 并行执行
    """
    import time
    time.sleep(0.1)
    return {"results": [f"Task B processed: {state['input']}"]}

def task_c(state: ParallelState) -> dict:
    """
    任务 C：模拟耗时处理

    与 Task A、Task B 并行执行
    """
    import time
    time.sleep(0.1)
    return {"results": [f"Task C processed: {state['input']}"]}

def merge_results(state: ParallelState) -> dict:
    """
    合并节点：所有并行任务完成后执行

    此时 state['results'] 已经包含了所有任务的结果
    因为使用了 operator.add 作为 Reducer
    """
    result_count = len(state['results'])
    return {"results": [f"Merged {result_count} results"]}

def create_parallel_graph():
    """
    创建并行执行图

    架构：
    1. 三个入口点：task_a, task_b, task_c (并行)
    2. 一个同步点：merge (等待所有任务完成)
    """
    graph = StateGraph(ParallelState)

    # 添加所有节点
    graph.add_node("task_a", task_a)
    graph.add_node("task_b", task_b)
    graph.add_node("task_c", task_c)
    graph.add_node("merge", merge_results)

    # 关键：设置多个入口点（并行执行）
    graph.set_entry_point("task_a")
    graph.set_entry_point("task_b")
    graph.set_entry_point("task_c")

    # 所有任务完成后汇聚到 merge 节点
    graph.add_edge("task_a", "merge")
    graph.add_edge("task_b", "merge")
    graph.add_edge("task_c", "merge")

    # merge 节点完成后结束
    graph.add_edge("merge", END)

    return graph.compile()

# 测试并行执行
def test_parallel():
    """
    测试并行执行的性能提升

    预期：
    - 串行执行：0.3s (100ms * 3)
    - 并行执行：~0.1s (max(100ms, 100ms, 100ms))
    """
    import time

    app = create_parallel_graph()

    # 计时开始
    start = time.time()

    # 执行图
    result = app.invoke({
        "input": "test",
        "results": []
    })

    # 计时结束
    duration = time.time() - start

    print("=== 并行执行测试 ===")
    print(f"执行时间: {duration:.2f}s")
    print(f"结果列表: {result['results']}")
    print(f"结果数量: {len(result['results'])}")

    # 验证：并行执行应该接近 0.1s，而不是 0.3s
    assert duration < 0.2, f"并行执行应该 < 0.2s，实际 {duration:.2f}s"

    # 验证：应该有 4 个结果（3个任务 + 1个合并）
    assert len(result['results']) == 4

    print("✅ 并行执行测试通过 - 性能提升 3倍！")
```

**关键技术点**

1. **Reducer 机制**
```python
# 使用 Annotated + operator.add
results: Annotated[list[str], operator.add]

# 效果：
# Task A 返回 {"results": ["A"]}
# Task B 返回 {"results": ["B"]}
# Task C 返回 {"results": ["C"]}
# 最终状态：{"results": ["A", "B", "C"]}
```

2. **执行顺序**
```python
# 并行节点的执行顺序是不确定的
# 但所有并行节点完成后，才会执行后续节点
```

3. **性能计算**
```python
# 串行时间 = task_a + task_b + task_c = 300ms
# 并行时间 = max(task_a, task_b, task_c) = 100ms
# 加速比 = 串行时间 / 并行时间 = 3倍
```

**适用场景**

✅ **适合并行的任务**：
- 多个 API 调用（查询数据库、调用外部服务）
- 多个 LLM 推理（不同模型或不同 prompt）
- 数据预处理（分片处理大文件）
- 独立的计算任务（不共享状态）

❌ **不适合并行的任务**：
- 有依赖关系的任务（A 的输出是 B 的输入）
- 共享资源的任务（需要加锁）
- 顺序敏感的任务（必须按特定顺序执行）

### 3.3 Send API 动态并行

**什么是 Send API？**

Send API 是 LangGraph 提供的一种**动态创建并行任务**的机制。与多入口点不同，Send API 可以在运行时根据数据动态决定创建多少个并行任务。

**多入口点 vs Send API**

| 特性 | 多入口点 | Send API |
|------|---------|----------|
| **任务数量** | 编译时固定 | 运行时动态 |
| **适用场景** | 固定的并行任务 | 数据驱动的并行 |
| **灵活性** | 低 | 高 |
| **实现复杂度** | 简单 | 中等 |

**典型应用场景**

1. **批量数据处理**：对列表中的每个元素并行处理
2. **Map-Reduce**：Map 阶段并行处理多个分片
3. **多路搜索**：同时搜索多个数据源
4. **Fan-out 模式**：一个输入触发多个处理流程

**执行流程图**

```mermaid
graph TB
    Start[输入: items列表] --> Router[路由器]
    Router --> P1[处理item 1]
    Router --> P2[处理item 2]
    Router --> P3[处理item 3]
    Router --> P4[处理item N...]
    P1 --> Collect[收集结果]
    P2 --> Collect
    P3 --> Collect
    P4 --> Collect
    Collect --> End[输出: 所有结果]

    style Router fill:#fff3e0
    style P1 fill:#e1f5fe
    style P2 fill:#e1f5fe
    style P3 fill:#e1f5fe
    style P4 fill:#e1f5fe
    style Collect fill:#c8e6c9
```

**完整实现示例**

```python
from langgraph.constants import Send
from typing import TypedDict, Annotated
import operator

# 主图状态：包含待处理的项目列表
class DynamicParallelState(TypedDict):
    items: list[dict]                           # 输入：待处理项目
    results: Annotated[list[dict], operator.add]  # 输出：处理结果（自动合并）

# 单个任务状态：每个并行任务的状态
class ItemState(TypedDict):
    item: dict        # 当前处理的项目
    processed: dict   # 处理结果

def process_item(state: ItemState) -> dict:
    """
    处理单个项目的节点

    功能：对项目的 value 字段乘以 2

    注意：
    - 这个节点会被并行调用多次
    - 每次调用处理一个独立的 item
    """
    item = state["item"]
    processed = {
        "id": item["id"],
        "value": item["value"] * 2  # 业务逻辑
    }

    # 返回处理结果
    # 注意：这里返回的不是 results，而是 processed
    return {"processed": processed}

def dynamic_parallel_router(state: DynamicParallelState):
    """
    动态并行路由器

    核心功能：
    1. 检查输入数据（items 列表）
    2. 为每个 item 创建一个 Send 对象
    3. 返回 Send 对象列表，触发并行执行

    返回格式：
    [
        Send("节点名", 状态),
        Send("节点名", 状态),
        ...
    ]
    """
    # 动态创建并行任务
    # 有多少个 item，就创建多少个并行任务
    return [
        Send(
            "process_item",  # 目标节点
            {                # 该节点的输入状态
                "item": item,
                "processed": {}
            }
        )
        for item in state["items"]
    ]

def collect_results(state: DynamicParallelState) -> dict:
    """
    收集所有并行任务的结果

    注意：
    - 这个节点会等待所有并行任务完成
    - state['results'] 已经通过 Reducer 自动合并了所有结果
    """
    print(f"收集到 {len(state['results'])} 个结果")
    return {"results": state["results"]}

def create_dynamic_parallel_graph():
    """
    创建动态并行图

    架构：
    1. 入口：条件路由器（动态创建并行任务）
    2. 中间：process_item 节点（并行执行 N 次）
    3. 出口：collect 节点（收集结果）
    """
    graph = StateGraph(DynamicParallelState)

    # 添加节点
    graph.add_node("process_item", process_item)
    graph.add_node("collect", collect_results)

    # 关键：使用条件入口点 + 路由器创建动态并行
    graph.set_conditional_entry_point(
        dynamic_parallel_router,      # 路由函数
        {"process_item": "process_item"}  # 路由映射
    )

    # 所有并行任务完成后，汇聚到 collect
    graph.add_edge("process_item", "collect")
    graph.add_edge("collect", END)

    return graph.compile()

# 测试动态并行
def test_dynamic_parallel():
    """
    测试动态并行执行

    场景：处理 3 个项目，每个项目的 value * 2
    """
    app = create_dynamic_parallel_graph()

    print("=== 动态并行测试 ===")

    # 测试1：3个项目
    result1 = app.invoke({
        "items": [
            {"id": 1, "value": 10},
            {"id": 2, "value": 20},
            {"id": 3, "value": 30},
        ],
        "results": []
    })

    print(f"输入项目数: 3")
    print(f"处理结果: {result1['results']}")
    assert len(result1['results']) == 3
    assert result1['results'][0]["value"] == 20  # 10 * 2

    # 测试2：动态数量（5个项目）
    result2 = app.invoke({
        "items": [{"id": i, "value": i * 10} for i in range(1, 6)],
        "results": []
    })

    print(f"\n输入项目数: 5")
    print(f"处理结果: {result2['results']}")
    assert len(result2['results']) == 5

    # 测试3：空列表
    result3 = app.invoke({
        "items": [],
        "results": []
    })

    print(f"\n输入项目数: 0")
    print(f"处理结果: {result3['results']}")
    assert len(result3['results']) == 0

    print("\n✅ 动态并行测试通过")
```

**Send API 的工作原理**

```mermaid
sequenceDiagram
    participant Main as 主图
    participant Router as 路由器
    participant Task1 as 任务1
    participant Task2 as 任务2
    participant TaskN as 任务N
    participant Collect as 收集节点

    Main->>Router: 调用路由器
    Router->>Router: 遍历 items
    Router-->>Main: 返回 [Send(...), Send(...)]

    par 并行执行
        Main->>Task1: Send(process_item, state1)
        Main->>Task2: Send(process_item, state2)
        Main->>TaskN: Send(process_item, stateN)
    end

    Task1-->>Collect: 返回结果1
    Task2-->>Collect: 返回结果2
    TaskN-->>Collect: 返回结果N

    Collect->>Collect: 合并所有结果
    Collect-->>Main: 返回最终状态
```

**关键技术点**

1. **Send 对象创建**
```python
# Send 的两个参数：
Send(
    "target_node",  # 目标节点名称
    {"key": "value"}  # 传递给目标节点的状态
)
```

2. **状态转换**
```python
# 主图状态 → 任务状态的转换
for item in state["items"]:
    Send("process_item", {
        "item": item,      # 从主图状态提取
        "processed": {}    # 初始化任务状态
    })
```

3. **结果收集**
```python
# 使用 Reducer 自动合并结果
# 不需要手动收集，框架自动处理
results: Annotated[list[dict], operator.add]
```

**性能优势**

| 场景 | 串行时间 | 并行时间 | 加速比 |
|------|---------|---------|--------|
| 10个任务，每个100ms | 1000ms | ~100ms | 10x |
| 100个任务，每个100ms | 10000ms | ~100ms | 100x |
| N个任务，每个T ms | N*T ms | ~T ms | Nx |

**最佳实践**

✅ **推荐做法**：
```python
# 1. 明确定义任务状态
class TaskState(TypedDict):
    input: Any
    output: Any

# 2. 使用列表推导式创建 Send
[Send("worker", {"input": x}) for x in items]

# 3. 使用 Reducer 自动合并结果
results: Annotated[list, operator.add]
```

❌ **避免的做法**：
```python
# 1. 不要在 Send 中包含大量数据
Send("worker", {"huge_data": ...})  # ❌

# 2. 不要创建过多的并行任务（内存问题）
[Send(...) for _ in range(10000)]  # ❌

# 3. 不要在并行任务中修改共享状态
def worker(state):
    shared_dict[key] = value  # ❌ 并发问题
```

**实际应用案例**

1. **批量图片处理**
```python
# 并行处理多张图片
[Send("resize_image", {"image": img}) for img in images]
```

2. **多数据源查询**
```python
# 同时查询多个数据库
[Send("query_db", {"db": db, "sql": sql}) for db in databases]
```

3. **多模型推理**
```python
# 并行调用多个 LLM 模型
[Send("call_llm", {"model": m, "prompt": p}) for m in models]
```

### 3.4 Map-Reduce 模式

**什么是 Map-Reduce？**

Map-Reduce 是一种经典的并行计算模式，最早由 Google 提出。它将大规模数据处理分为两个阶段：

1. **Map 阶段**：对每个数据元素进行独立处理（并行）
2. **Reduce 阶段**：将所有处理结果聚合成最终结果（串行）

**Map-Reduce 的特点**

| 特点 | 说明 | 优势 |
|------|------|------|
| **分而治之** | 将大问题拆分为小问题 | 易于并行化 |
| **无状态 Map** | Map 操作相互独立 | 高度并行 |
| **聚合 Reduce** | 合并所有中间结果 | 得到最终答案 |
| **可扩展性** | 支持海量数据处理 | 线性扩展 |

**执行流程图**

```mermaid
graph TB
    Input[输入数据: 1,2,3,4,5] --> Map[Map阶段: 并行处理]

    Map --> M1[处理元素1: 1*2=2]
    Map --> M2[处理元素2: 2*2=4]
    Map --> M3[处理元素3: 3*2=6]
    Map --> M4[处理元素4: 4*2=8]
    Map --> M5[处理元素5: 5*2=10]

    M1 --> Reduce[Reduce阶段: 聚合]
    M2 --> Reduce
    M3 --> Reduce
    M4 --> Reduce
    M5 --> Reduce

    Reduce --> Output[输出结果: 30]

    style Input fill:#e1f5fe
    style Map fill:#fff3e0
    style M1 fill:#b3e5fc
    style M2 fill:#b3e5fc
    style M3 fill:#b3e5fc
    style M4 fill:#b3e5fc
    style M5 fill:#b3e5fc
    style Reduce fill:#c8e6c9
    style Output fill:#a5d6a7
```

**基础 Map-Reduce 实现**

```python
from typing import TypedDict, Annotated, List
import operator

# 定义状态
class MapReduceState(TypedDict):
    data: list[int]                          # 原始数据
    mapped: Annotated[list[int], operator.add]  # Map 结果（自动合并）
    reduced: int                             # Reduce 结果

def map_phase(state: MapReduceState) -> dict:
    """
    Map 阶段：对每个元素进行转换

    功能：将每个数字乘以 2
    特点：这里是简化版，实际可以并行处理每个元素
    """
    # 处理所有元素
    mapped = [x * 2 for x in state["data"]]

    print(f"Map阶段: {state['data']} -> {mapped}")
    return {"mapped": mapped}

def reduce_phase(state: MapReduceState) -> dict:
    """
    Reduce 阶段：聚合所有结果

    功能：求和所有 Map 结果
    特点：等待所有 Map 完成后执行
    """
    # 聚合操作：求和
    reduced = sum(state["mapped"])

    print(f"Reduce阶段: sum({state['mapped']}) = {reduced}")
    return {"reduced": reduced}

def create_map_reduce_graph():
    """
    创建 Map-Reduce 图

    架构：
    1. Map 阶段：转换数据
    2. Reduce 阶段：聚合结果
    """
    graph = StateGraph(MapReduceState)

    # 添加节点
    graph.add_node("map", map_phase)
    graph.add_node("reduce", reduce_phase)

    # 定义流程
    graph.set_entry_point("map")
    graph.add_edge("map", "reduce")
    graph.add_edge("reduce", END)

    return graph.compile()

# 测试 Map-Reduce
def test_map_reduce():
    """
    测试 Map-Reduce 模式

    场景：计算 [1,2,3,4,5] 每个元素乘以2后的总和
    """
    app = create_map_reduce_graph()

    print("=== Map-Reduce 测试 ===")

    result = app.invoke({
        "data": [1, 2, 3, 4, 5],
        "mapped": [],
        "reduced": 0
    })

    print(f"\n最终结果:")
    print(f"  原始数据: [1,2,3,4,5]")
    print(f"  Map结果: {result['mapped']}")
    print(f"  Reduce结果: {result['reduced']}")

    # 验证：(1*2) + (2*2) + (3*2) + (4*2) + (5*2) = 30
    assert result["reduced"] == 30

    print("\n✅ Map-Reduce 测试通过")
```

**真正的并行 Map-Reduce**

上面的示例中，Map 阶段是串行的。下面展示如何使用 Send API 实现真正的并行 Map：

```python
from langgraph.constants import Send

class ParallelMapReduceState(TypedDict):
    data: list[int]                          # 原始数据
    mapped: Annotated[list[int], operator.add]  # Map 结果
    reduced: int                             # Reduce 结果

class MapTaskState(TypedDict):
    value: int      # 单个输入值
    result: int     # 处理结果

def map_single(state: MapTaskState) -> dict:
    """
    处理单个元素（并行执行）

    这个函数会被并行调用多次
    """
    result = state["value"] * 2
    print(f"  Map任务: {state['value']} * 2 = {result}")
    return {"result": result}

def map_router(state: ParallelMapReduceState):
    """
    Map 路由器：为每个元素创建并行任务

    返回 Send 对象列表
    """
    print(f"创建 {len(state['data'])} 个并行Map任务")
    return [
        Send("map_single", {"value": x, "result": 0})
        for x in state["data"]
    ]

def reduce_parallel(state: ParallelMapReduceState) -> dict:
    """
    Reduce 阶段：聚合所有并行 Map 结果
    """
    reduced = sum(state["mapped"])
    print(f"Reduce: sum({state['mapped']}) = {reduced}")
    return {"reduced": reduced}

def create_parallel_map_reduce():
    """创建并行 Map-Reduce 图"""
    graph = StateGraph(ParallelMapReduceState)

    # 添加节点
    graph.add_node("map_single", map_single)
    graph.add_node("reduce", reduce_parallel)

    # 使用条件入口点创建动态并行
    graph.set_conditional_entry_point(
        map_router,
        {"map_single": "map_single"}
    )

    # Map 完成后 Reduce
    graph.add_edge("map_single", "reduce")
    graph.add_edge("reduce", END)

    return graph.compile()

# 测试并行 Map-Reduce
def test_parallel_map_reduce():
    """测试并行 Map-Reduce"""
    import time

    app = create_parallel_map_reduce()

    print("=== 并行 Map-Reduce 测试 ===")

    start = time.time()
    result = app.invoke({
        "data": [1, 2, 3, 4, 5],
        "mapped": [],
        "reduced": 0
    })
    duration = time.time() - start

    print(f"\n执行时间: {duration:.3f}s")
    print(f"最终结果: {result['reduced']}")

    assert result["reduced"] == 30
    print("✅ 并行 Map-Reduce 测试通过")
```

**Map-Reduce 的实际应用**

1. **文本分析**
```python
# Map: 统计每个文档的词频
# Reduce: 汇总所有文档的词频
```

2. **日志聚合**
```python
# Map: 解析每个日志文件
# Reduce: 统计错误总数
```

3. **大数据计算**
```python
# Map: 计算每个数据块的局部结果
# Reduce: 合并所有局部结果
```

4. **机器学习**
```python
# Map: 在每个数据子集上训练模型
# Reduce: 平均所有模型参数
```

**Map-Reduce vs 其他并行模式**

| 模式 | Map阶段 | Reduce阶段 | 适用场景 |
|------|---------|-----------|---------|
| **Map-Reduce** | 并行转换 | 串行聚合 | 需要汇总所有结果 |
| **Fan-out** | 并行处理 | 无 | 独立的并行任务 |
| **Pipeline** | 串行处理 | 无 | 有依赖的任务链 |

**性能分析**

```python
# 假设：
# - N 个数据元素
# - Map 每个元素耗时 T_map
# - Reduce 耗时 T_reduce

# 串行 Map-Reduce:
总时间 = N * T_map + T_reduce

# 并行 Map-Reduce:
总时间 = max(T_map) + T_reduce ≈ T_map + T_reduce

# 加速比:
加速比 = N * T_map / T_map = N
```

**最佳实践**

✅ **推荐**：
1. Map 操作保持无状态（纯函数）
2. Reduce 使用内置的聚合函数（sum、max、min）
3. 合理划分数据块大小
4. 使用 Reducer 自动合并结果

❌ **避免**：
1. Map 中访问共享状态
2. Reduce 中进行复杂计算
3. 创建过多的小任务（开销大）
4. 在 Map 中进行 I/O 密集操作

**常见的 Reduce 操作**

```python
# 1. 求和
reduce = sum(mapped_results)

# 2. 求最大值
reduce = max(mapped_results)

# 3. 计数
reduce = len(mapped_results)

# 4. 合并列表
reduce = [item for sublist in mapped_results for item in sublist]

# 5. 合并字典
reduce = {k: v for d in mapped_results for k, v in d.items()}
```

## 四、流式执行

### 4.1 流式执行概述

**什么是流式执行？**

流式执行是指将图的执行过程分解为多个步骤，每完成一个节点就立即返回结果，而不是等待整个图执行完毕。这种方式特别适合需要实时反馈的场景。

**为什么需要流式执行？**

1. **实时反馈**：用户可以立即看到处理进度，提升用户体验
2. **降低感知延迟**：虽然总时间不变，但用户感觉更快
3. **早期错误检测**：可以在中间节点发现问题，及时终止
4. **资源优化**：可以边处理边展示，减少内存占用
5. **适合长任务**：对于耗时任务，可以展示中间进度

**流式 vs 阻塞对比**

```mermaid
sequenceDiagram
    participant U as 用户
    participant S as 系统

    Note over U,S: 阻塞模式
    U->>S: 发送请求
    Note over S: 节点1执行...
    Note over S: 节点2执行...
    Note over S: 节点3执行...
    S-->>U: 返回最终结果

    Note over U,S: 流式模式
    U->>S: 发送请求
    Note over S: 节点1执行
    S-->>U: 返回节点1结果
    Note over S: 节点2执行
    S-->>U: 返回节点2结果
    Note over S: 节点3执行
    S-->>U: 返回节点3结果
```

**LangGraph 流式API**

| API | 说明 | 适用场景 |
|-----|------|---------|
| **stream()** | 同步流式执行 | 同步程序 |
| **astream()** | 异步流式执行 | 异步程序 |
| **stream_mode** | 控制流式粒度 | 自定义输出格式 |

**流式输出模式**

| 模式 | 输出内容 | 适用场景 |
|------|---------|---------|
| **values** | 每个节点完成后的完整状态 | 查看状态变化 |
| **updates** | 每个节点返回的更新 | 最小化数据传输 |
| **debug** | 详细的执行信息 | 调试和监控 |

### 4.2 基本流式输出

**工作原理**

流式执行会在每个节点完成后产生一个事件，包含节点名称和输出结果。消费者可以实时处理这些事件。

**执行流程图**

```mermaid
graph LR
    Start[开始] --> N1[节点1]
    N1 --> E1[事件1: 输出结果1]
    E1 --> N2[节点2]
    N2 --> E2[事件2: 输出结果2]
    E2 --> N3[节点3]
    N3 --> E3[事件3: 输出结果3]
    E3 --> End[结束]

    style E1 fill:#e1f5fe
    style E2 fill:#e1f5fe
    style E3 fill:#e1f5fe
```

**完整实现示例**

```python
from typing import TypedDict
from langgraph.graph import StateGraph, END

# 定义状态
class StreamState(TypedDict):
    messages: list[str]  # 消息列表
    current: str         # 当前消息

def generate_messages(state: StreamState) -> dict:
    """
    生成多条消息

    功能：模拟消息生成过程
    返回：包含5条消息的列表
    """
    messages = [f"Message {i}" for i in range(1, 6)]
    print(f"生成了 {len(messages)} 条消息")
    return {"messages": messages}

def create_stream_graph():
    """
    创建流式图

    架构：单节点图，用于演示流式输出
    """
    graph = StateGraph(StreamState)

    graph.add_node("generate", generate_messages)
    graph.set_entry_point("generate")
    graph.add_edge("generate", END)

    return graph.compile()

# 同步流式消费
def test_streaming():
    """
    测试流式输出

    特点：
    - 使用 stream() 方法获取迭代器
    - 每个节点完成后产生一个事件
    - 事件格式：{节点名: 节点输出}
    """
    app = create_stream_graph()

    print("=== 同步流式输出 ===")
    for chunk in app.stream({"messages": [], "current": ""}):
        # chunk 格式：{"节点名": {"字段": "值"}}
        print(f"收到事件: {chunk}")

        # 处理节点输出
        for node_name, node_output in chunk.items():
            print(f"  节点 '{node_name}' 完成")
            print(f"  输出: {node_output}")

# 异步流式消费
async def test_async_streaming():
    """
    测试异步流式输出

    优势：
    - 不阻塞主线程
    - 支持并发处理多个流
    - 更高的吞吐量
    """
    app = create_stream_graph()

    print("\n=== 异步流式输出 ===")
    async for chunk in app.astream({"messages": [], "current": ""}):
        print(f"异步收到: {chunk}")

        # 可以在这里进行异步处理
        for node_name, node_output in chunk.items():
            print(f"  异步处理节点 '{node_name}'")

# 测试不同的流式模式
def test_stream_modes():
    """
    测试不同的流式模式

    三种模式：
    1. values: 完整状态
    2. updates: 只包含更新
    3. debug: 调试信息
    """
    app = create_stream_graph()
    initial_state = {"messages": [], "current": ""}

    # 模式1: values (默认)
    print("\n=== 模式1: values (完整状态) ===")
    for chunk in app.stream(initial_state, stream_mode="values"):
        print(f"完整状态: {chunk}")

    # 模式2: updates (只有更新)
    print("\n=== 模式2: updates (只有更新) ===")
    for chunk in app.stream(initial_state, stream_mode="updates"):
        print(f"更新内容: {chunk}")

    # 模式3: debug (调试信息)
    print("\n=== 模式3: debug (调试信息) ===")
    for chunk in app.stream(initial_state, stream_mode="debug"):
        print(f"调试信息: {chunk}")

# 流式处理多节点图
def test_multi_node_streaming():
    """
    测试多节点图的流式输出

    场景：三个节点依次执行，流式返回每个节点的结果
    """
    class MultiNodeState(TypedDict):
        value: int
        stage: str

    def node1(state: MultiNodeState) -> dict:
        print("  [节点1] 执行中...")
        return {"value": state["value"] + 1, "stage": "node1"}

    def node2(state: MultiNodeState) -> dict:
        print("  [节点2] 执行中...")
        return {"value": state["value"] * 2, "stage": "node2"}

    def node3(state: MultiNodeState) -> dict:
        print("  [节点3] 执行中...")
        return {"value": state["value"] + 10, "stage": "node3"}

    # 构建图
    graph = StateGraph(MultiNodeState)
    graph.add_node("node1", node1)
    graph.add_node("node2", node2)
    graph.add_node("node3", node3)

    graph.set_entry_point("node1")
    graph.add_edge("node1", "node2")
    graph.add_edge("node2", "node3")
    graph.add_edge("node3", END)

    app = graph.compile()

    # 流式执行
    print("\n=== 多节点流式输出 ===")
    print("输入: value=5")

    for i, chunk in enumerate(app.stream({"value": 5, "stage": ""})):
        print(f"\n第 {i+1} 个事件:")
        for node_name, output in chunk.items():
            print(f"  节点: {node_name}")
            print(f"  当前值: {output.get('value')}")
            print(f"  阶段: {output.get('stage')}")

    print("\n最终结果: (5+1)*2+10 = 22")
```

**流式输出的关键点**

1. **事件格式**
```python
# stream() 返回的每个 chunk 格式：
{
    "节点名": {
        "字段1": "值1",
        "字段2": "值2"
    }
}
```

2. **执行顺序**
```python
# 节点按照图的拓扑顺序执行
# 每个节点完成后立即产生事件
# 不会等待整个图执行完毕
```

3. **性能对比**
```python
# 阻塞模式：
# 总感知时间 = 所有节点执行时间之和

# 流式模式：
# 首次响应时间 = 第一个节点执行时间
# 用户感知延迟 << 总执行时间
```

**适用场景**

✅ **适合流式的场景**：
- LLM 文本生成（逐字输出）
- 长时间数据处理（显示进度）
- 多步骤工作流（展示中间结果）
- 实时监控系统（即时反馈）

❌ **不适合流式的场景**：
- 需要原子性的操作（要么全成功要么全失败）
- 后续节点依赖全部前序结果
- 输出需要后处理的场景
- 对实时性没有要求的批处理

### 4.3 实时流式处理

**什么是实时流式处理？**

实时流式处理是指在节点内部也采用流式方式生成数据，常见于 LLM 文本生成场景。这种方式可以实现逐字或逐句的实时输出，极大提升用户体验。

**应用场景**

1. **LLM 对话**：GPT、Claude 等模型的逐字输出
2. **实时翻译**：边识别边翻译
3. **代码生成**：逐行生成代码
4. **数据流处理**：实时处理传感器数据

**两层流式结构**

```mermaid
graph TB
    subgraph "图级流式"
        A[节点1] --> B[事件1]
        B --> C[节点2]
        C --> D[事件2]
    end

    subgraph "节点级流式"
        E[开始生成] --> F[chunk 1]
        F --> G[chunk 2]
        G --> H[chunk 3]
        H --> I[完成]
    end

    style B fill:#e1f5fe
    style D fill:#e1f5fe
    style F fill:#fff3e0
    style G fill:#fff3e0
    style H fill:#fff3e0
```

**完整实现示例**

```python
from typing import TypedDict, AsyncGenerator
import asyncio

# 定义状态
class RealtimeState(TypedDict):
    query: str          # 用户查询
    response: str       # 完整响应
    chunks: list[str]   # 响应片段

async def stream_llm_response(query: str) -> AsyncGenerator[str, None]:
    """
    模拟 LLM 流式响应

    功能：模拟 OpenAI/Claude 的流式 API
    特点：逐词生成，模拟网络延迟
    """
    response = f"Response to: {query}"
    words = response.split()

    print(f"开始流式生成 {len(words)} 个词...")

    for i, word in enumerate(words, 1):
        await asyncio.sleep(0.1)  # 模拟网络延迟
        print(f"  生成第 {i} 个词: '{word}'")
        yield word + " "

async def streaming_node(state: RealtimeState) -> dict:
    """
    流式处理节点

    功能：
    1. 调用流式 API
    2. 收集所有 chunks
    3. 返回完整响应

    注意：这里是在节点内部处理流式，
    图级仍然是节点完成后才产生事件
    """
    print(f"处理查询: {state['query']}")

    chunks = []
    async for chunk in stream_llm_response(state["query"]):
        chunks.append(chunk)
        # 在这里可以实时处理每个 chunk
        # 例如：发送到前端、保存到数据库等

    response = "".join(chunks)
    print(f"生成完毕，总长度: {len(response)} 字符")

    return {
        "response": response,
        "chunks": chunks
    }

def create_realtime_graph():
    """
    创建实时流式图

    架构：单节点，内部使用流式生成
    """
    graph = StateGraph(RealtimeState)
    graph.add_node("stream", streaming_node)
    graph.set_entry_point("stream")
    graph.add_edge("stream", END)

    return graph.compile()

# 测试实时流式
async def test_realtime_streaming():
    """
    测试实时流式处理

    特点：
    - 节点内部流式生成
    - 图级仍然是节点粒度的事件
    """
    app = create_realtime_graph()

    print("=== 实时流式处理 ===")

    async for event in app.astream({
        "query": "Hello world",
        "response": "",
        "chunks": []
    }):
        # 节点完成后收到事件
        for node_name, output in event.items():
            print(f"\n节点 '{node_name}' 完成")
            print(f"完整响应: {output['response']}")
            print(f"Chunks数量: {len(output['chunks'])}")

# 真正的逐chunk流式（需要自定义实现）
async def test_true_streaming():
    """
    实现真正的逐chunk流式输出

    方法：使用回调或队列在生成时立即发送
    """
    import asyncio

    # 创建队列用于传递 chunks
    chunk_queue = asyncio.Queue()

    async def producer(query: str):
        """生产者：生成 chunks"""
        response = f"Response to: {query}"
        words = response.split()

        for word in words:
            await asyncio.sleep(0.05)
            await chunk_queue.put(word + " ")

        # 发送结束信号
        await chunk_queue.put(None)

    async def consumer():
        """消费者：处理 chunks"""
        print("\n=== 逐chunk流式输出 ===")
        full_response = []

        while True:
            chunk = await chunk_queue.get()
            if chunk is None:
                break

            # 实时输出
            print(chunk, end='', flush=True)
            full_response.append(chunk)

        print(f"\n\n完整响应: {''.join(full_response)}")

    # 并发运行生产者和消费者
    await asyncio.gather(
        producer("Hello world"),
        consumer()
    )

# 运行测试
async def run_all_tests():
    """运行所有测试"""
    # 测试1：节点级流式
    await test_realtime_streaming()

    # 测试2：逐chunk流式
    await test_true_streaming()

# 如果直接运行此脚本
if __name__ == "__main__":
    asyncio.run(run_all_tests())
```

**实时流式的最佳实践**

1. **使用异步生成器**
```python
async def stream_data() -> AsyncGenerator[str, None]:
    for item in items:
        await asyncio.sleep(0)  # 让出控制权
        yield item
```

2. **错误处理**
```python
async def safe_stream():
    try:
        async for chunk in stream_data():
            yield chunk
    except Exception as e:
        yield f"Error: {str(e)}"
```

3. **超时控制**
```python
async def stream_with_timeout():
    try:
        async with asyncio.timeout(30):  # 30秒超时
            async for chunk in stream_data():
                yield chunk
    except asyncio.TimeoutError:
        yield "Timeout"
```

**性能对比**

| 模式 | 首字延迟 | 总时间 | 用户体验 |
|------|---------|--------|---------|
| **阻塞模式** | 等所有生成完 | 10s | 差 |
| **节点流式** | 等节点完成 | 10s | 中 |
| **实时流式** | 100ms | 10s | 优 |

**LLM集成示例**

```python
# 与 OpenAI 集成
async def stream_openai(query: str):
    """
    OpenAI 流式调用

    使用 stream=True 参数
    """
    from openai import AsyncOpenAI

    client = AsyncOpenAI()

    stream = await client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": query}],
        stream=True  # 启用流式
    )

    async for chunk in stream:
        if chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content

# 与 Anthropic Claude 集成
async def stream_claude(query: str):
    """
    Claude 流式调用

    使用 stream 方法
    """
    from anthropic import AsyncAnthropic

    client = AsyncAnthropic()

    async with client.messages.stream(
        model="claude-3-5-sonnet-20241022",
        messages=[{"role": "user", "content": query}],
        max_tokens=1024
    ) as stream:
        async for text in stream.text_stream:
            yield text
```

**实际应用架构**

```mermaid
graph LR
    A[用户] --> B[前端]
    B --> C[WebSocket/SSE]
    C --> D[后端API]
    D --> E[LangGraph]
    E --> F[LLM API]

    F -.流式返回.-> E
    E -.流式返回.-> D
    D -.流式推送.-> C
    C -.实时展示.-> B

    style C fill:#e1f5fe
    style E fill:#fff3e0
    style F fill:#f3e5f5
```

**关键技术点**

1. **缓冲策略**
```python
# 不要逐字节发送，适当缓冲
buffer = []
for chunk in chunks:
    buffer.append(chunk)
    if len(buffer) >= 10 or is_sentence_end(chunk):
        yield ''.join(buffer)
        buffer = []
```

2. **背压处理**
```python
# 如果消费者处理不过来，生产者要减速
if queue.qsize() > 100:
    await asyncio.sleep(0.1)
```

3. **优雅关闭**
```python
try:
    async for chunk in stream:
        yield chunk
finally:
    # 清理资源
    await stream.close()
```

## 五、动态图

### 5.1 动态图概述

**什么是动态图？**

动态图是指在**运行时根据参数或配置动态构建图结构**，而不是在代码中硬编码固定的图结构。这种灵活性使得同一套代码可以根据不同的输入创建不同的工作流。

**为什么需要动态图？**

1. **灵活性**：根据不同场景使用不同的处理流程
2. **可配置性**：通过配置文件控制工作流结构
3. **代码复用**：一套代码支持多种工作流
4. **动态扩展**：无需修改代码即可添加新功能
5. **A/B测试**：轻松切换不同的处理策略

**静态图 vs 动态图**

```mermaid
graph TB
    subgraph "静态图 - 固定结构"
        S1[节点A] --> S2[节点B]
        S2 --> S3[节点C]
        S3 --> S4[结束]
    end

    subgraph "动态图 - 灵活结构"
        D1[配置] --> D2{动态构建}
        D2 --> D3[3节点流程]
        D2 --> D4[5节点流程]
        D2 --> D5[自定义流程]
    end

    style S4 fill:#ffcdd2
    style D2 fill:#fff3e0
    style D3 fill:#c8e6c9
    style D4 fill:#c8e6c9
    style D5 fill:#c8e6c9
```

**动态图的应用场景**

| 场景 | 说明 | 示例 |
|------|------|------|
| **可配置工作流** | 用户自定义处理流程 | 数据处理管道 |
| **多租户系统** | 不同租户不同流程 | SaaS平台 |
| **A/B测试** | 实验不同的策略 | 推荐系统 |
| **插件架构** | 动态加载和组合插件 | 内容审核系统 |
| **条件流程** | 根据输入选择流程 | 业务审批流 |

### 5.2 运行时构建图

**工作原理**

在运行时根据参数（如节点数量、配置文件等）动态创建节点和边，最后编译成可执行的图。

**动态构建流程**

```mermaid
graph LR
    A[输入参数] --> B[创建StateGraph]
    B --> C[循环添加节点]
    C --> D[动态添加边]
    D --> E[编译图]
    E --> F[返回可执行图]

    style A fill:#e1f5fe
    style C fill:#fff3e0
    style D fill:#fff3e0
    style E fill:#c8e6c9
```

**完整实现示例**

```python
from typing import TypedDict, Literal
from langgraph.graph import StateGraph, END

# 定义状态
class DynamicState(TypedDict):
    config: dict    # 配置信息
    result: str     # 处理结果

def create_dynamic_graph(node_count: int):
    """
    根据参数动态创建图

    参数:
        node_count: 要创建的节点数量

    返回:
        编译后的图应用

    特点:
    - 节点数量在运行时决定
    - 节点自动串联成链
    - 每个节点执行简单的处理逻辑
    """
    def make_node(index: int):
        """
        节点工厂函数

        使用闭包捕获节点索引，创建独立的节点函数
        """
        def node(state: DynamicState) -> dict:
            """节点处理函数"""
            return {"result": f"Node {index} executed"}
        return node

    # 1. 创建图实例
    graph = StateGraph(DynamicState)

    # 2. 动态添加节点
    print(f"创建包含 {node_count} 个节点的图...")
    for i in range(node_count):
        node_name = f"node_{i}"
        graph.add_node(node_name, make_node(i))
        print(f"  添加节点: {node_name}")

    # 3. 动态添加边（串联所有节点）
    # 设置第一个节点为入口
    graph.set_entry_point("node_0")

    # 连接相邻节点
    for i in range(node_count - 1):
        from_node = f"node_{i}"
        to_node = f"node_{i+1}"
        graph.add_edge(from_node, to_node)
        print(f"  连接: {from_node} -> {to_node}")

    # 最后一个节点连接到结束
    graph.add_edge(f"node_{node_count-1}", END)

    # 4. 编译并返回
    return graph.compile()

# 测试动态图
def test_dynamic_graph():
    """
    测试动态图的创建和执行

    演示:
    1. 创建不同大小的图
    2. 执行并查看结果
    """
    print("=== 动态图测试 ===\n")

    # 测试1: 创建 3 节点的图
    print("测试1: 3节点图")
    app3 = create_dynamic_graph(3)
    result3 = app3.invoke({"config": {}, "result": ""})
    print(f"执行结果: {result3['result']}\n")

    # 测试2: 创建 5 节点的图
    print("测试2: 5节点图")
    app5 = create_dynamic_graph(5)
    result5 = app5.invoke({"config": {}, "result": ""})
    print(f"执行结果: {result5['result']}\n")

    # 测试3: 创建单节点图
    print("测试3: 单节点图")
    app1 = create_dynamic_graph(1)
    result1 = app1.invoke({"config": {}, "result": ""})
    print(f"执行结果: {result1['result']}\n")

    print("✅ 动态图测试通过")

# 高级示例：根据配置动态构建图
def create_configurable_graph(config: dict):
    """
    根据配置字典动态构建图

    配置格式:
    {
        "nodes": [
            {"name": "validate", "type": "validation"},
            {"name": "process", "type": "processing"},
            {"name": "save", "type": "storage"}
        ],
        "edges": [
            ["validate", "process"],
            ["process", "save"]
        ]
    }
    """
    class ConfigurableState(TypedDict):
        data: str
        status: str

    # 节点类型映射
    node_functions = {
        "validation": lambda state: {"status": "validated"},
        "processing": lambda state: {"status": "processed"},
        "storage": lambda state: {"status": "saved"}
    }

    graph = StateGraph(ConfigurableState)

    # 根据配置添加节点
    for node_config in config["nodes"]:
        node_name = node_config["name"]
        node_type = node_config["type"]

        if node_type in node_functions:
            graph.add_node(node_name, node_functions[node_type])

    # 根据配置添加边
    if config["nodes"]:
        graph.set_entry_point(config["nodes"][0]["name"])

    for from_node, to_node in config["edges"]:
        graph.add_edge(from_node, to_node)

    # 最后一个节点连接到END
    if config["nodes"]:
        last_node = config["nodes"][-1]["name"]
        graph.add_edge(last_node, END)

    return graph.compile()

# 测试可配置图
def test_configurable_graph():
    """测试基于配置的动态图"""
    config = {
        "nodes": [
            {"name": "validate", "type": "validation"},
            {"name": "process", "type": "processing"},
            {"name": "save", "type": "storage"}
        ],
        "edges": [
            ["validate", "process"],
            ["process", "save"]
        ]
    }

    print("\n=== 可配置图测试 ===")
    print(f"配置: {config}")

    app = create_configurable_graph(config)
    result = app.invoke({"data": "test data", "status": ""})

    print(f"最终状态: {result['status']}")
    print("✅ 可配置图测试通过")
```

**动态图的关键技术**

1. **节点工厂模式**
```python
# 使用闭包创建独立的节点函数
def make_node(index: int):
    def node(state):
        return {"value": index}
    return node
```

2. **循环构建**
```python
# 根据参数循环创建节点和边
for i in range(count):
    graph.add_node(f"node_{i}", make_node(i))
```

3. **配置驱动**
```python
# 从配置文件读取图结构
config = load_config("workflow.yaml")
graph = build_from_config(config)
```

**优势与限制**

| 方面 | 优势 | 限制 |
|------|------|------|
| **灵活性** | 运行时调整结构 | 调试相对困难 |
| **可维护性** | 集中管理配置 | 需要验证配置 |
| **扩展性** | 易于添加新节点 | 可能影响性能 |
| **复用性** | 一套代码多种流程 | 复杂度增加 |

### 5.3 条件图构建

**什么是条件图构建？**

条件图构建是根据运行时的条件（如模式、用户类型、环境等）选择不同的图结构。这是动态图的一种特殊形式，强调基于条件的分支选择。

**应用场景**

1. **多模式处理**：新手模式 vs 专家模式
2. **环境切换**：开发环境 vs 生产环境
3. **用户分层**：普通用户 vs VIP用户
4. **功能开关**：A/B测试、灰度发布

**条件分支示意图**

```mermaid
graph TB
    A[输入条件] --> B{mode?}
    B -->|simple| C[简单流程]
    B -->|advanced| D[高级流程]
    B -->|expert| E[专家流程]

    C --> C1[节点1]
    C1 --> C2[结束]

    D --> D1[验证]
    D1 --> D2[处理]
    D2 --> D3[结束]

    E --> E1[验证]
    E1 --> E2[深度处理]
    E2 --> E3[优化]
    E3 --> E4[结束]

    style B fill:#fff3e0
    style C fill:#c8e6c9
    style D fill:#81d4fa
    style E fill:#f3e5f5
```

**完整实现示例**

```python
from typing import TypedDict, Literal
from langgraph.graph import StateGraph, END

# 定义状态
class ConditionalGraphState(TypedDict):
    mode: Literal["simple", "advanced"]  # 模式选择
    result: str                           # 处理结果

def create_conditional_graph(mode: str):
    """
    根据模式创建不同的图

    参数:
        mode: "simple" 或 "advanced"

    返回:
        编译后的图应用

    特点:
    - 简单模式：单节点快速处理
    - 高级模式：多节点完整流程
    """
    # 定义节点函数
    def simple_process(state: ConditionalGraphState) -> dict:
        """简单处理：单步完成"""
        return {"result": "Simple processing"}

    def advanced_process(state: ConditionalGraphState) -> dict:
        """高级处理：复杂逻辑"""
        return {"result": "Advanced processing"}

    def validation(state: ConditionalGraphState) -> dict:
        """验证节点：高级模式专属"""
        return {"result": "Validated"}

    # 创建图
    graph = StateGraph(ConditionalGraphState)

    if mode == "simple":
        # 简单模式：只有处理节点
        print("构建简单模式图...")
        graph.add_node("process", simple_process)
        graph.set_entry_point("process")
        graph.add_edge("process", END)

    else:
        # 高级模式：包含验证和处理
        print("构建高级模式图...")
        graph.add_node("validate", validation)
        graph.add_node("process", advanced_process)
        graph.set_entry_point("validate")
        graph.add_edge("validate", "process")
        graph.add_edge("process", END)

    return graph.compile()

# 测试条件图
def test_conditional_graph():
    """
    测试条件图构建

    演示不同模式下的不同执行流程
    """
    print("=== 条件图测试 ===\n")

    # 测试1: 简单模式
    print("测试1: 简单模式")
    simple_app = create_conditional_graph("simple")
    simple_result = simple_app.invoke({"mode": "simple", "result": ""})
    print(f"结果: {simple_result['result']}\n")

    # 测试2: 高级模式
    print("测试2: 高级模式")
    advanced_app = create_conditional_graph("advanced")
    advanced_result = advanced_app.invoke({"mode": "advanced", "result": ""})
    print(f"结果: {advanced_result['result']}\n")

    print("✅ 条件图测试通过")

# 更复杂的条件图示例
def create_multi_condition_graph(config: dict):
    """
    根据多个条件创建图

    配置:
    {
        "user_type": "vip" | "normal",
        "enable_cache": true | false,
        "enable_logging": true | false
    }
    """
    class MultiCondState(TypedDict):
        data: str
        result: str

    graph = StateGraph(MultiCondState)

    # 必须的节点
    graph.add_node("process", lambda s: {"result": "processed"})

    # 条件1：根据用户类型添加不同的预处理
    if config.get("user_type") == "vip":
        graph.add_node("vip_preprocess", lambda s: {"data": "VIP: " + s["data"]})
        graph.set_entry_point("vip_preprocess")
        graph.add_edge("vip_preprocess", "process")
    else:
        graph.set_entry_point("process")

    # 条件2：是否启用缓存
    if config.get("enable_cache"):
        graph.add_node("cache", lambda s: {"result": "cached: " + s["result"]})
        graph.add_edge("process", "cache")
        last_node = "cache"
    else:
        last_node = "process"

    # 条件3：是否启用日志
    if config.get("enable_logging"):
        graph.add_node("log", lambda s: {"result": "logged: " + s["result"]})
        graph.add_edge(last_node, "log")
        last_node = "log"

    graph.add_edge(last_node, END)

    return graph.compile()

# 测试多条件图
def test_multi_condition_graph():
    """测试多条件图"""
    print("\n=== 多条件图测试 ===")

    # 配置1：VIP用户 + 缓存 + 日志
    config1 = {
        "user_type": "vip",
        "enable_cache": True,
        "enable_logging": True
    }
    print(f"\n配置1: {config1}")
    app1 = create_multi_condition_graph(config1)
    result1 = app1.invoke({"data": "test", "result": ""})
    print(f"结果: {result1['result']}")

    # 配置2：普通用户 + 无缓存 + 无日志
    config2 = {
        "user_type": "normal",
        "enable_cache": False,
        "enable_logging": False
    }
    print(f"\n配置2: {config2}")
    app2 = create_multi_condition_graph(config2)
    result2 = app2.invoke({"data": "test", "result": ""})
    print(f"结果: {result2['result']}")

    print("\n✅ 多条件图测试通过")
```

**条件图的最佳实践**

1. **清晰的条件逻辑**
```python
# ✅ 好的做法：条件明确
if mode == "simple":
    add_simple_nodes()
elif mode == "advanced":
    add_advanced_nodes()
else:
    raise ValueError(f"Unknown mode: {mode}")
```

2. **配置验证**
```python
# 在构建前验证配置
def validate_config(config: dict):
    required_keys = ["mode", "user_type"]
    for key in required_keys:
        if key not in config:
            raise ValueError(f"Missing key: {key}")
```

3. **文档化不同模式**
```python
# 清晰记录每种模式的行为
MODES = {
    "simple": "单节点快速处理",
    "advanced": "多节点完整流程",
    "expert": "包含优化和验证"
}
```

### 5.4 插件系统

**什么是插件系统？**

插件系统是一种架构模式,允许在运行时动态注册、加载和组合功能模块。在 LangGraph 中,通过动态图构建能力,可以实现灵活的插件架构,让用户自定义工作流。

**为什么需要插件系统？**

1. **扩展性**：用户可以添加自定义功能而不修改核心代码
2. **灵活性**：根据需求选择性启用或禁用插件
3. **可组合性**：多个插件可以任意组合形成新的功能
4. **易维护**：插件独立开发、测试和部署
5. **多租户**：不同用户可以配置不同的插件组合

**插件系统架构**

```mermaid
graph TB
    A[插件注册] --> B[插件管理器]
    B --> C{用户配置}
    C -->|启用插件列表| D[动态构建图]
    D --> E[Plugin 1]
    D --> F[Plugin 2]
    D --> G[Plugin 3]
    E --> H[串联执行]
    F --> H
    G --> H
    H --> I[输出结果]

    style A fill:#e1f5fe
    style B fill:#fff3e0
    style D fill:#ffe0b2
    style E fill:#c8e6c9
    style F fill:#c8e6c9
    style G fill:#c8e6c9
    style H fill:#b2dfdb
```

**插件系统的应用场景**

| 场景 | 说明 | 示例 |
|------|------|------|
| **内容处理** | 文本/图像/视频处理管道 | 内容审核系统 |
| **数据处理** | ETL 数据转换流程 | 数据清洗工具 |
| **微服务编排** | 动态组合服务调用 | API 网关 |
| **自动化工作流** | 用户自定义任务流 | CI/CD 系统 |
| **消息处理** | 消息过滤和转换 | 消息队列处理器 |

**完整实现示例**

```python
from typing import TypedDict, Callable, Dict
from langgraph.graph import StateGraph, END

# 定义插件状态
class PluginState(TypedDict):
    input: str      # 原始输入
    output: str     # 处理后的输出

class PluginSystem:
    """
    插件系统管理器

    功能:
    1. 注册插件（register）
    2. 根据配置动态构建图（create_graph）
    3. 支持插件链式组合
    """

    def __init__(self):
        """
        初始化插件系统

        维护一个插件字典: name -> function
        """
        self.plugins: Dict[str, Callable] = {}

    def register(self, name: str, plugin: Callable):
        """
        注册插件

        参数:
            name: 插件名称（唯一标识）
            plugin: 插件函数（接受 state 返回 dict）

        示例:
            system.register("uppercase", uppercase_plugin)
        """
        self.plugins[name] = plugin
        print(f"✅ 插件已注册: {name}")

    def create_graph(self, enabled_plugins: list[str]):
        """
        根据启用的插件列表动态创建图

        参数:
            enabled_plugins: 要启用的插件名称列表

        返回:
            编译后的图应用

        工作流程:
        1. 创建空图
        2. 遍历启用的插件列表
        3. 为每个插件创建节点
        4. 串联所有插件节点
        5. 编译并返回
        """
        graph = StateGraph(PluginState)

        # 跟踪上一个节点，用于串联
        previous_node = None

        for i, plugin_name in enumerate(enabled_plugins):
            # 检查插件是否已注册
            if plugin_name in self.plugins:
                # 创建唯一的节点名称
                node_name = f"plugin_{i}_{plugin_name}"

                # 添加插件节点
                graph.add_node(node_name, self.plugins[plugin_name])
                print(f"  添加节点: {node_name}")

                # 设置入口点或连接到上一个节点
                if previous_node is None:
                    graph.set_entry_point(node_name)
                    print(f"  设置入口点: {node_name}")
                else:
                    graph.add_edge(previous_node, node_name)
                    print(f"  连接: {previous_node} -> {node_name}")

                previous_node = node_name
            else:
                print(f"⚠️  警告: 插件 '{plugin_name}' 未注册，跳过")

        # 连接最后一个节点到结束
        if previous_node:
            graph.add_edge(previous_node, END)

        return graph.compile()

# 定义各种插件
def uppercase_plugin(state: PluginState) -> dict:
    """
    大写插件

    功能: 将输入文本转换为大写
    输入: state["input"]
    输出: state["output"] = input.upper()
    """
    result = state["input"].upper()
    print(f"  [大写插件] {state['input']} -> {result}")
    return {"output": result}

def reverse_plugin(state: PluginState) -> dict:
    """
    反转插件

    功能: 反转文本
    输入: state["output"] 或 state["input"]
    输出: state["output"] = text[::-1]

    注意: 优先使用 output 字段（支持插件链）
    """
    text = state.get("output") or state["input"]
    result = text[::-1]
    print(f"  [反转插件] {text} -> {result}")
    return {"output": result}

def exclamation_plugin(state: PluginState) -> dict:
    """
    感叹号插件

    功能: 在文本末尾添加感叹号
    输入: state["output"] 或 state["input"]
    输出: state["output"] = text + "!!!"
    """
    text = state.get("output") or state["input"]
    result = text + "!!!"
    print(f"  [感叹号插件] {text} -> {result}")
    return {"output": result}

def prefix_plugin(state: PluginState) -> dict:
    """
    前缀插件

    功能: 在文本前添加前缀
    """
    text = state.get("output") or state["input"]
    result = "[处理完成] " + text
    print(f"  [前缀插件] {text} -> {result}")
    return {"output": result}

def length_plugin(state: PluginState) -> dict:
    """
    长度统计插件

    功能: 在文本后添加长度信息
    """
    text = state.get("output") or state["input"]
    result = f"{text} (长度: {len(text)})"
    print(f"  [长度插件] {text} -> {result}")
    return {"output": result}

# 测试插件系统
def test_plugin_system():
    """
    测试插件系统

    演示:
    1. 注册多个插件
    2. 创建不同的插件组合
    3. 测试插件链式执行
    """
    print("=== 插件系统测试 ===\n")

    system = PluginSystem()

    # 1. 注册插件
    print("1. 注册插件:")
    system.register("uppercase", uppercase_plugin)
    system.register("reverse", reverse_plugin)
    system.register("exclamation", exclamation_plugin)
    system.register("prefix", prefix_plugin)
    system.register("length", length_plugin)

    # 2. 场景1：只使用大写插件
    print("\n2. 场景1: 单个插件")
    print("启用插件: ['uppercase']")
    app1 = system.create_graph(["uppercase"])
    result1 = app1.invoke({"input": "hello", "output": ""})
    print(f"✅ 结果: {result1['output']}\n")  # HELLO

    # 3. 场景2：组合多个插件
    print("3. 场景2: 插件链")
    print("启用插件: ['uppercase', 'reverse', 'exclamation']")
    app2 = system.create_graph(["uppercase", "reverse", "exclamation"])
    result2 = app2.invoke({"input": "hello", "output": ""})
    print(f"✅ 结果: {result2['output']}\n")  # OLLEH!!!

    # 4. 场景3：完整处理流程
    print("4. 场景3: 完整流程")
    print("启用插件: ['uppercase', 'exclamation', 'prefix', 'length']")
    app3 = system.create_graph([
        "uppercase",
        "exclamation",
        "prefix",
        "length"
    ])
    result3 = app3.invoke({"input": "world", "output": ""})
    print(f"✅ 结果: {result3['output']}\n")  # [处理完成] WORLD!!! (长度: 17)

    # 5. 场景4：测试未注册插件
    print("5. 场景4: 处理未注册插件")
    print("启用插件: ['uppercase', 'unknown', 'reverse']")
    app4 = system.create_graph(["uppercase", "unknown", "reverse"])
    result4 = app4.invoke({"input": "test", "output": ""})
    print(f"✅ 结果: {result4['output']}\n")  # TSET (跳过 unknown)

    print("✅ 插件系统测试通过")
```

**高级插件系统示例**

```python
from typing import TypedDict, Callable, Dict, Any
from langgraph.graph import StateGraph, END

# 增强的插件状态
class AdvancedPluginState(TypedDict):
    input: str
    output: str
    metadata: dict  # 插件元数据
    errors: list    # 错误记录

class AdvancedPluginSystem:
    """
    高级插件系统

    新特性:
    1. 插件元数据（版本、作者、描述）
    2. 插件依赖检查
    3. 错误处理
    4. 插件优先级排序
    """

    def __init__(self):
        self.plugins: Dict[str, Dict[str, Any]] = {}

    def register(
        self,
        name: str,
        plugin: Callable,
        version: str = "1.0.0",
        dependencies: list[str] = None,
        priority: int = 0
    ):
        """
        注册插件（带元数据）

        参数:
            name: 插件名称
            plugin: 插件函数
            version: 插件版本
            dependencies: 依赖的其他插件
            priority: 优先级（数字越大越优先）
        """
        self.plugins[name] = {
            "function": plugin,
            "version": version,
            "dependencies": dependencies or [],
            "priority": priority
        }
        print(f"✅ 注册插件: {name} v{version} (优先级: {priority})")

    def _check_dependencies(self, enabled_plugins: list[str]) -> list[str]:
        """
        检查并解析插件依赖

        返回: 按依赖顺序排列的插件列表
        """
        resolved = []
        visited = set()

        def resolve(plugin_name: str):
            if plugin_name in visited:
                return
            if plugin_name not in self.plugins:
                raise ValueError(f"插件 '{plugin_name}' 未注册")

            visited.add(plugin_name)

            # 先解析依赖
            deps = self.plugins[plugin_name]["dependencies"]
            for dep in deps:
                if dep not in enabled_plugins:
                    raise ValueError(
                        f"插件 '{plugin_name}' 依赖 '{dep}'，"
                        f"但 '{dep}' 未启用"
                    )
                resolve(dep)

            resolved.append(plugin_name)

        for plugin in enabled_plugins:
            resolve(plugin)

        return resolved

    def create_graph(self, enabled_plugins: list[str]):
        """
        创建插件图（带依赖检查）
        """
        # 1. 检查依赖
        try:
            ordered_plugins = self._check_dependencies(enabled_plugins)
            print(f"插件执行顺序: {ordered_plugins}")
        except ValueError as e:
            print(f"❌ 依赖检查失败: {e}")
            return None

        # 2. 按优先级排序
        ordered_plugins.sort(
            key=lambda name: self.plugins[name]["priority"],
            reverse=True
        )

        # 3. 构建图
        graph = StateGraph(AdvancedPluginState)
        previous_node = None

        for i, plugin_name in enumerate(ordered_plugins):
            node_name = f"plugin_{i}_{plugin_name}"
            plugin_func = self.plugins[plugin_name]["function"]

            # 包装插件函数以支持错误处理
            def make_safe_plugin(func, name):
                def safe_wrapper(state: AdvancedPluginState) -> dict:
                    try:
                        result = func(state)
                        return {
                            **result,
                            "metadata": {
                                **state.get("metadata", {}),
                                f"{name}_executed": True
                            }
                        }
                    except Exception as e:
                        print(f"❌ 插件 '{name}' 执行失败: {e}")
                        errors = state.get("errors", [])
                        errors.append(f"{name}: {str(e)}")
                        return {"errors": errors}
                return safe_wrapper

            graph.add_node(
                node_name,
                make_safe_plugin(plugin_func, plugin_name)
            )

            if previous_node is None:
                graph.set_entry_point(node_name)
            else:
                graph.add_edge(previous_node, node_name)

            previous_node = node_name

        if previous_node:
            graph.add_edge(previous_node, END)

        return graph.compile()

# 测试高级插件系统
def test_advanced_plugin_system():
    """测试高级插件系统"""
    print("\n=== 高级插件系统测试 ===\n")

    system = AdvancedPluginSystem()

    # 注册插件（带依赖）
    system.register(
        "base_transform",
        uppercase_plugin,
        version="1.0.0",
        priority=10
    )

    system.register(
        "enhance",
        exclamation_plugin,
        version="1.0.0",
        dependencies=["base_transform"],  # 依赖 base_transform
        priority=5
    )

    # 测试正确的依赖顺序
    print("测试1: 正确的依赖")
    app = system.create_graph(["enhance", "base_transform"])
    if app:
        result = app.invoke({
            "input": "test",
            "output": "",
            "metadata": {},
            "errors": []
        })
        print(f"✅ 结果: {result['output']}")
        print(f"元数据: {result['metadata']}\n")

    # 测试缺少依赖
    print("测试2: 缺少依赖")
    app2 = system.create_graph(["enhance"])  # 缺少 base_transform

    print("\n✅ 高级插件系统测试完成")
```

**插件系统的最佳实践**

1. **清晰的插件接口**
```python
# 定义标准的插件接口
from typing import Protocol

class Plugin(Protocol):
    """插件协议"""

    def execute(self, state: PluginState) -> dict:
        """执行插件逻辑"""
        ...

    @property
    def name(self) -> str:
        """插件名称"""
        ...

    @property
    def version(self) -> str:
        """插件版本"""
        ...
```

2. **插件隔离**
```python
# 每个插件有独立的命名空间
def create_isolated_plugin(plugin_func):
    """创建隔离的插件执行环境"""
    def wrapper(state):
        # 复制状态避免污染
        local_state = state.copy()
        return plugin_func(local_state)
    return wrapper
```

3. **插件配置**
```python
# 支持插件参数配置
class ConfigurablePlugin:
    def __init__(self, config: dict):
        self.config = config

    def __call__(self, state: PluginState) -> dict:
        # 使用配置执行插件逻辑
        threshold = self.config.get("threshold", 10)
        # ...
```

4. **插件版本管理**
```python
# 检查版本兼容性
def check_version_compatibility(
    plugin_version: str,
    required_version: str
) -> bool:
    """检查版本兼容性"""
    # 实现语义化版本检查
    return compare_versions(plugin_version, required_version)
```

**插件系统的实际应用**

1. **内容审核系统**
```python
plugins = [
    "text_filter",      # 敏感词过滤
    "spam_detector",    # 垃圾检测
    "sentiment_check",  # 情感分析
    "compliance_verify" # 合规检查
]
```

2. **数据ETL流程**
```python
plugins = [
    "extract_csv",      # 提取CSV数据
    "validate_schema",  # 验证数据模式
    "transform_json",   # 转换为JSON
    "load_database"     # 加载到数据库
]
```

3. **CI/CD工作流**
```python
plugins = [
    "checkout_code",    # 检出代码
    "run_tests",        # 运行测试
    "build_docker",     # 构建镜像
    "deploy_k8s"        # 部署到K8s
]
```

## 六、中断与恢复

### 6.1 人工审核中断

```python
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict

class ApprovalState(TypedDict):
    content: str
    approved: bool
    reviewer_comment: str

def create_approval_workflow():
    """创建需要人工审核的工作流"""
    def prepare(state: ApprovalState) -> dict:
        return {"content": f"Prepared: {state['content']}"}

    def wait_for_approval(state: ApprovalState) -> dict:
        """等待审核的节点"""
        # 这里会中断，等待人工输入
        return {}

    def process_approved(state: ApprovalState) -> dict:
        return {"content": f"Approved and processed: {state['content']}"}

    def handle_rejection(state: ApprovalState) -> dict:
        return {"content": f"Rejected: {state['reviewer_comment']}"}

    def route_approval(state: ApprovalState) -> str:
        if state.get("approved"):
            return "approved"
        return "rejected"

    graph = StateGraph(ApprovalState)

    graph.add_node("prepare", prepare)
    graph.add_node("approval", wait_for_approval)
    graph.add_node("process", process_approved)
    graph.add_node("reject", handle_rejection)

    graph.set_entry_point("prepare")
    graph.add_edge("prepare", "approval")

    graph.add_conditional_edges(
        "approval",
        route_approval,
        {
            "approved": "process",
            "rejected": "reject"
        }
    )

    graph.add_edge("process", END)
    graph.add_edge("reject", END)

    # 使用 checkpointer 以支持中断恢复
    checkpointer = MemorySaver()
    return graph.compile(checkpointer=checkpointer, interrupt_before=["approval"])

# 测试中断与恢复
def test_interrupt_and_resume():
    """测试中断与恢复"""
    app = create_approval_workflow()

    config = {"configurable": {"thread_id": "approval-1"}}

    # 第一次执行 - 会在 approval 节点前中断
    print("第一次执行（中断前）:")
    result1 = app.invoke({
        "content": "Document to review",
        "approved": False,
        "reviewer_comment": ""
    }, config=config)

    print(f"状态: {result1}")

    # 模拟人工审核 - 批准
    print("\n人工审核后（批准）:")
    result2 = app.invoke({
        **result1,
        "approved": True
    }, config=config)

    print(f"最终结果: {result2}")
```

### 6.2 断点调试

```python
from typing import TypedDict
from langgraph.checkpoint.memory import MemorySaver

class DebugState(TypedDict):
    step: int
    data: str
    debug_info: list[str]

def create_debug_workflow():
    """创建可调试的工作流"""
    def step1(state: DebugState) -> dict:
        return {
            "step": 1,
            "data": "Step 1 complete",
            "debug_info": [f"Step 1 executed at step {state['step']}"]
        }

    def step2(state: DebugState) -> dict:
        return {
            "step": 2,
            "data": "Step 2 complete",
            "debug_info": [f"Step 2 executed at step {state['step']}"]
        }

    def step3(state: DebugState) -> dict:
        return {
            "step": 3,
            "data": "Step 3 complete",
            "debug_info": [f"Step 3 executed at step {state['step']}"]
        }

    graph = StateGraph(DebugState)

    graph.add_node("step1", step1)
    graph.add_node("step2", step2)
    graph.add_node("step3", step3)

    graph.set_entry_point("step1")
    graph.add_edge("step1", "step2")
    graph.add_edge("step2", "step3")
    graph.add_edge("step3", END)

    checkpointer = MemorySaver()
    # 在每个节点前设置断点
    return graph.compile(
        checkpointer=checkpointer,
        interrupt_before=["step1", "step2", "step3"]
    )

# 测试逐步调试
def test_step_debugging():
    """测试逐步调试"""
    app = create_debug_workflow()
    config = {"configurable": {"thread_id": "debug-1"}}

    initial_state = {"step": 0, "data": "", "debug_info": []}

    # 逐步执行
    print("=== 逐步调试 ===")

    # 执行到 step1
    print("\n执行到 step1:")
    state1 = app.invoke(initial_state, config=config)
    print(f"  当前状态: {state1}")

    # 继续到 step2
    print("\n执行到 step2:")
    state2 = app.invoke(None, config=config)
    print(f"  当前状态: {state2}")

    # 继续到 step3
    print("\n执行到 step3:")
    state3 = app.invoke(None, config=config)
    print(f"  当前状态: {state3}")

    # 完成
    print("\n执行完成:")
    final_state = app.invoke(None, config=config)
    print(f"  最终状态: {final_state}")
```

## 七、时间旅行

### 7.1 状态历史查询

```python
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, END
from typing import TypedDict

class HistoryState(TypedDict):
    count: int
    operation: str

def create_history_graph():
    """创建记录历史的图"""
    def increment(state: HistoryState) -> dict:
        return {"count": state["count"] + 1, "operation": "increment"}

    def double(state: HistoryState) -> dict:
        return {"count": state["count"] * 2, "operation": "double"}

    graph = StateGraph(HistoryState)

    graph.add_node("increment", increment)
    graph.add_node("double", double)

    graph.set_entry_point("increment")
    graph.add_edge("increment", "double")
    graph.add_edge("double", END)

    checkpointer = MemorySaver()
    return graph.compile(checkpointer=checkpointer)

# 测试历史查询
def test_state_history():
    """测试状态历史"""
    app = create_history_graph()
    config = {"configurable": {"thread_id": "history-1"}}

    # 执行工作流
    initial_state = {"count": 5, "operation": ""}
    final_state = app.invoke(initial_state, config=config)

    print(f"最终状态: {final_state}")

    # 查询历史状态
    print("\n=== 状态历史 ===")
    history = list(app.get_state_history(config))

    for i, checkpoint in enumerate(history):
        print(f"\n检查点 {i}:")
        print(f"  值: {checkpoint.values}")
        print(f"  下一步: {checkpoint.next}")
```

### 7.2 状态回溯

```python
from typing import TypedDict

class ReplayState(TypedDict):
    value: int
    history: list[int]

def create_replay_graph():
    """创建支持回溯的图"""
    checkpointer = MemorySaver()

    def process(state: ReplayState) -> dict:
        new_value = state["value"] + 10
        return {
            "value": new_value,
            "history": state["history"] + [new_value]
        }

    graph = StateGraph(ReplayState)
    graph.add_node("process", process)
    graph.set_entry_point("process")
    graph.add_edge("process", END)

    return graph.compile(checkpointer=checkpointer)

# 测试回溯
def test_replay():
    """测试状态回溯"""
    app = create_replay_graph()
    config = {"configurable": {"thread_id": "replay-1"}}

    # 执行多次
    state1 = app.invoke({"value": 0, "history": []}, config=config)
    state2 = app.invoke(state1, config=config)
    state3 = app.invoke(state2, config=config)

    print(f"当前状态: {state3}")

    # 回溯到之前的状态
    print("\n=== 回溯状态 ===")
    history = list(app.get_state_history(config))

    if len(history) >= 2:
        # 获取倒数第二个状态
        previous_checkpoint = history[1]
        print(f"回溯到: {previous_checkpoint.values}")

        # 从该状态继续执行
        new_state = app.invoke(
            previous_checkpoint.values,
            config=config
        )
        print(f"新的执行结果: {new_state}")
```

## 八、高级特性组合示例

### 综合案例：智能文档处理系统

```python
# 结合子图、并行、流式、中断等特性的完整示例

from typing import TypedDict, Annotated, Literal
import operator
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

class DocumentState(TypedDict):
    document_id: str
    content: str
    validated: bool
    processed_chunks: Annotated[list[dict], operator.add]
    summary: str
    approved: bool
    final_output: str

# 子图：验证模块
def create_validation_subgraph():
    """文档验证子图"""
    def validate_format(state: dict) -> dict:
        # 验证格式
        return {"valid": len(state["content"]) > 0}

    def validate_content(state: dict) -> dict:
        # 验证内容
        return {"valid": "test" not in state["content"].lower()}

    graph = StateGraph(dict)
    graph.add_node("format", validate_format)
    graph.add_node("content", validate_content)

    graph.set_entry_point("format")
    graph.add_edge("format", "content")
    graph.add_edge("content", END)

    return graph.compile()

# 主工作流
def create_document_workflow():
    """文档处理工作流"""
    validation_graph = create_validation_subgraph()

    def validate(state: DocumentState) -> dict:
        """验证节点（使用子图）"""
        result = validation_graph.invoke({
            "content": state["content"],
            "valid": False
        })
        return {"validated": result["valid"]}

    def split_document(state: DocumentState) -> dict:
        """分割文档"""
        # 模拟分割成多个块
        chunks = [
            {"id": i, "text": f"Chunk {i}"}
            for i in range(3)
        ]
        return {"processed_chunks": chunks}

    def summarize(state: DocumentState) -> dict:
        """生成摘要"""
        summary = f"Summary of {len(state['processed_chunks'])} chunks"
        return {"summary": summary}

    def wait_approval(state: DocumentState) -> dict:
        """等待审批（中断点）"""
        return {}

    def finalize(state: DocumentState) -> dict:
        """最终处理"""
        return {"final_output": f"Completed: {state['summary']}"}

    def route_approval(state: DocumentState) -> str:
        return "finalize" if state.get("approved") else END

    graph = StateGraph(DocumentState)

    graph.add_node("validate", validate)
    graph.add_node("split", split_document)
    graph.add_node("summarize", summarize)
    graph.add_node("approval", wait_approval)
    graph.add_node("finalize", finalize)

    graph.set_entry_point("validate")
    graph.add_edge("validate", "split")
    graph.add_edge("split", "summarize")
    graph.add_edge("summarize", "approval")

    graph.add_conditional_edges(
        "approval",
        route_approval,
        {"finalize": "finalize", END: END}
    )

    graph.add_edge("finalize", END)

    checkpointer = MemorySaver()
    return graph.compile(
        checkpointer=checkpointer,
        interrupt_before=["approval"]
    )

# 测试综合案例
def test_advanced_workflow():
    """测试高级工作流"""
    app = create_document_workflow()
    config = {"configurable": {"thread_id": "doc-1"}}

    # 第一阶段：处理到审批
    initial_state = {
        "document_id": "doc_001",
        "content": "This is a sample document.",
        "validated": False,
        "processed_chunks": [],
        "summary": "",
        "approved": False,
        "final_output": ""
    }

    print("=== 第一阶段：处理文档 ===")
    state1 = app.invoke(initial_state, config=config)
    print(f"等待审批状态: {state1['summary']}")

    # 第二阶段：审批后继续
    print("\n=== 第二阶段：审批通过 ===")
    state2 = app.invoke({
        **state1,
        "approved": True
    }, config=config)
    print(f"最终输出: {state2['final_output']}")
```

## 九、总结

### 高级特性使用建议

| 特性 | 适用场景 | 复杂度 | 性能影响 |
|-----|---------|-------|---------|
| 子图 | 模块化、复用 | 中 | 低 |
| 并行处理 | 独立任务 | 中 | 提升 |
| 流式执行 | 实时响应 | 中 | 中等 |
| 动态图 | 灵活配置 | 高 | 低 |
| 中断恢复 | 人工干预 | 高 | 低 |
| 时间旅行 | 调试、审计 | 中 | 中等 |

---

**下一步：** 学习 [11.LangChain集成](./11.LangChain集成.md) 与生态集成！
