---
title: LangGraph 状态管理与数据流
date: 2025-09-30
permalink: /ai/langgraph/state-management.html
tags:
  - AI
  - LangGraph
  - State Management
categories:
  - AI
  - LangGraph
---

# LangGraph 状态管理与数据流

## 状态管理的核心理念

在 LangGraph 中，状态（State）是贯穿整个图执行过程的数据载体。它不仅存储数据，还定义了数据如何在节点间流转和更新。

```python
# 状态流转示意图
"""
┌──────────┐    State v1    ┌──────────┐    State v2    ┌──────────┐
│  Node A  │ ─────────────> │  Node B  │ ─────────────> │  Node C  │
└──────────┘                └──────────┘                └──────────┘
     ↓                           ↓                           ↓
  更新状态                    读取+更新                   最终状态
"""
```

## 1. 状态定义的高级技巧

### 基础状态定义

```python
from typing import TypedDict, List, Dict, Optional, Any
from typing_extensions import Annotated
from operator import add
from datetime import datetime

class BasicState(TypedDict):
    """基础状态定义"""
    messages: List[str]
    context: Dict[str, Any]
    metadata: Optional[Dict]
```

### 带注解的状态定义

```python
# 使用 Annotated 定义更新策略
class AdvancedState(TypedDict):
    # 累加列表
    messages: Annotated[List[str], add]

    # 保留最新值
    current_step: str

    # 合并字典
    context: Annotated[Dict, lambda x, y: {**x, **y}]

    # 计数器
    counter: Annotated[int, lambda x, y: x + y]

    # 时间戳（自动更新）
    last_updated: Annotated[datetime, lambda x, y: datetime.now()]
```

### 嵌套状态结构

```python
class UserInfo(TypedDict):
    name: str
    email: str
    preferences: Dict

class SessionState(TypedDict):
    session_id: str
    user: UserInfo
    history: List[Dict]

class ComplexState(TypedDict):
    """复杂嵌套状态"""
    session: SessionState
    workflow_data: Dict
    messages: Annotated[List[str], add]
```

## 2. 状态更新机制详解

### 默认更新策略

```python
def understanding_updates(state: Dict) -> Dict:
    """
    理解状态更新的三种模式
    """
    # 1. 完全覆盖（默认行为）
    return {"field": "new_value"}  # field 被完全替换

    # 2. 部分更新
    return {"field": state["field"] + ["new_item"]}  # 手动合并

    # 3. 使用 Reducer（通过 Annotated）
    # 自动应用定义的合并策略
```

### 自定义 Reducer

```python
from typing import Any

def custom_list_reducer(current: List, update: List) -> List:
    """自定义列表合并逻辑：去重并保持顺序"""
    seen = set()
    result = []
    for item in current + update:
        if item not in seen:
            seen.add(item)
            result.append(item)
    return result

def priority_dict_reducer(current: Dict, update: Dict) -> Dict:
    """优先级字典合并：新值优先，但保留特殊字段"""
    result = current.copy()
    for key, value in update.items():
        if key.startswith("_"):  # 保护字段
            continue
        result[key] = value
    return result

class StateWithCustomReducers(TypedDict):
    unique_items: Annotated[List, custom_list_reducer]
    config: Annotated[Dict, priority_dict_reducer]
```

### 条件更新

```python
def conditional_update_node(state: State) -> State:
    """根据条件决定是否更新状态"""
    updates = {}

    # 条件更新
    if state.get("should_update", False):
        updates["data"] = process_data(state["data"])

    # 增量更新
    if "counter" in state:
        updates["counter"] = state["counter"] + 1

    # 选择性字段更新
    if needs_refresh(state):
        updates.update({
            "cache": None,
            "last_refresh": datetime.now()
        })

    return updates
```

## 3. 状态通道（Channels）深入

### 内置通道类型

```python
from langgraph.channels import (
    LastValue,      # 保留最后一个值
    BinaryChannel,  # 二进制操作
    Topic,          # 主题订阅
    Context        # 上下文累积
)

class ChannelState(TypedDict):
    # LastValue: 只保留最新值
    current_task: Annotated[str, LastValue]

    # BinaryChannel: 位操作
    flags: Annotated[int, BinaryChannel]

    # Topic: 发布订阅模式
    events: Annotated[List[str], Topic]

    # Context: 保留所有历史
    audit_log: Annotated[List[Dict], Context]
```

### 自定义通道实现

```python
class SlidingWindowChannel:
    """滑动窗口通道：只保留最近 N 条记录"""

    def __init__(self, window_size: int = 10):
        self.window_size = window_size
        self.data = []

    def update(self, values: List) -> List:
        self.data.extend(values)
        # 保持窗口大小
        if len(self.data) > self.window_size:
            self.data = self.data[-self.window_size:]
        return self.data

    def get(self) -> List:
        return self.data

class PriorityQueueChannel:
    """优先级队列通道"""

    def __init__(self):
        self.queue = []

    def update(self, items: List[Tuple[int, Any]]) -> List:
        for priority, item in items:
            self.queue.append((priority, item))
        # 按优先级排序
        self.queue.sort(key=lambda x: x[0], reverse=True)
        return self.queue

    def get(self) -> List:
        return [item for _, item in self.queue]
```

## 4. 状态持久化与检查点

### 基础持久化

```python
from langgraph.checkpoint import MemorySaver, SqliteSaver
import json

# 内存持久化（测试用）
memory_saver = MemorySaver()

# SQLite 持久化
sqlite_saver = SqliteSaver.from_conn_string("workflow.db")

# 编译时启用检查点
app = workflow.compile(checkpointer=sqlite_saver)
```

### 自定义检查点存储

```python
from langgraph.checkpoint.base import BaseCheckpointSaver
import redis

class RedisCheckpointer(BaseCheckpointSaver):
    """Redis 检查点存储实现"""

    def __init__(self, redis_client: redis.Redis):
        self.client = redis_client

    def put(self, config: Dict, checkpoint: Dict) -> None:
        """保存检查点"""
        thread_id = config["configurable"]["thread_id"]
        key = f"checkpoint:{thread_id}"
        self.client.set(key, json.dumps(checkpoint))
        self.client.expire(key, 3600)  # 1小时过期

    def get(self, config: Dict) -> Optional[Dict]:
        """获取检查点"""
        thread_id = config["configurable"]["thread_id"]
        key = f"checkpoint:{thread_id}"
        data = self.client.get(key)
        return json.loads(data) if data else None

    def list(self, config: Dict) -> List[Dict]:
        """列出所有检查点"""
        pattern = "checkpoint:*"
        keys = self.client.keys(pattern)
        return [{"thread_id": k.decode().split(":")[1]} for k in keys]

# 使用自定义检查点
redis_client = redis.Redis(host='localhost', port=6379)
redis_checkpointer = RedisCheckpointer(redis_client)
app = workflow.compile(checkpointer=redis_checkpointer)
```

### 检查点的高级应用

```python
# 1. 版本控制
class VersionedState(TypedDict):
    version: int
    data: Dict
    history: Annotated[List[Dict], add]

def versioned_node(state: VersionedState) -> VersionedState:
    """带版本控制的节点"""
    new_version = state.get("version", 0) + 1
    snapshot = {
        "version": new_version,
        "timestamp": datetime.now().isoformat(),
        "data": state.get("data", {}).copy()
    }

    return {
        "version": new_version,
        "data": process_data(state["data"]),
        "history": [snapshot]
    }

# 2. 回滚机制
class RollbackableWorkflow:
    def __init__(self, app, checkpointer):
        self.app = app
        self.checkpointer = checkpointer

    def rollback_to_checkpoint(self, thread_id: str, checkpoint_id: str):
        """回滚到特定检查点"""
        config = {"configurable": {"thread_id": thread_id}}

        # 获取历史检查点
        checkpoints = self.checkpointer.list(config)

        # 找到目标检查点
        target = next((cp for cp in checkpoints if cp["id"] == checkpoint_id), None)

        if target:
            # 恢复状态
            state = self.checkpointer.get_tuple(config)
            return state
        return None
```

## 5. 状态的并发控制

### 并发安全的状态更新

```python
import threading
from typing import TypedDict, Annotated

class ConcurrentState(TypedDict):
    """支持并发的状态定义"""
    # 使用线程安全的累加器
    counter: Annotated[int, lambda x, y: x + y]

    # 使用锁保护的字段
    critical_data: Dict

class ThreadSafeNode:
    def __init__(self):
        self.lock = threading.Lock()

    def __call__(self, state: ConcurrentState) -> ConcurrentState:
        """线程安全的节点执行"""
        with self.lock:
            # 临界区代码
            critical_data = state.get("critical_data", {})
            processed = self.process_critical(critical_data)

            return {
                "counter": 1,  # 自动安全累加
                "critical_data": processed
            }

    def process_critical(self, data: Dict) -> Dict:
        # 处理关键数据
        return data
```

### 分布式状态管理

```python
from typing import Any
import pickle

class DistributedState:
    """分布式状态管理器"""

    def __init__(self, backend: str = "redis"):
        self.backend = self._init_backend(backend)

    def _init_backend(self, backend: str):
        if backend == "redis":
            import redis
            return redis.Redis(host='localhost', port=6379)
        elif backend == "etcd":
            import etcd3
            return etcd3.client()

    def get_state(self, key: str) -> Any:
        """获取分布式状态"""
        if hasattr(self.backend, 'get'):  # Redis
            data = self.backend.get(key)
            return pickle.loads(data) if data else None

    def set_state(self, key: str, value: Any) -> None:
        """设置分布式状态"""
        if hasattr(self.backend, 'set'):  # Redis
            self.backend.set(key, pickle.dumps(value))

    def atomic_update(self, key: str, updater: callable) -> Any:
        """原子更新操作"""
        with self.backend.lock(f"{key}:lock"):
            current = self.get_state(key)
            updated = updater(current)
            self.set_state(key, updated)
            return updated
```

## 6. 数据流模式

### 单向数据流

```python
def unidirectional_flow():
    """单向数据流：A → B → C"""
    workflow = StateGraph(State)

    workflow.add_node("extract", extract_node)
    workflow.add_node("transform", transform_node)
    workflow.add_node("load", load_node)

    workflow.add_edge("extract", "transform")
    workflow.add_edge("transform", "load")
    workflow.add_edge("load", END)

    return workflow.compile()
```

### 双向数据流

```python
def bidirectional_flow():
    """双向数据流：支持反馈循环"""
    workflow = StateGraph(State)

    def feedback_router(state):
        if state.get("needs_refinement"):
            return "refine"
        return "complete"

    workflow.add_node("process", process_node)
    workflow.add_node("validate", validate_node)
    workflow.add_node("refine", refine_node)

    workflow.add_edge("process", "validate")
    workflow.add_conditional_edges(
        "validate",
        feedback_router,
        {
            "refine": "process",  # 反馈循环
            "complete": END
        }
    )

    return workflow.compile()
```

### 扇出/扇入模式

```python
def fanout_fanin_flow():
    """扇出/扇入：并行处理后聚合"""
    workflow = StateGraph(State)

    # 扇出：一个节点到多个节点
    workflow.add_node("split", split_node)
    workflow.add_node("process_a", process_a_node)
    workflow.add_node("process_b", process_b_node)
    workflow.add_node("process_c", process_c_node)

    # 扇入：多个节点到一个节点
    workflow.add_node("merge", merge_node)

    # 定义扇出边
    workflow.add_edge("split", "process_a")
    workflow.add_edge("split", "process_b")
    workflow.add_edge("split", "process_c")

    # 定义扇入边
    workflow.add_edge("process_a", "merge")
    workflow.add_edge("process_b", "merge")
    workflow.add_edge("process_c", "merge")

    return workflow.compile()
```

## 7. 状态监控与调试

### 状态追踪

```python
class StateTracker:
    """状态追踪器"""

    def __init__(self):
        self.history = []

    def track(self, node_name: str, state_before: Dict, state_after: Dict):
        """记录状态变化"""
        changes = self._diff_states(state_before, state_after)
        self.history.append({
            "node": node_name,
            "timestamp": datetime.now(),
            "changes": changes,
            "state_snapshot": state_after.copy()
        })

    def _diff_states(self, before: Dict, after: Dict) -> Dict:
        """计算状态差异"""
        changes = {}
        all_keys = set(before.keys()) | set(after.keys())

        for key in all_keys:
            before_val = before.get(key)
            after_val = after.get(key)

            if before_val != after_val:
                changes[key] = {
                    "before": before_val,
                    "after": after_val
                }

        return changes

    def get_history(self) -> List[Dict]:
        """获取历史记录"""
        return self.history

# 使用追踪器
tracker = StateTracker()

def tracked_node(tracker: StateTracker, node_name: str):
    def wrapper(func):
        def inner(state):
            state_before = state.copy()
            result = func(state)
            state_after = {**state, **result}
            tracker.track(node_name, state_before, state_after)
            return result
        return inner
    return wrapper

# 应用追踪
@tracked_node(tracker, "process")
def process_with_tracking(state):
    return {"processed": True}
```

### 状态验证

```python
from typing import Type
import jsonschema

class StateValidator:
    """状态验证器"""

    def __init__(self, state_class: Type[TypedDict]):
        self.state_class = state_class
        self.schema = self._generate_schema(state_class)

    def _generate_schema(self, state_class):
        """从 TypedDict 生成 JSON Schema"""
        # 简化示例
        return {
            "type": "object",
            "properties": {
                key: {"type": "string"}
                for key in state_class.__annotations__
            }
        }

    def validate(self, state: Dict) -> bool:
        """验证状态是否符合定义"""
        try:
            jsonschema.validate(state, self.schema)
            return True
        except jsonschema.ValidationError as e:
            print(f"状态验证失败: {e}")
            return False

# 使用验证器
validator = StateValidator(State)

def validated_node(validator: StateValidator):
    def wrapper(func):
        def inner(state):
            if not validator.validate(state):
                raise ValueError("Invalid state")
            result = func(state)
            return result
        return inner
    return wrapper
```

## 实践示例：复杂状态管理

```python
from typing import TypedDict, List, Dict, Annotated
from datetime import datetime
from operator import add
from langgraph.graph import StateGraph, END
from langgraph.checkpoint import SqliteSaver

# 定义复杂状态
class ConversationState(TypedDict):
    # 消息历史（累加）
    messages: Annotated[List[Dict], add]

    # 当前上下文
    context: Dict

    # 用户信息
    user_info: Dict

    # 会话元数据
    metadata: Annotated[Dict, lambda x, y: {**x, **y}]

    # 状态标志
    is_complete: bool

    # 错误信息
    errors: Annotated[List[str], add]

# 创建带监控的工作流
def create_monitored_workflow():
    workflow = StateGraph(ConversationState)

    # 添加监控节点
    def monitor_node(state):
        """监控节点：记录关键指标"""
        return {
            "metadata": {
                "last_check": datetime.now().isoformat(),
                "message_count": len(state.get("messages", [])),
                "has_errors": len(state.get("errors", [])) > 0
            }
        }

    # 添加处理节点
    def process_node(state):
        """主处理节点"""
        try:
            # 处理逻辑
            result = process_messages(state["messages"])
            return {"context": result}
        except Exception as e:
            return {"errors": [str(e)]}

    # 添加验证节点
    def validate_node(state):
        """验证节点"""
        if state.get("errors"):
            return {"is_complete": False}
        return {"is_complete": True}

    # 构建流程
    workflow.add_node("monitor", monitor_node)
    workflow.add_node("process", process_node)
    workflow.add_node("validate", validate_node)

    workflow.set_entry_point("monitor")
    workflow.add_edge("monitor", "process")
    workflow.add_edge("process", "validate")

    # 条件结束
    workflow.add_conditional_edges(
        "validate",
        lambda s: "end" if s["is_complete"] else "monitor",
        {
            "end": END,
            "monitor": "monitor"
        }
    )

    # 编译with持久化
    checkpointer = SqliteSaver.from_conn_string("conversation.db")
    return workflow.compile(checkpointer=checkpointer)

# 使用示例
app = create_monitored_workflow()

initial_state = {
    "messages": [{"role": "user", "content": "Hello"}],
    "context": {},
    "user_info": {"id": "user123"},
    "metadata": {},
    "is_complete": False,
    "errors": []
}

config = {"configurable": {"thread_id": "conversation_1"}}
final_state = app.invoke(initial_state, config)
```

## 总结

LangGraph 的状态管理系统提供了：

1. **灵活的状态定义**：支持简单和复杂的状态结构
2. **强大的更新机制**：通过 Reducer 和 Channel 控制更新逻辑
3. **可靠的持久化**：检查点机制确保状态可恢复
4. **并发控制**：支持线程安全和分布式场景
5. **丰富的数据流模式**：单向、双向、扇出/扇入等
6. **完善的监控调试**：状态追踪、验证和可视化

掌握这些概念，你就能构建健壮、可扩展的 AI 工作流系统。下一篇我们将通过实战案例来应用这些知识。